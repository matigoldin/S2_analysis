{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "from phy.io import KwikModel\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# READ STIMULUS\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Here we read the binary file with stimulus: 902 of 25 piezos x 1024 samples\n",
    "# Text file has the type of stimulus: F sparse, C correlated, U uncorrelated\n",
    "def read_stimulus(binname='Stimulus_UCC.bin', textname='Stimulus_UCC.txt'):\n",
    "    ## This function reads the stimulus binary file, reads the type of stimulus,\n",
    "    ## and stores it in a matrix and a row vector\n",
    "    \n",
    "    bin_file = open(binname,'rb')\n",
    "    read_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "    read_data = read_data.reshape((-1,25,10240)) # reshapes data assuming 25 whiskers, 10240 time bins\n",
    "    txt_data = np.loadtxt(textname, dtype='S8') # Makes sure data type is text decoded\n",
    "    txt_data = txt_data.view(np.chararray).decode('utf-8') # Makes sure data type is text decoded\n",
    "    \n",
    "    return read_data, txt_data\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "def readkwikinfo(kwik, grupete=3):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "\n",
    "def BuildPSTH(Spikes, Vtag1, sampling_freq, t_before, t_after) :\n",
    "## The first task is to find the stimulus onset times for each whisker in each sweep in each direction\n",
    "    stim, stimtype = read_stimulus()\n",
    "    start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "    starts = (where(start_and_stops==1)[0]-2999)/float(sampling_freq) # time in seconds\n",
    "    stops = (where(start_and_stops==-1)[0]+4110)/float(sampling_freq) # time in seconds\n",
    "    \n",
    "    stim = stim[0:len(stops),:,:]\n",
    "    stimtype = stimtype[0:len(stops)]\n",
    "    \n",
    "    stim = stim[np.where(stimtype=='F')[0], :, :]\n",
    "    starts = starts[np.where(stimtype=='F')[0]]\n",
    "    stops = stops[np.where(stimtype=='F')[0]]\n",
    "    \n",
    "    stimtimes = {}\n",
    "    for w in np.arange(25, dtype='int') :  \n",
    "        timesUP = []\n",
    "        timesDOWN = []\n",
    "        for i in np.arange(len(stim), dtype='int') :\n",
    "            indsUP = (np.where(stim[i, w, :]==1108.8889)[0]-1)[::2]   #we correct for 0 at the start of stim\n",
    "            timesUP.append(indsUP)       \n",
    "            indsDOWN = (np.where(stim[i, w, :]==-1108.8889)[0]-1)[::2]   #we correct for 0 at the start of stim\n",
    "            timesDOWN.append(indsDOWN)\n",
    "        stimtimes[w] = timesUP, timesDOWN #stimtimes[whisker][0][:]=UP stimtimes[whisker][1][:]=DOWN\n",
    "    \n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    hist_inds = {}\n",
    "    PSTH_spike_counts = {}\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in Spikes.keys(): \n",
    "        PSTH_spike_counts[neuron], hist_inds[neuron] = PSTH_spikes(stim, stimtype, stimtimes, Spikes[neuron].spike_times, sampling_freq, t_before, t_after, starts, stops)\n",
    "    \n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "def PSTH_spikes(stimulation, stimtype, stimtimes, spikes, samp, t_before, t_after, starts, stops):\n",
    "    \"\"\"\n",
    "    stimulation   : a list of numpy arrays with a n*t stimulus inside\n",
    "    stimtimes     : a list of the times the stimulus occurred for each whisker \n",
    "    spikes        : an array that contains the spike times (s)\n",
    "    Vtag1         : synchronises stimulus with spike times\n",
    "    samp          : sampling rate of the stimulation (Hz)\n",
    "    t_before      : duration before the stim (positive, s)\n",
    "    t_after       : duration after the stim (positive, s)\n",
    "    starts        : the start of the F sweeps\n",
    "    stops         : the stops of the F sweeps\n",
    "    \"\"\"\n",
    "    \n",
    "    stim_samp = 1/.0009997575757\n",
    "    \n",
    "    PSTH_spike_counts = {}\n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(len(stimtimes[w][0][i]), dtype='int') :           \n",
    "                timesUP = starts[i] + stimtimes[w][0][i][x]/stim_samp\n",
    "                spikecountsup += len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)])\n",
    "            for y in np.arange(len(stimtimes[w][1][i]), dtype='int') :\n",
    "                timesDOWN = starts[i] + stimtimes[w][1][i][y]/stim_samp                \n",
    "                spikecountsdown += len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "        PSTH_spike_counts[w] = spikecountsup, spikecountsdown\n",
    "    \n",
    "    hist_inds = {}\n",
    "    \n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        hist_inds[w] = np.zeros(PSTH_spike_counts[w][0]), np.zeros(PSTH_spike_counts[w][1])\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(len(stimtimes[w][0][i]), dtype='int') :           \n",
    "                timesUP = starts[i] + stimtimes[w][0][i][x]/stim_samp\n",
    "                spikecountup = len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)])\n",
    "                spikeidxup = spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)]\n",
    "                spikeidxup = np.around((spikeidxup - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                hist_inds[w][0][spikecountsup:(spikecountsup+spikecountup)] = spikeidxup-stimtimes[w][0][i][x]\n",
    "                spikecountsup += spikecountup\n",
    "            \n",
    "            for y in np.arange(len(stimtimes[w][1][i]), dtype='int') :\n",
    "                timesDOWN = starts[i] + stimtimes[w][1][i][y]/stim_samp                \n",
    "                spikecountdown = len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "                spikeidxdown = spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)]\n",
    "                spikeidxdown = np.around((spikeidxdown - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                hist_inds[w][1][spikecountsdown:(spikecountsdown+spikecountdown)] = spikeidxdown-stimtimes[w][1][i][y]\n",
    "                spikecountsdown += spikecountdown\n",
    "                \n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "def display_PSTH(histdata, counts, t_before, t_after) :\n",
    "    stim_samp = 1/.0009997575757 \n",
    "    before_index = int(np.around(t_before*stim_samp)) # indexes\n",
    "    after_index = int(np.around(t_after*stim_samp)) # indexes\n",
    "    histlength = before_index + after_index + 1\n",
    "    \n",
    "    nup = np.zeros((25,histlength-1))\n",
    "    ndown = np.zeros((25,histlength-1))\n",
    "    for i in range(25) :\n",
    "        if histdata[i][0].size :\n",
    "            n1, bins, patches = hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength))\n",
    "            nup[i,:] = n1\n",
    "            close()\n",
    "        if histdata[i][1].size :\n",
    "            n2, bins, patches = hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength))\n",
    "            ndown[i,:] = n2\n",
    "            close()\n",
    "    normnum = (1/np.sum(nup+ndown))\n",
    "    height = np.max(np.array([np.max(nup), np.max(ndown)]))/(1/normnum)\n",
    "      \n",
    "    clf()\n",
    "    for i in range(25) :\n",
    "        if i == 0 :\n",
    "            ax1 = subplot(5,5,1, frame_on=False)\n",
    "        else :\n",
    "            subplot(5,5,i+1,sharex=ax1,sharey=ax1,frame_on=False)\n",
    "            xticks([],[])  #gets rid of the x ticks and numbers\n",
    "            yticks([],[])  #gets rid of the y ticks and numbers\n",
    "        if histdata[i][0].size :\n",
    "            hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength), color='b', alpha=0.5, edgecolor='none', histtype='stepfilled', label='Pos', weights=np.repeat(normnum, len(histdata[i][0])))\n",
    "        if histdata[i][1].size :\n",
    "            hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength), color='r', alpha=0.5, edgecolor='none', histtype='stepfilled', label='Neg', weights=np.repeat(normnum, len(histdata[i][1]))) \n",
    "        #if (histdata[i][0].size) or (histdata[i][1].size) :\n",
    "        xlim(-before_index, after_index)\n",
    "        axvline(0, color = 'r', linewidth=1)\n",
    "        axhline(0, color = 'r', linewidth=2)\n",
    "        ymax = 1.02 * height\n",
    "        ylim(0, ymax)\n",
    "        xvals = np.array([0,10,20,30])\n",
    "        yvals = np.array([0,ymax*0.9,ymax*0.9,0])\n",
    "        plot(xvals, yvals, 'r-', linewidth=0.5)\n",
    "        ax1.set_title('ymax =' + str( np.around(height,decimals = 3) ),fontsize=8)\n",
    "        \n",
    "def display_all_PSTHs_of_recording(histdata, counts, pdf_files_directory, t_before, t_after) :\n",
    "    for neuron in histdata.keys() :\n",
    "        clf()\n",
    "        totalup = 0\n",
    "        totaldown = 0\n",
    "        for i in np.arange(25, dtype='int') :\n",
    "            totalup+=counts[neuron][i][0]\n",
    "            totaldown+=counts[neuron][i][1]\n",
    "        numspikesP= totalup                  \n",
    "        numspikesN= totaldown\n",
    "        display_PSTH(histdata[neuron], counts[neuron], t_before, t_after)                               \n",
    "        suptitle('Nrn' + str(neuron) + '_Pos' + str(int(numspikesP))+ '_Neg' + str(int(numspikesN)),fontsize=10)\n",
    "        savefig(pdf_files_directory + 'Nrn' + str(neuron) + '_Pos' + str(int(numspikesP)) + '_Neg' + str(int(numspikesN)) + '_hist.pdf', format='pdf')\n",
    "        clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kwiks = ['./m2s1/MEAS-151027-2_ele01_ele08.kwik', './m2s2/MEAS-151027-2_ele09_ele16.kwik', './m2s3/MEAS-151027-2_ele17_ele24.kwik', './m2s4/MEAS-151027-2_ele25_ele32.kwik', './m2s5/MEAS-151027-2_ele33_ele40.kwik', './m2s6/MEAS-151027-2_ele41_ele48.kwik', './m2s7/MEAS-151027-2_ele49_ele56.kwik', './m2s8/MEAS-151027-2_ele57_ele64.kwik']\n",
    "#INSERT LIST Of KWIK FILES with full directory paths like the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ind in np.arange(len(kwiks)) :\n",
    "\n",
    "    sp_file = kwiks[ind]\n",
    "    #bin_file = open('MEAS-151116-3_Vtag1.dat','rb')\n",
    "    #INSERT bin_file like the line above\n",
    "    \n",
    "    subdir = os.path.dirname(kwiks[ind])\n",
    "    dirs  = [subdir+'/PDFS', subdir+'/PDFS/PDFpsth/']\n",
    "    for dir in dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "\n",
    "    Spikes, sampling_freq = readkwikinfo(sp_file, 3)\n",
    "\n",
    "    Vtag1 = np.fromfile(file=bin_file, dtype=np.int16)\n",
    "    t_before = 0.005\n",
    "    t_after = 0.045\n",
    "\n",
    "    PSTH_spike_counts, hist_output = BuildPSTH(Spikes, Vtag1, sampling_freq, t_before, t_after)\n",
    "\n",
    "    display_all_PSTHs_of_recording(hist_output, PSTH_spike_counts, dirs[1], t_before, t_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
