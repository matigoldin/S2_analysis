{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD PSTHs STAs AND STCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# READ STIMULUS\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Here we read the binary file with stimulus: 902 of 25 piezos x 1024 samples\n",
    "# Text file has the type of stimulus: F sparse, C correlated, U uncorrelated\n",
    "def read_stimulus(expe,meas):\n",
    "    ## This function reads the stimulus binary file, reads the type of stimulus,\n",
    "    ## and stores it in a matrix and a row vector\n",
    "    \n",
    "    bin_file = open(binname,'rb')\n",
    "    read_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "    read_data = read_data.reshape((-1,25,10240)) # reshapes data assuming 25 whiskers, 10240 time bins\n",
    "    txt_data = np.loadtxt(textname, dtype='S8') # Makes sure data type is text decoded\n",
    "    txt_data = txt_data.view(np.chararray).decode('utf-8') # Makes sure data type is text decoded\n",
    "    \n",
    "    return read_data, txt_data\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "# Grupete stands for cluster groups! 2: good clusters, 1: multiunits, 0: unsorted, 3: noise\n",
    "def readkwikinfo(kwik, grupete=3):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READ VTAG\n",
    "#----------------------------------------------------------------------------------------\n",
    "def readVtag(Vtag1,stim,stimtype):\n",
    "    ## The first task is to find the stimulus onset times for each whisker in each sweep in each direction\n",
    "    start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "    starts = (where(start_and_stops==1)[0]-2999)/float(sampling_freq) # time in seconds\n",
    "    stops = (where(start_and_stops==-1)[0]+4110)/float(sampling_freq) # time in seconds\n",
    "    \n",
    "    stim_ret = stim[0:len(stops),:,:]\n",
    "    stimtype_ret = stimtype[0:len(stops)]\n",
    "    \n",
    "    return stim_ret, stimtype_ret, starts, stops\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS PSTH\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildPSTH(stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops) :\n",
    "## The first task is to find the stimulus onset times for each whisker in each sweep in each direction\n",
    "    #stim, stimtype = read_stimulus()\n",
    "    stim = stim[np.where(stimtype=='F')[0], :, :]\n",
    "    starts = starts[np.where(stimtype=='F')[0]]\n",
    "    stops = stops[np.where(stimtype=='F')[0]]\n",
    "    \n",
    "    stimtimes = {}\n",
    "    for w in np.arange(25, dtype='int') :  \n",
    "        timesUP = []\n",
    "        timesDOWN = []\n",
    "        for i in np.arange(len(stim), dtype='int') :\n",
    "            indsUP = (np.where(stim[i, w, :]==1108.8889)[0]-1)[::2]\n",
    "            # This finds all time points where the stim = 1108.8889, because each ramp has two 1108.8889 values\n",
    "            # (on the way up and on the way down) we take every other index using [::2]\n",
    "            timesUP.append(indsUP)\n",
    "            indsDOWN = (np.where(stim[i, w, :]==-1108.8889)[0]-1)[::2]\n",
    "            # This finds all time points where the stim = -1108.8889, because each ramp has two -1108.8889 values\n",
    "            # (on the way up and on the way down) we take every other index using [::2]\n",
    "            timesDOWN.append(indsDOWN)\n",
    "        stimtimes[w] = timesUP, timesDOWN # stimtimes[whisker][0][:]=UP stimtimes[whisker][1][:]=DOWN\n",
    "    \n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    hist_inds = {}\n",
    "    PSTH_spike_counts = {}\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in Spikes.keys(): \n",
    "        PSTH_spike_counts[neuron], hist_inds[neuron] = PSTH_spikes(stim, stimtype, stimtimes, Spikes[neuron].spike_times, sampling_freq, t_before, t_after, starts, stops)\n",
    "    \n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "def PSTH_spikes(stimulation, stimtype, stimtimes, spikes, samp, t_before, t_after, starts, stops):\n",
    "    \"\"\"\n",
    "    stimulation   : a list of numpy arrays with a n*t stimulus inside\n",
    "    stimtimes     : a list of the times the stimulus occurred for each whisker \n",
    "    spikes        : an array that contains the spike times (s)\n",
    "    Vtag1         : synchronises stimulus with spike times\n",
    "    samp          : sampling rate of the stimulation (Hz)\n",
    "    t_before      : duration before the stim (positive, s)\n",
    "    t_after       : duration after the stim (positive, s)\n",
    "    starts        : the start of the F sweeps\n",
    "    stops         : the stops of the F sweeps\n",
    "    \"\"\"\n",
    "    \n",
    "    stim_samp = 1/.0009997575757\n",
    "    \n",
    "    PSTH_spike_counts = {}\n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(len(stimtimes[w][0][i]), dtype='int') :  # we must look at the number of stimulations per whisker per stimulation block and this is no longer 4        \n",
    "                timesUP = starts[i] + stimtimes[w][0][i][x]/stim_samp # stimtimes is now stimtimes[whisker][0 for UP, 1 for DOWN][stimsweep][trial]\n",
    "                spikecountsup += len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)]) # count spikes that are within PSTH window of stimtimes\n",
    "            for y in np.arange(len(stimtimes[w][1][i]), dtype='int') : # for the DOWN stimuli we must have a separate loop because they also are now randomly distributed and not 4\n",
    "                timesDOWN = starts[i] + stimtimes[w][1][i][y]/stim_samp                \n",
    "                spikecountsdown += len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "        PSTH_spike_counts[w] = spikecountsup, spikecountsdown\n",
    "    \n",
    "    hist_inds = {} #same changes for this block, each loop will change length depending on how many stimulations fall in a sweep\n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        hist_inds[w] = np.zeros(PSTH_spike_counts[w][0]), np.zeros(PSTH_spike_counts[w][1])\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(len(stimtimes[w][0][i]), dtype='int') :     # dynamic loop depends on how many stims fall in sweep      \n",
    "                timesUP = starts[i] + stimtimes[w][0][i][x]/stim_samp\n",
    "                spikecountup = len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)])\n",
    "                spikeidxup = spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)]\n",
    "                spikeidxup = np.around((spikeidxup - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                hist_inds[w][0][spikecountsup:(spikecountsup+spikecountup)] = spikeidxup-stimtimes[w][0][i][x]\n",
    "                spikecountsup += spikecountup\n",
    "            \n",
    "            for y in np.arange(len(stimtimes[w][1][i]), dtype='int') :     # dynamic loop depends on how many stims fall in sweep\n",
    "                timesDOWN = starts[i] + stimtimes[w][1][i][y]/stim_samp                \n",
    "                spikecountdown = len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "                spikeidxdown = spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)]\n",
    "                spikeidxdown = np.around((spikeidxdown - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                hist_inds[w][1][spikecountsdown:(spikecountsdown+spikecountdown)] = spikeidxdown-stimtimes[w][1][i][y]\n",
    "                spikecountsdown += spikecountdown\n",
    "                \n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "def GetWhiskers(histdata, t_before, t_after, thresh,activity,chancelevel,start_win,end_win) :\n",
    "    STC_on = {}\n",
    "    PW = {}\n",
    "    ActMod2={}\n",
    "    ActModout={}\n",
    "    \n",
    "    stim_samp = 1/.0009997575757 \n",
    "    before_index = int(np.around(t_before*stim_samp)) \n",
    "    after_index = int(np.around(t_after*stim_samp)) \n",
    "    bins = before_index + after_index\n",
    "    \n",
    "    for neuron in histdata.keys() :\n",
    "        ActMod = np.zeros(25)\n",
    "        Countinout = np.zeros(25)\n",
    "        Count=np.zeros(25)\n",
    "        SHARP = np.zeros(25)\n",
    "        for i in np.arange(25, dtype='int') :\n",
    "            after = 0\n",
    "            before = 0\n",
    "            countin = 0\n",
    "            countout =0\n",
    "            \n",
    "            for j in np.arange(len(histdata[neuron][i][0]), dtype='int') :\n",
    "                if histdata[neuron][i][0][j]>start_win-1 and histdata[neuron][i][0][j]<end_win : \n",
    "                    after+=1                              #conunt spikes in 30ms timewindow after stimulus\n",
    "                    countin += 1\n",
    "                elif histdata[neuron][i][0][j]<start_win :                \n",
    "                    before+=1                             #conunt spikes in 20ms timewindow befor stimulus\n",
    "                    countout += 1\n",
    "            for j in np.arange(len(histdata[neuron][i][1]), dtype='int') :\n",
    "                if histdata[neuron][i][1][j]>start_win-1 and histdata[neuron][i][1][j]<end_win :\n",
    "                    after+=1                              \n",
    "                    countin += 1\n",
    "                elif histdata[neuron][i][1][j]<start_win-1:\n",
    "                    before+=1\n",
    "                    countout += 1\n",
    "            if (after+before)==0 :\n",
    "                before=1\n",
    "            elif (after)>activity : \n",
    "                ActMod[i]= (  after*(before_index+start_win) - before*(end_win-start_win)  ) / (  after*(before_index+start_win) + before*(end_win-start_win)  )   #weight different time windows\n",
    "                Countinout[i] = countin/(countout+1)\n",
    "                condition1 = where((histdata[neuron][i][0]<20)*(histdata[neuron][i][0]>5))\n",
    "                condition2 = where((histdata[neuron][i][1]<20)*(histdata[neuron][i][1]>5))\n",
    "                SHARP[i] = sum( histdata[neuron][i][0][ condition1 ] ) + sum( histdata[neuron][i][1][condition2] )\n",
    "            else :\n",
    "                ActMod[i]=0               \n",
    "            Count[i]=countin+countout\n",
    "            \n",
    "        ActModout[neuron]=ActMod\n",
    "        ActMod2[neuron]=ActMod*Countinout*SHARP\n",
    "        STC_on[neuron] = (ActMod>thresh)*(Count/sum(Count)>chancelevel)\n",
    "        PW[neuron] = np.where(ActMod2[neuron]==max(ActMod2[neuron]))[0][0]\n",
    "        if size(np.where(STC_on[neuron]==True))==0:\n",
    "            PW[neuron]= 20\n",
    "        \n",
    "        \n",
    "    return STC_on,PW, ActModout,ActMod2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAYING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY PSTH \n",
    "#----------------------------------------------------------------------------------------\n",
    "# Plot a single neuron PSTH, 25 piezos\n",
    "def display_PSTH(expe,histdata, counts, t_before, t_after,fig,inner_grid,neuron,numspikesP,numspikesN,STC_on,PW) :\n",
    "    stim_samp = 1/.0009997575757 \n",
    "    before_index = int(np.around(t_before*stim_samp)) # indexes\n",
    "    after_index = int(np.around(t_after*stim_samp)) # indexes\n",
    "    histlength = before_index + after_index + 1\n",
    "    \n",
    "    nup = np.zeros((25,histlength-1))\n",
    "    ndown = np.zeros((25,histlength-1))\n",
    "    \n",
    "    fig2 = figure()\n",
    "    ax = fig2.add_subplot(1,1,1)\n",
    "    for i in range(25) :\n",
    "        if histdata[i][0].size :\n",
    "            n1, bins, patches = ax.hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength))\n",
    "            nup[i,:] = n1\n",
    "            close()\n",
    "        if histdata[i][1].size :\n",
    "            n2=2\n",
    "            n2, bins, patches = ax.hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength))\n",
    "            ndown[i,:] = n2\n",
    "            close()\n",
    "    normnum = (1/np.sum(nup+ndown))\n",
    "    height = np.max(np.array([np.max(nup), np.max(ndown)]))/(1/normnum)\n",
    "        \n",
    "    clf()\n",
    "    for j in range(25) : #I use a dummy variable to sort whisker problems in exp23\n",
    "        i=j\n",
    "        if i == 0 :\n",
    "            #ax1 = subplot(5,5,1, frame_on=False)\n",
    "            ax1 = Subplot(fig, inner_grid[i])     \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        elif i==20:\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.spines['right'].set_linewidth(0.3)\n",
    "            ax1.spines['top'].set_linewidth(0.3)\n",
    "            ax1.spines['left'].set_linewidth(0.3)\n",
    "            ax1.spines['bottom'].set_linewidth(0.3)\n",
    "            \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        else :\n",
    "            #subplot(5,5,i+1,sharex=ax1,sharey=ax1,frame_on=False)\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        \n",
    "        #-------------------------------------------------------\n",
    "        #-------------------------------------------------------\n",
    "        #for whisker problems\n",
    "        #-------------------------------------------------------\n",
    "        #Only for EXP 23: I shift first row to the left and leave A4 empty\n",
    "        if expe == 23:\n",
    "            if j<4: i=j+1\n",
    "            elif j==4: continue\n",
    "            elif j>4:i=j\n",
    "        #-------------------------------------------------------\n",
    "        #Only for EXP 27: D1 whisker missing\n",
    "        if expe == 27:     \n",
    "            if j==16: continue\n",
    "        #-------------------------------------------------------\n",
    "        #-------------------------------------------------------\n",
    "                        \n",
    "        if PW==i:\n",
    "            ax1.set_axis_bgcolor('#dddddd')    \n",
    "        elif i!=20:\n",
    "            ax1.spines['right'].set_visible(False)\n",
    "            ax1.spines['top'].set_visible(False)\n",
    "            ax1.spines['left'].set_visible(False)\n",
    "            ax1.spines['bottom'].set_visible(False)\n",
    "        if STC_on[i]== True:\n",
    "            ax1.set_axis_bgcolor('#dddddd')    \n",
    "                        \n",
    "        \n",
    "        if histdata[i][1].size :\n",
    "            ax1.hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength), color='g', alpha=1.0, edgecolor='none', histtype='stepfilled', label='Pos', weights=np.repeat(normnum, len(histdata[i][1])))\n",
    "        if histdata[i][0].size :\n",
    "            ax1.hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength), color='b', alpha=0.7, edgecolor='none', histtype='stepfilled', label='Neg', weights=np.repeat(normnum, len(histdata[i][0]))) \n",
    "        #if (histdata[i][0].size) or (histdata[i][1].size) :\n",
    "        xlim(-before_index, after_index)\n",
    "        ax1.axvline(0, color = 'r', linewidth=1)\n",
    "        ax1.axhline(0, color = 'r', linewidth=2)\n",
    "        ymax = 1.02 * height\n",
    "        ylim(0, ymax)\n",
    "        xvals = np.array([0,10,20,30])\n",
    "        yvals = np.array([0,ymax*0.9,ymax*0.9,0])\n",
    "        ax1.plot(xvals, yvals, linewidth=0.2,color = (0.75,0.75,0.75))\n",
    "        if i==4: ax1.set_title('ymax =' + str( np.around(height,decimals = 3) ),fontsize=8)\n",
    "        if i ==1: ax1.set_title('Nrn' + str(neuron) + '_Pos' + str(int(numspikesP))+ '_Neg' + str(int(numspikesN)),fontsize=9)\n",
    "        \n",
    "        fig.add_subplot(ax1)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "def display_all_PSTHs_of_recording(expe,histdata, counts, pdf_files_directory, t_before, t_after,grupete,STC_on,PW,titles) :\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(histdata.keys())\n",
    "    if nrns <16: \n",
    "        layout = [5,3]\n",
    "    else: layout = [nrns//3+(nrns%3!=0),3]\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.1, hspace=0.2)\n",
    "    \n",
    "    ii=0\n",
    "    orderneurons = np.sort(list(histdata.keys()))\n",
    "    for neuron in  orderneurons:\n",
    "        clf()\n",
    "        totalup = 0\n",
    "        totaldown = 0\n",
    "        for i in np.arange(25, dtype='int') :\n",
    "            totalup+=counts[neuron][i][0]\n",
    "            totaldown+=counts[neuron][i][1]\n",
    "            \n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(5,5,subplot_spec=outer_grid[ii], wspace=0.1, hspace=0.1)\n",
    "               \n",
    "        numspikesP= totalup                  \n",
    "        numspikesN= totaldown\n",
    "        display_PSTH(expe,histdata[neuron], counts[neuron], t_before, t_after,fig,inner_grid,neuron,numspikesP,numspikesN,STC_on[neuron],PW[neuron])                               \n",
    "        \n",
    "        if grupete ==1:\n",
    "            fig.suptitle(titles + '_multiunits',fontsize=16)\n",
    "        elif grupete ==3:\n",
    "            fig.suptitle(titles + '_responsiveMULTIUNITS',fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(titles ,fontsize=16)\n",
    "        \n",
    "        ii+=1\n",
    "    if grupete ==1:                  \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_multi.pdf', format='pdf')\n",
    "    elif grupete==3:\n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_respMULTI.pdf', format='pdf')\n",
    "    else:        \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist.pdf', format='pdf')\n",
    "        \n",
    "    clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell you put all the information to make the code portable from computer to computer\n",
    "# You have to place all the file names and experiments, then you loop whichever you want to analyse\n",
    "#--------------------------------------------------------------------------------\n",
    "#Experiment numbers\n",
    "ExpeNum = [23,24,25,26,27,28,29,30,31,32]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders for measurements and experiments (this is how we separate shanks in folders for individual analyses)\n",
    "m164 = ['m1s1','m1s2','m1s3','m1s4','m1s5','m1s6','m1s7','m1s8']\n",
    "m264 = ['m2s1','m2s2','m2s3','m2s4','m2s5','m2s6','m2s7','m2s8']\n",
    "m364 = ['m3s1','m3s2','m3s3','m3s4','m3s5','m3s6','m3s7','m3s8']\n",
    "m464 = ['m4s1','m4s2','m4s3','m4s4','m4s5','m4s6','m4s7','m4s8']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Kwik files    \n",
    "files23 = [ 'MEAS-151027-1_ele01_ele08.kwik',\n",
    "            'MEAS-151027-1_ele09_ele16.kwik',\n",
    "            'MEAS-151027-1_ele17_ele24.kwik',\n",
    "            'MEAS-151027-1_ele25_ele32.kwik',\n",
    "            'MEAS-151027-1_ele33_ele40.kwik',\n",
    "            'MEAS-151027-1_ele41_ele48.kwik',\n",
    "            'MEAS-151027-1_ele49_ele56.kwik',\n",
    "            'MEAS-151027-1_ele57_ele64.kwik',\n",
    "            'MEAS-151027-2_ele01_ele08.kwik',\n",
    "            'MEAS-151027-2_ele09_ele16.kwik',\n",
    "            'MEAS-151027-2_ele17_ele24.kwik',\n",
    "            'MEAS-151027-2_ele25_ele32.kwik',\n",
    "            'MEAS-151027-2_ele33_ele40.kwik',\n",
    "            'MEAS-151027-2_ele41_ele48.kwik',\n",
    "            'MEAS-151027-2_ele49_ele56.kwik',\n",
    "            'MEAS-151027-2_ele57_ele64.kwik']\n",
    "\n",
    "files24 = ['MEAS-151103-1_EXTRACTED_ele25_ele32.kwik',\n",
    "           'MEAS-151103-1_EXTRACTED_ele33_ele40.kwik',\n",
    "           'MEAS-151103-1_EXTRACTED_ele41_ele48.kwik',\n",
    "           'MEAS-151103-1_EXTRACTED_ele49_ele56.kwik',\n",
    "           'MEAS-151103-1_EXTRACTED_ele57_ele64.kwik',\n",
    "           'MEAS-151103-2_ele33_ele40.kwik',\n",
    "           'MEAS-151103-2_ele41_ele48.kwik',\n",
    "           'MEAS-151103-2_ele49_ele56.kwik',\n",
    "           'MEAS-151103-2_ele57_ele64.kwik']\n",
    "\n",
    "files25 = [ 'MEAS-151105-1good_ele01_ele08.kwik',\n",
    "            'MEAS-151105-1good_ele09_ele16.kwik',\n",
    "            'MEAS-151105-1good_ele17_ele24.kwik',\n",
    "            'MEAS-151105-1good_ele25_ele32.kwik',\n",
    "            'MEAS-151105-1good_ele33_ele40.kwik',\n",
    "            'MEAS-151105-1good_ele41_ele48.kwik',\n",
    "            'MEAS-151105-1good_ele49_ele56.kwik',\n",
    "            'MEAS-151105-1good_ele57_ele64.kwik',\n",
    "            'MEAS-151105-2_ele01_ele08.kwik',\n",
    "            'MEAS-151105-2_ele09_ele16.kwik',\n",
    "            'MEAS-151105-2_ele17_ele24.kwik',\n",
    "            'MEAS-151105-2_ele25_ele32.kwik',\n",
    "            'MEAS-151105-2_ele33_ele40.kwik',\n",
    "            'MEAS-151105-2_ele41_ele48.kwik',\n",
    "            'MEAS-151105-2_ele49_ele56.kwik',\n",
    "            'MEAS-151105-2_ele57_ele64.kwik']\n",
    "\n",
    "files26 = [ 'MEAS-151110-1_ele01_ele08.kwik',\n",
    "            'MEAS-151110-1_ele09_ele16.kwik',\n",
    "            'MEAS-151110-1_ele17_ele24.kwik',\n",
    "            'MEAS-151110-1_ele25_ele32.kwik',\n",
    "            'MEAS-151110-1_ele33_ele40.kwik',\n",
    "            'MEAS-151110-1_ele41_ele48.kwik',\n",
    "            'MEAS-151110-1_ele49_ele56.kwik',\n",
    "            'MEAS-151110-1_ele57_ele64.kwik',\n",
    "            'MEAS-151110-2_ele01_ele08.kwik',\n",
    "            'MEAS-151110-2_ele09_ele16.kwik',\n",
    "            'MEAS-151110-2_ele17_ele24.kwik',\n",
    "            'MEAS-151110-2_ele25_ele32.kwik',\n",
    "            'MEAS-151110-2_ele33_ele40.kwik',\n",
    "            'MEAS-151110-2_ele41_ele48.kwik',\n",
    "            'MEAS-151110-2_ele49_ele56.kwik',\n",
    "            'MEAS-151110-2_ele57_ele64.kwik',\n",
    "            'MEAS-151110-3_ele01_ele08.kwik',\n",
    "            'MEAS-151110-3_ele09_ele16.kwik',\n",
    "            'MEAS-151110-3_ele17_ele24.kwik',\n",
    "            'MEAS-151110-3_ele25_ele32.kwik',\n",
    "            'MEAS-151110-3_ele33_ele40.kwik',\n",
    "            'MEAS-151110-3_ele41_ele48.kwik',\n",
    "            'MEAS-151110-3_ele49_ele56.kwik',\n",
    "            'MEAS-151110-3_ele57_ele64.kwik']\n",
    "\n",
    "files27  = ['MEAS-151112-1_ele01_ele08.kwik',\n",
    "            'MEAS-151112-1_ele09_ele16.kwik',\n",
    "            'MEAS-151112-1_ele17_ele24.kwik',\n",
    "            'MEAS-151112-1_ele25_ele32.kwik',\n",
    "            'MEAS-151112-1_ele33_ele40.kwik',\n",
    "            'MEAS-151112-1_ele41_ele48.kwik',\n",
    "            'MEAS-151112-1_ele49_ele56.kwik',\n",
    "            'MEAS-151112-1_ele57_ele64.kwik',\n",
    "            'MEAS-151112-2_ele01_ele08.kwik',\n",
    "            'MEAS-151112_2_ele09_ele16.kwik',\n",
    "            'MEAS-151112-2_ele17_ele24.kwik',\n",
    "            'MEAS-151112-2_ele25_ele32.kwik',\n",
    "            'MEAS-151112-2_ele33_ele40.kwik',\n",
    "            'MEAS-151112-2_ele41_ele48.kwik',\n",
    "            'MEAS-151112-2_ele49_ele56.kwik',\n",
    "            'MEAS-151112-2_ele57_ele64.kwik',\n",
    "            'MEAS-151112-3_ele01_ele08.kwik',\n",
    "            'MEAS-151112-3_ele09_ele16.kwik',\n",
    "            'MEAS-151112-3_ele17_ele24.kwik',\n",
    "            'MEAS-151112-3_ele25_ele32.kwik',\n",
    "            'MEAS-151112-3_ele33_ele40.kwik',\n",
    "            'MEAS-151112-3_ele41_ele48.kwik',\n",
    "            'MEAS-151112-3_ele49_ele56.kwik',\n",
    "            'MEAS-151112-3_ele57_ele64.kwik']\n",
    "\n",
    "files28 =  ['MEAS-151116-1_ele01_ele08.kwik',\n",
    "            'MEAS-151116-1_ele09_ele16.kwik',\n",
    "            'MEAS-151116-1_ele17_ele24.kwik',\n",
    "            'MEAS-151116-1_ele25_ele32.kwik',\n",
    "            'MEAS-151116-1_ele33_ele40.kwik',\n",
    "            'MEAS-151116-1_ele41_ele48.kwik',\n",
    "            'MEAS-151116-1_ele49_ele56.kwik',\n",
    "            'MEAS-151116-1_ele57_ele64.kwik',\n",
    "            'MEAS-151116-2_ele01_ele08.kwik',\n",
    "            'MEAS-151116-2_ele09_ele16.kwik',\n",
    "            'MEAS-151116-2_ele17_ele24.kwik',\n",
    "            'MEAS-151116-2_ele25_ele32.kwik',\n",
    "            'MEAS-151116-2_ele33_ele40.kwik',\n",
    "            'MEAS-151116-2_ele41_ele48.kwik',\n",
    "            'MEAS-151116-2_ele49_ele56.kwik',\n",
    "            'MEAS-151116-2_ele57_ele64.kwik',\n",
    "            'MEAS-151116-3_ele01_ele08.kwik',\n",
    "            'MEAS-151116-3_ele09_ele16.kwik',\n",
    "            'MEAS-151116-3_ele17_ele24.kwik',\n",
    "            'MEAS-151116-3_ele25_ele32.kwik',\n",
    "            'MEAS-151116-3_ele33_ele40.kwik',\n",
    "            'MEAS-151116-3_ele41_ele48.kwik',\n",
    "            'MEAS-151116-3_ele49_ele56.kwik',\n",
    "            'MEAS-151116-3_ele57_ele64.kwik']\n",
    "\n",
    "files29  = ['MEAS-151118-1_ele01_ele08.kwik',\n",
    "            'MEAS-151118-1_ele09_ele16.kwik',\n",
    "            'MEAS-151118-1_ele17_ele24.kwik',\n",
    "            'MEAS-151118-1_ele25_ele32.kwik',\n",
    "            'MEAS-151118-1_ele33_ele40.kwik',\n",
    "            'MEAS-151118-1_ele41_ele48.kwik',\n",
    "            'MEAS-151118-1_ele49_ele56.kwik',\n",
    "            'MEAS-151118-1_ele57_ele64.kwik',\n",
    "            'MEAS-151118-2_ele01_ele08.kwik',\n",
    "            'MEAS-151118-2_ele09_ele16.kwik',\n",
    "            'MEAS-151118-2_ele17_ele24.kwik',\n",
    "            'MEAS-151118-2_ele25_ele32.kwik',\n",
    "            'MEAS-151118-2_ele33_ele40.kwik',\n",
    "            'MEAS-151118-2_ele41_ele48.kwik',\n",
    "            'MEAS-151118-2_ele49_ele56.kwik',\n",
    "            'MEAS-151118-2_ele57_ele64.kwik',\n",
    "            'MEAS-151118-3_ele01_ele08.kwik',\n",
    "            'MEAS-151118-3_ele09_ele16.kwik',\n",
    "            'MEAS-151118-3_ele17_ele24.kwik',\n",
    "            'MEAS-151118-3_ele25_ele32.kwik',\n",
    "            'MEAS-151118-3_ele33_ele40.kwik',\n",
    "            'MEAS-151118-3_ele41_ele48.kwik',\n",
    "            'MEAS-151118-3_ele49_ele56.kwik',\n",
    "            'MEAS-151118-3_ele57_ele64.kwik']\n",
    "\n",
    "\n",
    "files30  = ['MEAS-151208-2_ele01_ele08.kwik',\n",
    "            'MEAS-151208-2_ele09_ele16.kwik',\n",
    "            'MEAS-151208-2_ele17_ele24.kwik',\n",
    "            'MEAS-151208-2_ele25_ele32.kwik',\n",
    "            'MEAS-151208-2_ele33_ele40.kwik',\n",
    "            'MEAS-151208-2_ele41_ele48.kwik',\n",
    "            'MEAS-151208-2_ele49_ele56.kwik',\n",
    "            'MEAS-151208-2_ele57_ele64.kwik',\n",
    "            'MEAS-151208-3_ele01_ele08.kwik',\n",
    "            'MEAS-151208-3_ele09_ele16.kwik',\n",
    "            'MEAS-151208-3_ele17_ele24.kwik',\n",
    "            'MEAS-151208-3_ele25_ele32.kwik',\n",
    "            'MEAS-151208-3_ele33_ele40.kwik',\n",
    "            'MEAS-151208-3_ele41_ele48.kwik',\n",
    "            'MEAS-151208-3_ele49_ele56.kwik',\n",
    "            'MEAS-151208-3_ele57_ele64.kwik',\n",
    "            'MEAS-151208-4_ele01_ele08.kwik',\n",
    "            'MEAS-151208-4_ele09_ele16.kwik',\n",
    "            'MEAS-151208-4_ele17_ele24.kwik',\n",
    "            'MEAS-151208-4_ele25_ele32.kwik',\n",
    "            'MEAS-151208-4_ele33_ele40.kwik',\n",
    "            'MEAS-151208-4_ele41_ele48.kwik',\n",
    "            'MEAS-151208-4_ele49_ele56.kwik',\n",
    "            'MEAS-151208-4_ele57_ele64.kwik',\n",
    "            'MEAS-151208-5_ele01_ele08.kwik',\n",
    "            'MEAS-151208-5_ele09_ele16.kwik',\n",
    "            'MEAS-151208-5_ele17_ele24.kwik',\n",
    "            'MEAS-151208-5_ele25_ele32.kwik',\n",
    "            'MEAS-151208-5_ele33_ele40.kwik',\n",
    "            'MEAS-151208-5_ele41_ele48.kwik',\n",
    "            'MEAS-151208-5_ele49_ele56.kwik',\n",
    "            'MEAS-151208-5_ele57_ele64.kwik']\n",
    "\n",
    "\n",
    "files31 = [ 'MEAS-151210-1_ele01_ele08.kwik',\n",
    "            'MEAS-151210-1_ele09_ele16.kwik',\n",
    "            'MEAS-151210-1_ele17_ele24.kwik',\n",
    "            'MEAS-151210-1_ele25_ele32.kwik',\n",
    "            'MEAS-151210-1_ele33_ele40.kwik',\n",
    "            'MEAS-151210-1_ele41_ele48.kwik',\n",
    "            'MEAS-151210-1_ele49_ele56.kwik',\n",
    "            'MEAS-151210-1_ele57_ele64.kwik',\n",
    "            'MEAS-151210-2_ele01_ele08.kwik',\n",
    "            'MEAS-151210-2_ele09_ele16.kwik',\n",
    "            'MEAS-151210-2_ele17_ele24.kwik',\n",
    "            'MEAS-151210-2_ele25_ele32.kwik',\n",
    "            'MEAS-151210-2_ele33_ele40.kwik',\n",
    "            'MEAS-151210-2_ele41_ele48.kwik',\n",
    "            'MEAS-151210-2_ele49_ele56.kwik',\n",
    "            'MEAS-151210-2_ele57_ele64.kwik',\n",
    "            'MEAS-151210-3_ele01_ele08.kwik',\n",
    "            'MEAS-151210-3_ele09_ele16.kwik',\n",
    "            'MEAS-151210-3_ele17_ele24.kwik',\n",
    "            'MEAS-151210-3_ele25_ele32.kwik',\n",
    "            'MEAS-151210-3_ele33_ele40.kwik',\n",
    "            'MEAS-151210-3_ele41_ele48.kwik',\n",
    "            'MEAS-151210-3_ele49_ele56.kwik',\n",
    "            'MEAS-151210-3_ele57_ele64.kwik']\n",
    "\n",
    "files32 = [ 'MEAS-151214-1_ele01_ele08.kwik',\n",
    "            'MEAS-151214-1_ele09_ele16.kwik',\n",
    "            'MEAS-151214-1_ele17_ele24.kwik',\n",
    "            'MEAS-151214-1_ele25_ele32.kwik',\n",
    "            'MEAS-151214-1_ele33_ele40.kwik',\n",
    "            'MEAS-151214-2_ele01_ele08.kwik',\n",
    "            'MEAS-151214-2_ele09_ele16.kwik',\n",
    "            'MEAS-151214-2_ele17_ele24.kwik',\n",
    "            'MEAS-151214-2_ele25_ele32.kwik',\n",
    "            'MEAS-151214-2_ele33_ele40.kwik']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------\n",
    "# Here I create my dictionary of experiments\n",
    "Expe={}\n",
    "Vtags={}\n",
    "Stim={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "    Vtags[num] = dict()\n",
    "i=0    \n",
    "for meas in np.append(m164,m264):\n",
    "    Expe[23][meas] = files23[i]\n",
    "    Expe[25][meas] = files25[i]\n",
    "    i+=1\n",
    "i=0\n",
    "for meas in np.append(m164[3:8],m264[4:8]):    \n",
    "    Expe[24][meas] = files24[i]\n",
    "    i+=1\n",
    "i=0\n",
    "for meas in np.append(np.append(m164,m264),m364):\n",
    "    Expe[26][meas] = files26[i]\n",
    "    Expe[27][meas] = files27[i]\n",
    "    Expe[28][meas] = files28[i]\n",
    "    Expe[29][meas] = files29[i]\n",
    "    Expe[30][meas] = files30[i]\n",
    "    Expe[31][meas] = files31[i]\n",
    "    i+=1\n",
    "i=0\n",
    "for meas in m464:\n",
    "    Expe[30][meas] = files30[i]\n",
    "    i+=1\n",
    "i=0\n",
    "for meas in np.append(m164[0:5],m264[0:5]):\n",
    "    Expe[32][meas] = files32[i]\n",
    "    i+=1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Vtag files \n",
    "Vtags[23] = ['MEAS-151027-1_Vtag1.dat','MEAS-151027-2_Vtag1.dat']\n",
    "Vtags[24] = ['MEAS-151103-1_Vtag1.dat','MEAS-151103-2_Vtag1.dat']\n",
    "Vtags[25] = ['MEAS-151105-1good_Vtag1.dat','MEAS-151105-2_Vtag1.dat']\n",
    "Vtags[26] = ['MEAS-151110-1_Vtag1.dat','MEAS-151110-2_Vtag1.dat','MEAS-151110-3_Vtag1.dat']\n",
    "Vtags[27] = ['MEAS-151112-1_Vtag1.dat','MEAS-151112-2_Vtag1.dat','MEAS-151112-3_Vtag1.dat']\n",
    "Vtags[28] = ['MEAS-151116-1_Vtag1.dat','MEAS-151116-2_Vtag1.dat','MEAS-151116-3_Vtag1.dat']\n",
    "Vtags[29] = ['MEAS-151118-1_Vtag1.dat','MEAS-151118-2_Vtag1.dat','MEAS-151118-3_Vtag1.dat']\n",
    "Vtags[30] = ['MEAS-151208-2_Vtag1.dat','MEAS-151208-3_Vtag1.dat','MEAS-151208-4_Vtag1.dat','MEAS-151208-5_Vtag1.dat']\n",
    "Vtags[31] = ['MEAS-151210-1_Vtag1.dat','MEAS-151210-2_Vtag1.dat','MEAS-151210-3_Vtag1.dat']\n",
    "Vtags[32] = ['MEAS-151214-1_Vtag1.dat','MEAS-151214-2_Vtag1.dat']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Stimulus type\n",
    "for i in range(23,33):\n",
    "    Stim[i] = 'big_STIM_FC_corrected'\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "#Root folder to work in, such all will be in subfolders \n",
    "#e.g.: \"/EXP_23/m1s1/\" for data or \"/STIM/\" for stims\n",
    "rootF = '/home/matias/WORKSPACE/'    \n",
    "stimFolder = rootF +'STIM/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "group: 2\n",
      "m3s7\n",
      "10:20:37 [W] The `.kwx` file hasn't been found. Features and masks won't be available.\n",
      "10:20:37 [W] Could not find any data source for traces (raw.kwd or .dat or .bin.) Waveforms and traces will not be available.\n",
      "   reading stim at: m3s7\n",
      "   trimming stim at: m3s7\n",
      "   building psths\n",
      "   finding PW and ON whiskers\n",
      "   plotting\n",
      "m3s8\n",
      "10:21:50 [W] The `.kwx` file hasn't been found. Features and masks won't be available.\n",
      "10:21:50 [W] Could not find any data source for traces (raw.kwd or .dat or .bin.) Waveforms and traces will not be available.\n",
      "   building psths\n",
      "   finding PW and ON whiskers\n",
      "   plotting\n",
      "group: 3\n",
      "m3s7\n",
      "10:22:36 [W] The `.kwx` file hasn't been found. Features and masks won't be available.\n",
      "10:22:36 [W] Could not find any data source for traces (raw.kwd or .dat or .bin.) Waveforms and traces will not be available.\n",
      "m3s8\n",
      "10:22:36 [W] The `.kwx` file hasn't been found. Features and masks won't be available.\n",
      "10:22:36 [W] Could not find any data source for traces (raw.kwd or .dat or .bin.) Waveforms and traces will not be available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14a0dc9ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [28]   #Expe                                        #select experiment numbers!\n",
    "grupete = [2,3]   #select cluster groups! 2 for good clusters 1 for multiunits, 3 for unsorted\n",
    "\n",
    "#select measurement and/or shanks!\n",
    "Measurements = m364[6:8]           #['m1s1']#['m3s1','m3s3']#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']   \n",
    "\n",
    "#select type of stimuli, for PSTH is only 'F' and this does not change anything\n",
    "choices = ['F','C','U']                      #select stimulus type (for STA and STC)\n",
    "\n",
    "# choice code not to ploteverything at the same time\n",
    "ploteo = [1,0,0,0]                                           #1 to make plots: psth,sta,ufc,stc\n",
    "\n",
    "dirs =[]\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "last_exp=0     #we use this to load stim only when we change experiment\n",
    "for expe in SelExp:\n",
    "    \n",
    "    #Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    print(expe)\n",
    "\n",
    "    #This two lines are to account for diffrerent stims when looping diffrerent experiments\n",
    "    binname= stimFolder + Stim[expe] + '/Stimulus_UCC.bin'     \n",
    "    textname=stimFolder + Stim[expe] + '/Stimulus_UCC.txt'\n",
    "    \n",
    "    last_meas =0   #we use this to find when we change measurement to load Vtag and stim again\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits, multiunits, unsorted...\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits 3 for unsorted\n",
    "        #folder names\n",
    "        if group ==3:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFallRM/EXP_'+str(expe),rootF + 'OUTPUT/PDFallRM/STC/EXP_'+str(expe)]\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFall/EXP_'+str(expe),rootF + 'OUTPUT/PDFall/STC/EXP_'+str(expe)]\n",
    "        if group ==1:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFallM/EXP_'+str(expe),rootF + 'OUTPUT/PDFallM/STC/EXP_'+str(expe)]\n",
    "        print('group:', group)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        measurements = Expe[expe]                            \n",
    "                 \n",
    "        for meas in Measurements:           \n",
    "            print(meas)\n",
    "            current_meas = int(meas[1])   #measurement number\n",
    "            #---------------------------------------------------------------\n",
    "            #select datafile\n",
    "            sp_file = rootF + 'EXP_' + str(expe) +'/Spike_Sorting/'+ meas +'/'+ measurements[meas]\n",
    "            #load datafile\n",
    "            Spikes, sampling_freq = readkwikinfo(sp_file, group)  \n",
    "            #---------------------------------------------------------------\n",
    "            #load stimulus if looping new experiment, without trimming\n",
    "            if expe!=last_exp:\n",
    "                stimraw = []\n",
    "                stimtyperaw=[]\n",
    "                print(\"   reading stim at:\",  meas)\n",
    "                stimraw,stimtyperaw = read_stimulus(expe,meas)\n",
    "\n",
    "            #---------------------------------------------------------------\n",
    "            #load Vtag if looping new measurement\n",
    "            if (last_meas!=current_meas): #or (expe!=last_exp):   \n",
    "                # get Vtag name\n",
    "                measV=int(meas[1])-1\n",
    "                bin_file = rootF + 'EXP_' + str(expe) +'/' + Vtags[expe][measV]\n",
    "                #-----------------------------------------------------------\n",
    "                Vtag1 =[]                \n",
    "                Vtag1 = np.fromfile(file=bin_file, dtype=np.int16)\n",
    "                # here we trim down stim and stimtype from Vtag1 information\n",
    "                print(\"   trimming stim at:\", meas)\n",
    "                stim = []\n",
    "                stimtype=[]\n",
    "                stim, stimtype,starts, stops = readVtag(Vtag1,stimraw,stimtyperaw)\n",
    "                                          \n",
    "            last_meas = current_meas     #update measurement variable\n",
    "            last_exp = expe              #update experiment variable\n",
    "            \n",
    "            if len(Spikes.keys())>0:                              #do only if there are clusters\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #create output folders\n",
    "                for dir in dirs:\n",
    "                    if not os.path.exists(dir):\n",
    "                        os.makedirs(dir) \n",
    "                dire = dirs[0] +'/'\n",
    "                titles = 'Exp'+ str(expe) + '_Meas_' + meas[1] + '_Shank_' + meas[3]\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Build PSTHs\n",
    "                t_before = .005  \n",
    "                t_after = .060\n",
    "                \n",
    "                start_win=10  #10\n",
    "                end_win=60\n",
    "                \n",
    "                thresh = 0.3#0.37      #Act mod activity between 10,45ms and -10,10 ms (from -1 to 1)\n",
    "                activity = 40#40        #minimun amount of activity to get an active whisker from 10 to 45ms\n",
    "                chancelevel = 1/25*1.40 #1/25*1.4   #how much activity above chance in response area (10-45ms)\n",
    "                \n",
    "                print('   building psths')\n",
    "                PSTH_spikes_counts, hist_output = BuildPSTH(stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops)\n",
    "                print('   finding PW and ON whiskers')\n",
    "                STC_on, PW ,ActMod,ActMod2= GetWhiskers(hist_output, t_before, t_after, thresh,activity,chancelevel,start_win,end_win)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot PSTH\n",
    "                print('   plotting')\n",
    "                if ploteo[0]==1: display_all_PSTHs_of_recording(expe,hist_output, PSTH_spikes_counts, dire, t_before, t_after,group,STC_on,PW,titles)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PW[55]\n",
    "STC_on[55]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
