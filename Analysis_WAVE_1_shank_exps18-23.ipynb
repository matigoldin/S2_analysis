{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#SAVING BINARY OBJECTS DATA\n",
    "#need to automate data folder creation\n",
    "#----------------------------------------------------------------------------------------\n",
    "import pickle \n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO GET WAVE PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "# Grupete stands for cluster groups! 2: good clusters, 1: multiunits, 0: unsorted, 3: noise\n",
    "def readkwikinfo(kwik, grupete=3):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    model.close()\n",
    "    return spikedata, sample_rate\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READ KWIK WAVE INFO\n",
    "def readkwikwaveinfo(wavedata,kwik,expe,meas, grupete=2,samples=48,electrodes=8):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    #sample_rate = model.sample_rate # extract sampling freq\n",
    "    waveforms = model.waveforms\n",
    "    \n",
    "    if wavedata == False: wavedata = dict()\n",
    "    \n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            \n",
    "            wavematrix = AttrDict({'waves': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            wavematrix.update({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "                        \n",
    "            wavematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            \n",
    "            wavematrix.waves = waveforms[(model.spike_clusters==cluster)]\n",
    "                        \n",
    "            #wavematrix.update(AttrDict({'meanwave' : np.zeros([samples,electrodes]), 'stdwave' : np.zeros([samples,electrodes])}))\n",
    "            #wavematrix.meanwave = mean(wavematrix.waves[:,:,:],axis=0)\n",
    "            #wavematrix.stdwave = std(wavematrix.waves[:,:,:],axis=0)\n",
    "            \n",
    "            #parnames, params, electrode,bigwave = Getwaveparams(wavematrix.meanwave)\n",
    "            \n",
    "            #wavematrix.update(AttrDict({'params' : params, 'electrodemax': electrode,'parnames': parnames, 'bigwave' : bigwave}))\n",
    "            \n",
    "            wavematrix.update(AttrDict({'exp' : int(expe) , 'meas': int(meas[1]) , 'shank': int(meas[3])}))\n",
    "                                        #, 'bigwavestd': wavematrix.stdwave[:,electrode]  }))\n",
    "            codename = 'exp'+ str(expe) + '_' +meas + '_c' + str(cluster)\n",
    "            \n",
    "            #Comment to save all waveforms We don't save now for just only having the features\n",
    "            #wavematrix.waves = []\n",
    "                        \n",
    "            wavedata[codename] = wavematrix\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    \n",
    "    model.close()\n",
    "    return \n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "#GET WAVE PARAMS\n",
    "def Getwaveparams(Waves, zero_correct=False):\n",
    "    \n",
    "    #zero correction for putting first sample at 0\n",
    "    if zero_correct: Waves = Waves - Waves[0,:]\n",
    "    \n",
    "    #here I get the minimum of all electrodes\n",
    "    \n",
    "    #here I get the peak to peak maximum\n",
    "    p2p = amax(Waves,0)-amin(Waves,0)\n",
    "       \n",
    "    #here I get the electrode number of biggest waveform\n",
    "    electrode = where(p2p==max(p2p))[0][0]\n",
    "    \n",
    "    #I use the biggest waveform, already corrected for 0\n",
    "    Wave = Waves[:,electrode]\n",
    "    \n",
    "    #I get the minimum\n",
    "    minimo = min(Wave)\n",
    "    \n",
    "    plot(Wave)\n",
    "    plot(arange(48),0*arange(48))\n",
    "\n",
    "    \n",
    "    #I find max and min \n",
    "    minim = where(Wave== minimo)[0][0]\n",
    "    table_max = where(numpy.r_[False, Wave[1:] > Wave[:-1]] & numpy.r_[Wave[:-1] > Wave[1:], False])[0]\n",
    "\n",
    "    peak1 = table_max[0]\n",
    "    peak1val = Wave[peak1]/minimo\n",
    "    if len(table_max)<2:\n",
    "        peak2 = 47   #if there is no second peak, i select the las point\n",
    "        peak2val = Wave[peak2]/minimo\n",
    "    else:\n",
    "        peak2 = table_max[1] \n",
    "        peak2val = Wave[peak2]/minimo\n",
    "    \n",
    "    #relative to minimum\n",
    "    prel1 = peak1 - minim\n",
    "    prel2 = peak2 -minim\n",
    "            \n",
    "    #I find previous index of 0 crossings\n",
    "    table_0d = where(numpy.r_[Wave[1:] <= 0,False] & numpy.r_[Wave[:-1]>0,False])[0]\n",
    "    table_0u = where(numpy.r_[Wave[1:] >= 0,False] & numpy.r_[Wave[:-1]<0,False])[0]\n",
    "    \n",
    "    c1 = table_0d[0]\n",
    "    c2 = table_0u[0]\n",
    "    \n",
    "    #get 0 crossings\n",
    "    cr1 = c1+abs(Wave[c1])/(abs(Wave[c1])+abs(Wave[c1+1]))\n",
    "    cr2 = c2+abs(Wave[c2])/(abs(Wave[c2])+abs(Wave[c2+1]))\n",
    "    #relative to minimum\n",
    "    crel1 = cr1-minim\n",
    "    crel2 = cr2-minim\n",
    "    \n",
    "    #Get the widths\n",
    "    width0 = cr2-cr1\n",
    "    \n",
    "    amp50 = minimo/2\n",
    "    amp25 = minimo/4\n",
    "    \n",
    "    #get the amplitude crossings\n",
    "    table_0d = where(numpy.r_[Wave[1:] <= amp50,False] & numpy.r_[Wave[:-1]>amp50,False])[0]\n",
    "    table_0u = where(numpy.r_[Wave[1:] >= amp50,False] & numpy.r_[Wave[:-1]<amp50,False])[0]\n",
    "        \n",
    "    c1 = table_0d[0]\n",
    "    c2 = table_0u[0]\n",
    "    \n",
    "    cross1 = c1+abs(Wave[c1])/(abs(Wave[c1])+abs(Wave[c1+1]))\n",
    "    cross2 = c2+abs(Wave[c2])/(abs(Wave[c2])+abs(Wave[c2+1]))\n",
    "    \n",
    "    width50 = cross2-cross1\n",
    "    #---------------------------------\n",
    "    \n",
    "    table_0d = where(numpy.r_[Wave[1:] <= amp25,False] & numpy.r_[Wave[:-1]>amp25,False])[0]\n",
    "    table_0u = where(numpy.r_[Wave[1:] >= amp25,False] & numpy.r_[Wave[:-1]<amp25,False])[0]\n",
    "    \n",
    "    c1 = table_0d[0]\n",
    "    c2 = table_0u[0]\n",
    "    \n",
    "    cross1 = c1+abs(Wave[c1])/(abs(Wave[c1])+abs(Wave[c1+1]))\n",
    "    cross2 = c2+abs(Wave[c2])/(abs(Wave[c2])+abs(Wave[c2+1]))\n",
    "    \n",
    "    width25 = cross2-cross1\n",
    "    \n",
    "    pnames =['widths0-25-50','cross1-2','crossrel1-2','peakVals', 'peaks1-2','peaksrel1-2','mins']\n",
    "\n",
    "    \n",
    "    return pnames,[[width0, width25, width50],[cr1, cr2],[crel1,crel2],[peak1val,peak2val], [peak1, peak2],[prel1,prel2],  [minim, minimo]], electrode,Wave\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "#Wave DATABASE\n",
    "#def Wavedatabase(expe,meas,cluster,electrode,params):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAYING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY PSTH \n",
    "#----------------------------------------------------------------------------------------\n",
    "# Plot a single neuron PSTH, 25 piezos\n",
    "def display_PSTH(expe,histdata, counts, t_before, t_after,fig,inner_grid,neuron,numspikesP,numspikesN,STC_on,PW) :\n",
    "    \n",
    "    \n",
    "    fig2 = figure()\n",
    "    ax = fig2.add_subplot(1,1,1)\n",
    "    for i in range(25) :\n",
    "        \n",
    "        if i== 0:\n",
    "            #ax1 = subplot(5,5,1, frame_on=False)\n",
    "            ax1 = Subplot(fig, inner_grid[i])     \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        elif i==20:\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.spines['right'].set_linewidth(0.3)\n",
    "            ax1.spines['top'].set_linewidth(0.3)\n",
    "            ax1.spines['left'].set_linewidth(0.3)\n",
    "            ax1.spines['bottom'].set_linewidth(0.3)\n",
    "            \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        else :\n",
    "            #subplot(5,5,i+1,sharex=ax1,sharey=ax1,frame_on=False)\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "       \n",
    "            \n",
    "                        \n",
    "           \n",
    "        if histdata[i][1].size :\n",
    "            ax1.hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength), color='g', alpha=1.0, edgecolor='none', histtype='stepfilled', label='Pos', weights=np.repeat(normnum, len(histdata[i][1])))\n",
    "        if histdata[i][0].size :\n",
    "            ax1.hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength), color='b', alpha=0.7, edgecolor='none', histtype='stepfilled', label='Neg', weights=np.repeat(normnum, len(histdata[i][0]))) \n",
    "        #if (histdata[i][0].size) or (histdata[i][1].size) :\n",
    "        xlim(-before_index, after_index)\n",
    "        ax1.axvline(0, color = 'r', linewidth=1)\n",
    "        \n",
    "        ax1.axhline(0, color = 'r', linewidth=2)\n",
    "        ymax = 1.02 * height\n",
    "        ylim(0, ymax)\n",
    "        xvals = np.array([0,10,20,30])\n",
    "        yvals = np.array([0,ymax*0.9,ymax*0.9,0])\n",
    "        ax1.plot(xvals, yvals, linewidth=0.2,color = (0.75,0.75,0.75))\n",
    "        if i==4: ax1.set_title('ymax =' + str( np.around(height,decimals = 3) ),fontsize=8)\n",
    "        if i ==1: ax1.set_title('Nrn' + str(neuron) + '_Pos' + str(int(numspikesP))+ '_Neg' + str(int(numspikesN)),fontsize=9)\n",
    "        \n",
    "        fig.add_subplot(ax1)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "def display_all_PSTHs_of_recording(expe,histdata, counts, pdf_files_directory, t_before, t_after,grupete,STC_on,PW,titles) :\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(histdata.keys())\n",
    "    if nrns <16: \n",
    "        layout = [5,3]\n",
    "    else: layout = [nrns//3+(nrns%3!=0),3]\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.1, hspace=0.2)\n",
    "    \n",
    "    ii=0\n",
    "    orderneurons = np.sort(list(histdata.keys()))\n",
    "    for neuron in  orderneurons:\n",
    "        clf()\n",
    "        totalup = 0\n",
    "        totaldown = 0\n",
    "        for i in np.arange(8, dtype='int') :\n",
    "            totalup+=counts[neuron][i][0]\n",
    "            totaldown+=counts[neuron][i][1]\n",
    "            \n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(5,5,subplot_spec=outer_grid[ii], wspace=0.1, hspace=0.1)\n",
    "               \n",
    "        numspikesP= totalup                  \n",
    "        numspikesN= totaldown\n",
    "        display_PSTH(expe,histdata[neuron], counts[neuron], t_before, t_after,fig,inner_grid,neuron,numspikesP,numspikesN,STC_on[neuron],PW[neuron])                               \n",
    "        \n",
    "        if grupete ==1:\n",
    "            fig.suptitle(titles + '_multiunits',fontsize=16)\n",
    "        elif grupete ==3:\n",
    "            fig.suptitle(titles + '_responsiveMULTIUNITS',fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(titles ,fontsize=16)\n",
    "        \n",
    "        ii+=1\n",
    "    if grupete ==1:                  \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_multi.pdf', format='pdf')\n",
    "    elif grupete==3:\n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_respMULTI.pdf', format='pdf')\n",
    "    else:        \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist.pdf', format='pdf')\n",
    "        \n",
    "    clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_wave_params(wpdata,pdf_files_directory,titles) :\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(wpdata.keys())\n",
    "    \n",
    "    ii=0\n",
    "    orderneurons = np.sort(list(histdata.keys()))\n",
    "    for neuron in  orderneurons:\n",
    "        clf()\n",
    "        \n",
    "        params = wavedata[neuron].params\n",
    "        plot(params[0][0],params[2][0],params[4][0])\n",
    "        \n",
    "        \n",
    "    if grupete ==1:                  \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_multi.pdf', format='pdf')\n",
    "    elif grupete==3:\n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_respMULTI.pdf', format='pdf')\n",
    "    else:        \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist.pdf', format='pdf')\n",
    "        \n",
    "    clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell you put all the information to make the code portable from computer to computer\n",
    "# You have to place all the file names and experiments, then you loop whichever you want to analyse\n",
    "#--------------------------------------------------------------------------------\n",
    "#Experiment numbers\n",
    "ExpeNum = [20,22,23,24,26,27,28,29,30,31,32]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders for measurements and experiments (this is how we separate shanks in folders for individual analyses)\n",
    "m164 = ['m1s1','m1s2','m1s3','m1s4','m1s5','m1s6','m1s7','m1s8']\n",
    "m264 = ['m2s1','m2s2','m2s3','m2s4','m2s5','m2s6','m2s7','m2s8']\n",
    "m364 = ['m3s1','m3s2','m3s3','m3s4','m3s5','m3s6','m3s7','m3s8']\n",
    "m464 = ['m4s1','m4s2','m4s3','m4s4','m4s5','m4s6','m4s7','m4s8']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Kwik files    \n",
    "\n",
    "files20 = [ 'MEAS-150707-1_ele01_ele08.kwik',\n",
    "            'MEAS-150707-1_ele09_ele16.kwik',\n",
    "            'MEAS-150707-1_ele17_ele24.kwik',\n",
    "            'MEAS-150707-1_ele25_ele32.kwik',\n",
    "            'MEAS-150707-23_ele01_ele08.kwik',\n",
    "            'MEAS-150707-23_ele16_ele09.kwik']#,\n",
    "            #'MEAS-150707-23_ele17_ele24.kwik',  not in S2\n",
    "            #'MEAS-150707-23_ele25_ele32.kwik',] not in S2\n",
    "\n",
    "files22 = [ 'MEAS-150716-12_ele01_ele08.kwik',\n",
    "            'MEAS-150716-12_ele09_ele16.kwik',\n",
    "            'MEAS-150716-12_ele17_ele24.kwik',\n",
    "            'MEAS-150716-12_ele25_ele32.kwik',\n",
    "            'MEAS-150716-3_ele01_ele08.kwik',\n",
    "            'MEAS-150716-3_ele09_ele16.kwik',\n",
    "            'MEAS-150716-3_ele17_ele24.kwik',\n",
    "            'MEAS-150716-3_ele25_ele32.kwik',]\n",
    "\n",
    "files23 = [ 'MEAS-151027-1_ele01_ele08.kwik',\n",
    "            'MEAS-151027-1_ele09_ele16.kwik',\n",
    "            #'MEAS-151027-1_ele17_ele24.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele25_ele32.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele33_ele40.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele41_ele48.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele49_ele56.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele57_ele64.kwik', out of S2\n",
    "            'MEAS-151027-2_ele01_ele08.kwik',\n",
    "            'MEAS-151027-2_ele09_ele16.kwik',\n",
    "            'MEAS-151027-2_ele17_ele24.kwik',\n",
    "            'MEAS-151027-2_ele25_ele32.kwik',\n",
    "            'MEAS-151027-2_ele33_ele40.kwik']#,\n",
    "            #'MEAS-151027-2_ele41_ele48.kwik',  out of S2\n",
    "            #'MEAS-151027-2_ele49_ele56.kwik',  out of S2\n",
    "            #'MEAS-151027-2_ele57_ele64.kwik']  out of S2\n",
    "\n",
    "files24 = [#'MEAS-151103-1_EXTRACTED_ele25_ele32.kwik',  no functional responses\n",
    "           'MEAS-151103-1_EXTRACTED_ele33_ele40.kwik',  \n",
    "           'MEAS-151103-1_EXTRACTED_ele41_ele48.kwik',  \n",
    "           'MEAS-151103-1_EXTRACTED_ele49_ele56.kwik',  \n",
    "           'MEAS-151103-1_EXTRACTED_ele57_ele64.kwik',\n",
    "           #'MEAS-151103-2_ele33_ele40.kwik',   no units\n",
    "           'MEAS-151103-2_ele41_ele48.kwik',\n",
    "           'MEAS-151103-2_ele49_ele56.kwik',\n",
    "           'MEAS-151103-2_ele57_ele64.kwik']\n",
    "\n",
    "#OUT OF S2\n",
    "#files25 = [ 'MEAS-151105-1good_ele01_ele08.kwik',\n",
    "#            'MEAS-151105-1good_ele09_ele16.kwik',\n",
    "#            'MEAS-151105-1good_ele17_ele24.kwik',\n",
    "#            'MEAS-151105-1good_ele25_ele32.kwik',\n",
    "#            'MEAS-151105-1good_ele33_ele40.kwik',\n",
    "#            'MEAS-151105-1good_ele41_ele48.kwik',\n",
    "#            'MEAS-151105-1good_ele49_ele56.kwik',\n",
    "#            'MEAS-151105-1good_ele57_ele64.kwik',\n",
    "#            'MEAS-151105-2_ele01_ele08.kwik',\n",
    "#            'MEAS-151105-2_ele09_ele16.kwik',\n",
    "#            'MEAS-151105-2_ele17_ele24.kwik',\n",
    "#            'MEAS-151105-2_ele25_ele32.kwik',\n",
    "#            'MEAS-151105-2_ele33_ele40.kwik',\n",
    "#            'MEAS-151105-2_ele41_ele48.kwik',\n",
    "#            'MEAS-151105-2_ele49_ele56.kwik',\n",
    "#            'MEAS-151105-2_ele57_ele64.kwik']\n",
    "\n",
    "files26 = [ 'MEAS-151110-1_ele01_ele08.kwik',\n",
    "            'MEAS-151110-1_ele09_ele16.kwik',\n",
    "            'MEAS-151110-1_ele17_ele24.kwik',\n",
    "            'MEAS-151110-1_ele25_ele32.kwik',\n",
    "            'MEAS-151110-1_ele33_ele40.kwik',\n",
    "            'MEAS-151110-1_ele41_ele48.kwik',\n",
    "            'MEAS-151110-1_ele49_ele56.kwik',\n",
    "            #'MEAS-151110-1_ele57_ele64.kwik', out of S2\n",
    "            'MEAS-151110-2_ele01_ele08.kwik',\n",
    "            'MEAS-151110-2_ele09_ele16.kwik',\n",
    "            'MEAS-151110-2_ele17_ele24.kwik',\n",
    "            'MEAS-151110-2_ele25_ele32.kwik']#,\n",
    "            #'MEAS-151110-2_ele33_ele40.kwik',  no units\n",
    "            #'MEAS-151110-2_ele41_ele48.kwik', out of S2\n",
    "            #'MEAS-151110-2_ele49_ele56.kwik', no units\n",
    "            #'MEAS-151110-2_ele57_ele64.kwik', no units\n",
    "            #'MEAS-151110-3_ele01_ele08.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele09_ele16.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele17_ele24.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele25_ele32.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele33_ele40.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele41_ele48.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele49_ele56.kwik',  no units\n",
    "            #'MEAS-151110-3_ele57_ele64.kwik']  no units\n",
    "\n",
    "files27  = ['MEAS-151112-1_ele01_ele08.kwik',\n",
    "            'MEAS-151112-1_ele09_ele16.kwik',\n",
    "            'MEAS-151112-1_ele17_ele24.kwik',\n",
    "            'MEAS-151112-1_ele25_ele32.kwik',\n",
    "            'MEAS-151112-1_ele33_ele40.kwik',\n",
    "            'MEAS-151112-1_ele41_ele48.kwik',\n",
    "            'MEAS-151112-1_ele49_ele56.kwik',\n",
    "            'MEAS-151112-1_ele57_ele64.kwik',\n",
    "            'MEAS-151112-2_ele01_ele08.kwik',\n",
    "            'MEAS-151112-2_ele09_ele16.kwik',\n",
    "            'MEAS-151112-2_ele17_ele24.kwik',\n",
    "            'MEAS-151112-2_ele25_ele32.kwik',\n",
    "            'MEAS-151112-2_ele33_ele40.kwik',\n",
    "            'MEAS-151112-2_ele41_ele48.kwik',\n",
    "            'MEAS-151112-2_ele49_ele56.kwik',\n",
    "            'MEAS-151112-2_ele57_ele64.kwik',\n",
    "            'MEAS-151112-3_ele01_ele08.kwik',\n",
    "            'MEAS-151112-3_ele09_ele16.kwik',\n",
    "            'MEAS-151112-3_ele17_ele24.kwik',\n",
    "            'MEAS-151112-3_ele25_ele32.kwik',\n",
    "            'MEAS-151112-3_ele33_ele40.kwik',\n",
    "            'MEAS-151112-3_ele41_ele48.kwik',\n",
    "            'MEAS-151112-3_ele49_ele56.kwik',\n",
    "            'MEAS-151112-3_ele57_ele64.kwik']\n",
    "\n",
    "files28 =  ['MEAS-151116-1_ele01_ele08.kwik',\n",
    "            'MEAS-151116-1_ele09_ele16.kwik',\n",
    "            'MEAS-151116-1_ele17_ele24.kwik',\n",
    "            'MEAS-151116-1_ele25_ele32.kwik',\n",
    "            'MEAS-151116-1_ele33_ele40.kwik',\n",
    "            'MEAS-151116-1_ele41_ele48.kwik',\n",
    "            'MEAS-151116-1_ele49_ele56.kwik',\n",
    "            #'MEAS-151116-1_ele57_ele64.kwik',\n",
    "            'MEAS-151116-2_ele01_ele08.kwik',\n",
    "            'MEAS-151116-2_ele09_ele16.kwik',\n",
    "            'MEAS-151116-2_ele17_ele24.kwik',\n",
    "            'MEAS-151116-2_ele25_ele32.kwik',\n",
    "            'MEAS-151116-2_ele33_ele40.kwik',\n",
    "            'MEAS-151116-2_ele41_ele48.kwik',\n",
    "            'MEAS-151116-2_ele49_ele56.kwik',\n",
    "            'MEAS-151116-2_ele57_ele64.kwik',\n",
    "            'MEAS-151116-3_ele01_ele08.kwik',\n",
    "            'MEAS-151116-3_ele09_ele16.kwik',\n",
    "            'MEAS-151116-3_ele17_ele24.kwik',\n",
    "            'MEAS-151116-3_ele25_ele32.kwik',\n",
    "            'MEAS-151116-3_ele33_ele40.kwik',\n",
    "            'MEAS-151116-3_ele41_ele48.kwik',\n",
    "            'MEAS-151116-3_ele49_ele56.kwik',\n",
    "            'MEAS-151116-3_ele57_ele64.kwik']\n",
    "\n",
    "files29  = ['MEAS-151118-1_ele01_ele08.kwik',\n",
    "            'MEAS-151118-1_ele09_ele16.kwik',\n",
    "            'MEAS-151118-1_ele17_ele24.kwik',\n",
    "            'MEAS-151118-1_ele25_ele32.kwik',\n",
    "            'MEAS-151118-1_ele33_ele40.kwik',\n",
    "            'MEAS-151118-1_ele41_ele48.kwik',\n",
    "            'MEAS-151118-1_ele49_ele56.kwik',\n",
    "            'MEAS-151118-1_ele57_ele64.kwik',\n",
    "            'MEAS-151118-2_ele01_ele08.kwik',\n",
    "            'MEAS-151118-2_ele09_ele16.kwik',\n",
    "            'MEAS-151118-2_ele17_ele24.kwik',\n",
    "            'MEAS-151118-2_ele25_ele32.kwik',\n",
    "            'MEAS-151118-2_ele33_ele40.kwik',\n",
    "            'MEAS-151118-2_ele41_ele48.kwik',\n",
    "            'MEAS-151118-2_ele49_ele56.kwik',\n",
    "            'MEAS-151118-2_ele57_ele64.kwik',\n",
    "            'MEAS-151118-3_ele01_ele08.kwik',\n",
    "            'MEAS-151118-3_ele09_ele16.kwik',\n",
    "            'MEAS-151118-3_ele17_ele24.kwik',\n",
    "            'MEAS-151118-3_ele25_ele32.kwik',\n",
    "            'MEAS-151118-3_ele33_ele40.kwik',\n",
    "            'MEAS-151118-3_ele41_ele48.kwik',\n",
    "            'MEAS-151118-3_ele49_ele56.kwik',\n",
    "            'MEAS-151118-3_ele57_ele64.kwik']\n",
    "\n",
    "\n",
    "files30  = ['MEAS-151208-2_ele01_ele08.kwik',\n",
    "            'MEAS-151208-2_ele09_ele16.kwik',\n",
    "            'MEAS-151208-2_ele17_ele24.kwik',\n",
    "            'MEAS-151208-2_ele25_ele32.kwik',\n",
    "            'MEAS-151208-2_ele33_ele40.kwik',\n",
    "            'MEAS-151208-2_ele41_ele48.kwik',\n",
    "            'MEAS-151208-2_ele49_ele56.kwik',\n",
    "            'MEAS-151208-2_ele57_ele64.kwik',\n",
    "            'MEAS-151208-3_ele01_ele08.kwik',\n",
    "            'MEAS-151208-3_ele09_ele16.kwik',\n",
    "            'MEAS-151208-3_ele17_ele24.kwik',\n",
    "            'MEAS-151208-3_ele25_ele32.kwik',\n",
    "            'MEAS-151208-3_ele33_ele40.kwik',\n",
    "            'MEAS-151208-3_ele41_ele48.kwik',\n",
    "            'MEAS-151208-3_ele49_ele56.kwik',\n",
    "            'MEAS-151208-3_ele57_ele64.kwik',\n",
    "            'MEAS-151208-4_ele01_ele08.kwik',\n",
    "            'MEAS-151208-4_ele09_ele16.kwik',\n",
    "            'MEAS-151208-4_ele17_ele24.kwik',\n",
    "            'MEAS-151208-4_ele25_ele32.kwik',\n",
    "            'MEAS-151208-4_ele33_ele40.kwik',\n",
    "            'MEAS-151208-4_ele41_ele48.kwik',\n",
    "            'MEAS-151208-4_ele49_ele56.kwik',\n",
    "            'MEAS-151208-4_ele57_ele64.kwik',\n",
    "            'MEAS-151208-5_ele01_ele08.kwik',\n",
    "            'MEAS-151208-5_ele09_ele16.kwik',\n",
    "            'MEAS-151208-5_ele17_ele24.kwik',\n",
    "            'MEAS-151208-5_ele25_ele32.kwik',\n",
    "            'MEAS-151208-5_ele33_ele40.kwik',\n",
    "            'MEAS-151208-5_ele41_ele48.kwik',\n",
    "            'MEAS-151208-5_ele49_ele56.kwik',\n",
    "            'MEAS-151208-5_ele57_ele64.kwik']\n",
    "\n",
    "\n",
    "files31 = [ #'MEAS-151210-1_ele01_ele08.kwik',  no units\n",
    "            #'MEAS-151210-1_ele09_ele16.kwik',  no units\n",
    "            #'MEAS-151210-1_ele17_ele24.kwik',  no units\n",
    "            #'MEAS-151210-1_ele25_ele32.kwik',  no units\n",
    "            #'MEAS-151210-1_ele33_ele40.kwik',  no units\n",
    "            'MEAS-151210-1_ele41_ele48.kwik',\n",
    "            'MEAS-151210-1_ele49_ele56.kwik',\n",
    "            'MEAS-151210-1_ele57_ele64.kwik',\n",
    "            #'MEAS-151210-2_ele01_ele08.kwik',   out of S2\n",
    "            #'MEAS-151210-2_ele09_ele16.kwik',   out of S2\n",
    "            #'MEAS-151210-2_ele17_ele24.kwik',   out of S2\n",
    "            #'MEAS-151210-2_ele25_ele32.kwik',   out of S2\n",
    "            'MEAS-151210-2_ele33_ele40.kwik',\n",
    "            'MEAS-151210-2_ele41_ele48.kwik',\n",
    "            'MEAS-151210-2_ele49_ele56.kwik',\n",
    "            'MEAS-151210-2_ele57_ele64.kwik',\n",
    "            #'MEAS-151210-3_ele01_ele08.kwik',   out of S2\n",
    "            #'MEAS-151210-3_ele09_ele16.kwik',   no units\n",
    "            #'MEAS-151210-3_ele17_ele24.kwik',   no units\n",
    "            #'MEAS-151210-3_ele25_ele32.kwik',   out of S2\n",
    "            'MEAS-151210-3_ele33_ele40.kwik',\n",
    "            'MEAS-151210-3_ele41_ele48.kwik',\n",
    "            'MEAS-151210-3_ele49_ele56.kwik',\n",
    "            'MEAS-151210-3_ele57_ele64.kwik']\n",
    "\n",
    "files32 = [ 'MEAS-151214-1_ele01_ele08.kwik',\n",
    "            'MEAS-151214-1_ele09_ele16.kwik',\n",
    "            'MEAS-151214-1_ele17_ele24.kwik',\n",
    "            'MEAS-151214-1_ele25_ele32.kwik',\n",
    "            'MEAS-151214-1_ele33_ele40.kwik',\n",
    "            'MEAS-151214-2_ele01_ele08.kwik',\n",
    "            'MEAS-151214-2_ele09_ele16.kwik',\n",
    "            'MEAS-151214-2_ele17_ele24.kwik',\n",
    "            'MEAS-151214-2_ele25_ele32.kwik',\n",
    "            'MEAS-151214-2_ele33_ele40.kwik']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------\n",
    "# Here I create my dictionary of experiments\n",
    "Expe={}\n",
    "Vtags={}\n",
    "Stim={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "    Vtags[num] = dict()\n",
    "#---------------------------------------\n",
    "i=0        \n",
    "for meas in np.append(m164[0:4],m364[0:2]):\n",
    "    Expe[20][meas] = files20[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0 \n",
    "for meas in np.append(m164[0:4],m364[0:4]):\n",
    "    Expe[22][meas] = files22[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0 \n",
    "for meas in np.append(m164[0:2],m264[0:5]):\n",
    "    Expe[23][meas] = files23[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0\n",
    "for meas in np.append(m164[4:8],m264[5:8]):    \n",
    "    Expe[24][meas] = files24[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0 \n",
    "for meas in np.append(m164,m264):    \n",
    "    Expe[25][meas] = files25[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0\n",
    "for meas in np.append(m164[0:7],m264[0:4]):\n",
    "    Expe[26][meas] = files26[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0\n",
    "for meas in np.append(np.append(m164[0:7],m264),m364):    \n",
    "    Expe[28][meas] = files28[i]\n",
    "    i+=1\n",
    "#---------------------------------------    \n",
    "i=0\n",
    "for meas in np.append(np.append(m164,m264),m364):    \n",
    "    Expe[27][meas] = files27[i]\n",
    "    Expe[29][meas] = files29[i]\n",
    "    Expe[30][meas] = files30[i]\n",
    "    i+=1\n",
    "#---------------------------------------    \n",
    "for meas in m464:\n",
    "    Expe[30][meas] = files30[i]\n",
    "    i+=1\n",
    "i=0\n",
    "#---------------------------------------    \n",
    "i=0\n",
    "for meas in np.append(np.append(m164[5:8],m264[4:8]),m364[4:8]):    \n",
    "    Expe[31][meas] = files31[i]\n",
    "    i+=1\n",
    "i=0\n",
    "#---------------------------------------    \n",
    "for meas in np.append(m164[0:5],m264[0:5]):\n",
    "    Expe[32][meas] = files32[i]\n",
    "    i+=1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Vtag files \n",
    "Vtags[20] = ['MEAS-150707-1_Vtag1.dat','nada','MEAS-150707-23_Vtag1.dat']\n",
    "Vtags[22] = ['MEAS-150716-12_Vtag1.dat','nada','MEAS-150716-3_Vtag1.dat']\n",
    "Vtags[23] = ['MEAS-151027-1_Vtag1.dat','MEAS-151027-2_Vtag1.dat']\n",
    "Vtags[23] = ['MEAS-151027-1_Vtag1.dat','MEAS-151027-2_Vtag1.dat']\n",
    "Vtags[24] = ['MEAS-151103-1_Vtag1.dat','MEAS-151103-2_Vtag1.dat']\n",
    "Vtags[25] = ['MEAS-151105-1good_Vtag1.dat','MEAS-151105-2_Vtag1.dat']\n",
    "Vtags[26] = ['MEAS-151110-1_Vtag1.dat','MEAS-151110-2_Vtag1.dat','MEAS-151110-3_Vtag1.dat']\n",
    "Vtags[27] = ['MEAS-151112-1_Vtag1.dat','MEAS-151112-2_Vtag1.dat','MEAS-151112-3_Vtag1.dat']\n",
    "Vtags[28] = ['MEAS-151116-1_Vtag1.dat','MEAS-151116-2_Vtag1.dat','MEAS-151116-3_Vtag1.dat']\n",
    "Vtags[29] = ['MEAS-151118-1_Vtag1.dat','MEAS-151118-2_Vtag1.dat','MEAS-151118-3_Vtag1.dat']\n",
    "Vtags[30] = ['MEAS-151208-2_Vtag1.dat','MEAS-151208-3_Vtag1.dat','MEAS-151208-4_Vtag1.dat','MEAS-151208-5_Vtag1.dat']\n",
    "Vtags[31] = ['MEAS-151210-1_Vtag1.dat','MEAS-151210-2_Vtag1.dat','MEAS-151210-3_Vtag1.dat']\n",
    "Vtags[32] = ['MEAS-151214-1_Vtag1.dat','MEAS-151214-2_Vtag1.dat']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Stimulus type\n",
    "for i in range(23,33):\n",
    "    Stim[i] = 'big_STIM_FC_corrected'\n",
    "for i in range(15,23):\n",
    "    Stim[i] = 'big_STIM'\n",
    "for i in range(10,15):\n",
    "    Stim[i] = 'small_STIM'  \n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "#Root folder to work in, such all will be in subfolders \n",
    "#e.g.: \"/EXP_23/m1s1/\" for data or \"/STIM/\" for stims\n",
    "rootF = '/home/matias/WORKSPACE/'    \n",
    "stimFolder = rootF +'STIM/'\n",
    "\n",
    "#I have a separate folder for exp 22 and before\n",
    "rootF_kwiks = rootF    #uncomment this to work with the other root folder\n",
    "#rootF_kwiks = '/media/matias/DATA/WORKSPACE2/'\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Initialize wave features dictionary\n",
    "Wavedata = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "group: 2\n",
      "m1s1\n",
      "   building waves\n",
      "m1s2\n",
      "   building waves\n",
      "m1s3\n",
      "   building waves\n",
      "m1s4\n",
      "   building waves\n",
      "m1s5\n",
      "   building waves\n",
      "m1s6\n",
      "   building waves\n",
      "m1s7\n",
      "   building waves\n",
      "m1s8\n",
      "   building waves\n",
      "m2s1\n",
      "   building waves\n",
      "m2s2\n",
      "   building waves\n",
      "m2s3\n",
      "   building waves\n",
      "m2s4\n",
      "   building waves\n",
      "m2s5\n",
      "   building waves\n",
      "m2s6\n",
      "   building waves\n",
      "m2s7\n",
      "   building waves\n",
      "m2s8\n",
      "   building waves\n",
      "m3s1\n",
      "   building waves\n",
      "m3s2\n",
      "   building waves\n",
      "m3s3\n",
      "   building waves\n",
      "m3s4\n",
      "   building waves\n",
      "m3s5\n",
      "   building waves\n",
      "m3s6\n",
      "   building waves\n",
      "m3s7\n",
      "   building waves\n",
      "m3s8\n",
      "   building waves\n",
      "31\n",
      "group: 2\n",
      "m1s6\n",
      "   building waves\n",
      "m1s7\n",
      "   building waves\n",
      "m1s8\n",
      "   building waves\n",
      "m2s5\n",
      "   building waves\n",
      "m2s6\n",
      "   building waves\n",
      "m2s7\n",
      "   building waves\n",
      "m2s8\n",
      "   building waves\n",
      "m3s5\n",
      "   building waves\n",
      "m3s6\n",
      "   building waves\n",
      "m3s7\n",
      "   building waves\n",
      "m3s8\n",
      "   building waves\n",
      "32\n",
      "group: 2\n",
      "m1s1\n",
      "   building waves\n",
      "m1s2\n",
      "   building waves\n",
      "m1s3\n",
      "   building waves\n",
      "m1s4\n",
      "   building waves\n",
      "m1s5"
     ]
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [28,30]   #Expe                                        #select experiment numbers!\n",
    "grupete = [2]   #select cluster groups! 2 for good clusters 1 for multiunits, 3 for unsorted\n",
    "\n",
    "#select measurement and/or shanks!\n",
    "Measurements = m364[0:2]           #['m1s1']#['m3s1','m3s3']#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']   \n",
    "\n",
    "# choice code not to ploteverything at the same time\n",
    "ploteo = [0,0,0,0]                                           #1 to make plots: psth,sta,ufc,stc\n",
    "\n",
    "dirs =[]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "last_exp=0     #we use this to load stim only when we change experiment\n",
    "for expe in SelExp:\n",
    "    \n",
    "    #uncomment if we want a whole file for all the experiments\n",
    "    Wavedata = dict()\n",
    "    \n",
    "    Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    print(expe)\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits 3 for unsorted\n",
    "        #folder names\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFwaves/EXP_'+str(expe)]\n",
    "        print('group:', group)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        measurements = Expe[expe]                            \n",
    "                 \n",
    "        for meas in Measurements:           \n",
    "            print(meas)\n",
    "            #---------------------------------------------------------------\n",
    "            #select datafile\n",
    "            sp_file = rootF_kwiks + 'EXP_' + str(expe) +'/Spike_Sorting/'+ meas +'/'+ measurements[meas]\n",
    "            \n",
    "            #load datafile\n",
    "            print('   building waves')\n",
    "            readkwikwaveinfo(Wavedata,sp_file,str(expe),meas,group)  \n",
    "            \n",
    "            #---------------------------------------------------------------\n",
    "            #load stimulus if looping new experiment, without trimming\n",
    "           \n",
    "            if len(Wavedata.keys())>0:                              #do only if there are clusters\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #create output folders\n",
    "                for dir in dirs:\n",
    "                    if not os.path.exists(dir):\n",
    "                        os.makedirs(dir) \n",
    "                dire = dirs[0] +'/'\n",
    "                titles = 'Exp'+ str(expe) + '_Meas_' + meas[1] + '_Shank_' + meas[3]\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Wave params\n",
    "                \n",
    "                #print('   building waves')\n",
    "                                        \n",
    "                \n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot Waves\n",
    "                #print('   plotting')\n",
    "                if ploteo[0]==1: display_all_PSTHs_of_recording(expe,hist_output, PSTH_spikes_counts, dire, t_before, t_after,group,STC_on,PW,titles)\n",
    "         \n",
    "    filesave ='waveforms' + str(expe)\n",
    "    save_obj(Wavedata,filesave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    filesave ='wavedata' + str(expe)\n",
    "    save_obj(Wavedata,filesave)\n",
    "    \n",
    "    >>> x = {'a':1, 'b': 2}\n",
    ">>> y = {'b':10, 'c': 11}\n",
    ">>> z = x.update(y)\n",
    ">>> print z\n",
    "None\n",
    ">>> x\n",
    "{'a': 1, 'b': 10, 'c': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = list(sorted(Wavedata.keys()))\n",
    "idx[0]\n",
    "\n",
    "print('keys: ',Wavedata[idx[0]].keys())\n",
    "\n",
    "print('parnames: ',Wavedata[idx[0]].params_names)\n",
    "\n",
    "print('firstidx: ' ,idx[0])\n",
    "\n",
    "print('number of idx: ',len(idx))\n",
    "\n",
    "print('params: ',Wavedata[idx[0]].params)\n",
    "\n",
    "print(Wavedata.keys())\n",
    "\n",
    "neuron=0\n",
    "\n",
    "electrode = Wavedata[idx[neuron]].electrodemax\n",
    "\n",
    "plot(Wavedata[idx[neuron]].bigwave)\n",
    "plot(Wavedata[idx[neuron]].bigwave+Wavedata[idx[neuron]].bigwavestd)\n",
    "plot(Wavedata[idx[neuron]].bigwave-Wavedata[idx[neuron]].bigwavestd)\n",
    "\n",
    "wave0 = Wavedata[idx[0]]\n",
    "\n",
    "wave0.bigwave\n",
    "\n",
    "#print(wave0.waves.shape)\n",
    "\n",
    "wave0.params\n",
    "\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_obj(Wavedata,'wavedata220')\n",
    "\n",
    "neuron='12'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Wavedata = load_obj('wavedata20')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = sort(list(Wavedata.keys()))\n",
    "\n",
    "print(Wavedata[idx[0]].keys())\n",
    "\n",
    "Wavedata[idx[0]].params_names\n",
    "\n",
    "Wavedata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting waveforms\n",
    "\n",
    "idx = sort(list(Wavedata.keys()))\n",
    "\n",
    "neuron = idx[3]\n",
    "\n",
    "print(neuron)\n",
    "\n",
    "fig = figure(figsize=(3,20))\n",
    "\n",
    "elec = [0,7,1,6,2,5,3,4]\n",
    "\n",
    "print(size(Wavedata[neuron].meanwave[:,0]))\n",
    "\n",
    "pos = [1,4,5,8,9,12,13,16]\n",
    "\n",
    "pos2 = arange(1,9)\n",
    "\n",
    "pos2linear = [2,1,3,0,4,7,5,6]\n",
    "\n",
    "\n",
    "\n",
    "buzsaki=True\n",
    "\n",
    "if buzsaki:\n",
    "    pos = pos2\n",
    "else:\n",
    "    pos = pos2linear+1\n",
    "\n",
    "i=0\n",
    "origin=0\n",
    "for i in arange(8):\n",
    "    \n",
    "    ax1 = fig.add_subplot(8,2,pos2[i])\n",
    "    \n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    #ax1.spines['left'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "   \n",
    "    ax1.set_xlim([0, 48])\n",
    "    ax1.set_ylim([-1000, 1000])\n",
    "    \n",
    "    #for x in arange(Spikes[neuron]['spike_times'].shape[0]):\n",
    "    #    ax1.plot(arange(48),wave[neuron]['waves'][x,:,elec[i]],color='b')\n",
    "\n",
    "    m =Wavedata[neuron].meanwave[:,elec[i]]\n",
    "    s =Wavedata[neuron].stdwave[:,elec[i]]\n",
    "    \n",
    "    m=m-m[0]\n",
    "    \n",
    "    #sem= stats.sem (Waves[neuron]['waves'][:,:,elec[i]],axis=0)\n",
    "    if buzsaki:\n",
    "        if i%2==1:\n",
    "            m=m-500\n",
    "            origin =-500\n",
    "        else: \n",
    "            m=m+500\n",
    "            origin =500\n",
    "    \n",
    "    ax1.plot(arange(48),m,color='r')\n",
    "    \n",
    "    ax1.plot(arange(48),origin+0*arange(48))\n",
    "    ax1.plot(arange(48),m+s,color='g')\n",
    "    ax1.plot(arange(48),m-s,color='g')     \n",
    "    \n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticklabels([])\n",
    "      \n",
    "#print(Waves[21656]['waves'][100,:,0])\n",
    "#print(Waves[21656]['waves'].shape)\n",
    "#Spikes[21656]['spike_times'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
