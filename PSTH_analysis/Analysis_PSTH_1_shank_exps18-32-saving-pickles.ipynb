{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#SAVING BINARY OBJECTS DATA\n",
    "#need to automate data folder creation\n",
    "#----------------------------------------------------------------------------------------\n",
    "import pickle \n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# READ STIMULUS\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Here we read the binary file with stimulus: 902 of 25 piezos x 1024 samples\n",
    "# Text file has the type of stimulus: F sparse, C correlated, U uncorrelated\n",
    "def read_stimulus(expe,meas):\n",
    "    ## This function reads the stimulus binary file, reads the type of stimulus,\n",
    "    ## and stores it in a matrix and a row vector\n",
    "    \n",
    "    bin_file = open(binname,'rb')\n",
    "    read_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "    read_data = read_data.reshape((-1,25,10240)) # reshapes data assuming 25 whiskers, 10240 time bins\n",
    "    txt_data = np.loadtxt(textname, dtype='S8') # Makes sure data type is text decoded\n",
    "    txt_data = txt_data.view(np.chararray).decode('utf-8') # Makes sure data type is text decoded\n",
    "    \n",
    "    length2=0\n",
    "    \n",
    "    if expe==22 and meas[0:2] == 'm1':  #measurement 1 composed of two recorded\n",
    "        length1=902\n",
    "        length2 =93\n",
    "        \n",
    "    if expe == 20 and meas[0:2]=='m3': #there are 46 events in exp2 and 879 in exp3\n",
    "        length1 = 46 \n",
    "        length2 = 879\n",
    "    \n",
    "    if length2>0:\n",
    "        txt_data = np.append(txt_data[0:length1], txt_data[0:length2])\n",
    "        read_data = np.append(read_data[0:length1], read_data[0:length2],0)\n",
    "        read_data = read_data.reshape((-1,25,10240)) # reshapes data assuming 25 whiskers, 10240 time bins\n",
    "            \n",
    "    close(binname)\n",
    "    \n",
    "    return read_data, txt_data\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "# Grupete stands for cluster groups! 2: good clusters, 1: multiunits, 0: unsorted, 3: noise\n",
    "def readkwikinfo(kwik, grupete=3):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    model.close()\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READ VTAG\n",
    "#----------------------------------------------------------------------------------------\n",
    "def readVtag(Vtag1,stim,stimtype):\n",
    "    ## The first task is to find the stimulus onset times for each whisker in each sweep in each direction\n",
    "    start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "    starts = (where(start_and_stops==1)[0]-2999)/float(sampling_freq) # time in seconds\n",
    "    stops = (where(start_and_stops==-1)[0]+4110)/float(sampling_freq) # time in seconds\n",
    "    \n",
    "    stim_ret = stim[0:len(stops),:,:]\n",
    "    stimtype_ret = stimtype[0:len(stops)]\n",
    "    \n",
    "    return stim_ret, stimtype_ret, starts, stops\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS PSTH\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildPSTH(stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops,exp,meas) :\n",
    "## The first task is to find the stimulus onset times for each whisker in each sweep in each direction\n",
    "    #stim, stimtype = read_stimulus()\n",
    "    stim = stim[np.where(stimtype=='F')[0], :, :]\n",
    "    starts = starts[np.where(stimtype=='F')[0]]\n",
    "    stops = stops[np.where(stimtype=='F')[0]]\n",
    "    \n",
    "    stimtimes = {}\n",
    "    for w in np.arange(25, dtype='int') :  \n",
    "        timesUP = []\n",
    "        timesDOWN = []\n",
    "        for i in np.arange(len(stim), dtype='int') :\n",
    "            indsUP = (np.where(stim[i, w, :]==1108.8889)[0]-1)[::2]\n",
    "            # This finds all time points where the stim = 1108.8889, because each ramp has two 1108.8889 values\n",
    "            # (on the way up and on the way down) we take every other index using [::2]\n",
    "            timesUP.append(indsUP)\n",
    "            indsDOWN = (np.where(stim[i, w, :]==-1108.8889)[0]-1)[::2]\n",
    "            # This finds all time points where the stim = -1108.8889, because each ramp has two -1108.8889 values\n",
    "            # (on the way up and on the way down) we take every other index using [::2]\n",
    "            timesDOWN.append(indsDOWN)\n",
    "        stimtimes[w] = timesUP, timesDOWN # stimtimes[whisker][0][:]=UP stimtimes[whisker][1][:]=DOWN\n",
    "    \n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    hist_inds = {}\n",
    "    PSTH = {}\n",
    "    psth = dict()\n",
    "    psth_times = dict()\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in list(Spikes.keys()): \n",
    "        codename = 'exp'+ str(exp) + '_' + str(meas) + '_c' + str(neuron)\n",
    "        \n",
    "        psth = AttrDict({'clusnum': neuron,'exp' : int(exp) , 'meas': int(meas[1]) , 'shank': int(meas[3])})\n",
    "        \n",
    "        psth.update(AttrDict({'psth_counts': [] , 'psth_times': [] , 'psth_length': [t_before,t_after] }))\n",
    "        \n",
    "        psth['psth_counts'], psth['psth_times'] = PSTH_spikes(stim, stimtype, stimtimes, Spikes[neuron].spike_times, sampling_freq, t_before, t_after, starts, stops)\n",
    "        \n",
    "        PSTH[codename] = psth\n",
    "       \n",
    "    return PSTH\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "def PSTH_spikes(stimulation, stimtype, stimtimes, spikes, samp, t_before, t_after, starts, stops):\n",
    "    \"\"\"\n",
    "    stimulation   : a list of numpy arrays with a n*t stimulus inside\n",
    "    stimtimes     : a list of the times the stimulus occurred for each whisker \n",
    "    spikes        : an array that contains the spike times (s)\n",
    "    Vtag1         : synchronises stimulus with spike times\n",
    "    samp          : sampling rate of the stimulation (Hz)\n",
    "    t_before      : duration before the stim (positive, s)\n",
    "    t_after       : duration after the stim (positive, s)\n",
    "    starts        : the start of the F sweeps\n",
    "    stops         : the stops of the F sweeps\n",
    "    \"\"\"\n",
    "    \n",
    "    stim_samp = 1/.0009997575757\n",
    "    \n",
    "    PSTH_spike_counts = {}\n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(len(stimtimes[w][0][i]), dtype='int') :  # we must look at the number of stimulations per whisker per stimulation block and this is no longer 4        \n",
    "                timesUP = starts[i] + stimtimes[w][0][i][x]/stim_samp # stimtimes is now stimtimes[whisker][0 for UP, 1 for DOWN][stimsweep][trial]\n",
    "                spikecountsup += len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)]) # count spikes that are within PSTH window of stimtimes\n",
    "            for y in np.arange(len(stimtimes[w][1][i]), dtype='int') : # for the DOWN stimuli we must have a separate loop because they also are now randomly distributed and not 4\n",
    "                timesDOWN = starts[i] + stimtimes[w][1][i][y]/stim_samp                \n",
    "                spikecountsdown += len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "        PSTH_spike_counts[w] = spikecountsup, spikecountsdown\n",
    "    \n",
    "    hist_inds = {} #same changes for this block, each loop will change length depending on how many stimulations fall in a sweep\n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        hist_inds[w] = np.zeros(PSTH_spike_counts[w][0]), np.zeros(PSTH_spike_counts[w][1])\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(len(stimtimes[w][0][i]), dtype='int') :     # dynamic loop depends on how many stims fall in sweep      \n",
    "                timesUP = starts[i] + stimtimes[w][0][i][x]/stim_samp\n",
    "                spikecountup = len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)])\n",
    "                spikeidxup = spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)]\n",
    "                #spikeidxup = ((spikeidxup - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                hist_inds[w][0][spikecountsup:(spikecountsup+spikecountup)] = spikeidxup-timesUP#stimtimes[w][0][i][x]/float(stops[i] - starts[i])*len(stimulation[i,0])\n",
    "                spikecountsup += spikecountup\n",
    "            \n",
    "            for y in np.arange(len(stimtimes[w][1][i]), dtype='int') :     # dynamic loop depends on how many stims fall in sweep\n",
    "                timesDOWN = starts[i] + stimtimes[w][1][i][y]/stim_samp                \n",
    "                spikecountdown = len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "                spikeidxdown = spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)]\n",
    "                #spikeidxdown = ((spikeidxdown - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                hist_inds[w][1][spikecountsdown:(spikecountsdown+spikecountdown)] = spikeidxdown-timesDOWN#stimtimes[w][1][i][y]/float(stops[i] - starts[i])*len(stimulation[i,0])\n",
    "                spikecountsdown += spikecountdown\n",
    "                \n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "# March 25 we took out the rounding fronm this function, to keep the actual times with respect to stim.\n",
    "# April modified a little to be more precise with absolute times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell you put all the information to make the code portable from computer to computer\n",
    "# You have to place all the file names and experiments, then you loop whichever you want to analyse\n",
    "#--------------------------------------------------------------------------------\n",
    "#Experiment numbers\n",
    "ExpeNum = [20,22,23,24,25,26,27,28,29,30,31,32]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders for measurements and experiments (this is how we separate shanks in folders for individual analyses)\n",
    "m164 = ['m1s1','m1s2','m1s3','m1s4','m1s5','m1s6','m1s7','m1s8']\n",
    "m264 = ['m2s1','m2s2','m2s3','m2s4','m2s5','m2s6','m2s7','m2s8']\n",
    "m364 = ['m3s1','m3s2','m3s3','m3s4','m3s5','m3s6','m3s7','m3s8']\n",
    "m464 = ['m4s1','m4s2','m4s3','m4s4','m4s5','m4s6','m4s7','m4s8']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Kwik files    \n",
    "\n",
    "files20 = [ 'MEAS-150707-1_ele01_ele08.kwik',\n",
    "            'MEAS-150707-1_ele09_ele16.kwik',\n",
    "            'MEAS-150707-1_ele17_ele24.kwik',\n",
    "            'MEAS-150707-1_ele25_ele32.kwik',\n",
    "            'MEAS-150707-23_ele01_ele08.kwik',\n",
    "            'MEAS-150707-23_ele16_ele09.kwik']#,\n",
    "            #'MEAS-150707-23_ele17_ele24.kwik',  not in S2\n",
    "            #'MEAS-150707-23_ele25_ele32.kwik',] not in S2\n",
    "\n",
    "files22 = [ 'MEAS-150716-12_ele01_ele08.kwik',\n",
    "            'MEAS-150716-12_ele09_ele16.kwik',\n",
    "            'MEAS-150716-12_ele17_ele24.kwik',\n",
    "            'MEAS-150716-12_ele25_ele32.kwik',\n",
    "            'MEAS-150716-3_ele01_ele08.kwik',\n",
    "            'MEAS-150716-3_ele09_ele16.kwik',\n",
    "            'MEAS-150716-3_ele17_ele24.kwik',\n",
    "            'MEAS-150716-3_ele25_ele32.kwik',]\n",
    "\n",
    "files23 = [ 'MEAS-151027-1_ele01_ele08.kwik',\n",
    "            'MEAS-151027-1_ele09_ele16.kwik',\n",
    "            #'MEAS-151027-1_ele17_ele24.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele25_ele32.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele33_ele40.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele41_ele48.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele49_ele56.kwik', out of S2\n",
    "            #'MEAS-151027-1_ele57_ele64.kwik', out of S2\n",
    "            'MEAS-151027-2_ele01_ele08.kwik',\n",
    "            'MEAS-151027-2_ele09_ele16.kwik',\n",
    "            'MEAS-151027-2_ele17_ele24.kwik',\n",
    "            'MEAS-151027-2_ele25_ele32.kwik',\n",
    "            'MEAS-151027-2_ele33_ele40.kwik']#,\n",
    "            #'MEAS-151027-2_ele41_ele48.kwik',  out of S2\n",
    "            #'MEAS-151027-2_ele49_ele56.kwik',  out of S2\n",
    "            #'MEAS-151027-2_ele57_ele64.kwik']  out of S2\n",
    "\n",
    "files24 = [#'MEAS-151103-1_EXTRACTED_ele25_ele32.kwik',  no functional responses\n",
    "           'MEAS-151103-1_EXTRACTED_ele33_ele40.kwik',  \n",
    "           'MEAS-151103-1_EXTRACTED_ele41_ele48.kwik',  \n",
    "           'MEAS-151103-1_EXTRACTED_ele49_ele56.kwik',  \n",
    "           'MEAS-151103-1_EXTRACTED_ele57_ele64.kwik',\n",
    "           #'MEAS-151103-2_ele33_ele40.kwik',   no units\n",
    "           'MEAS-151103-2_ele41_ele48.kwik',\n",
    "           'MEAS-151103-2_ele49_ele56.kwik',\n",
    "           'MEAS-151103-2_ele57_ele64.kwik']\n",
    "\n",
    "#OUT OF S2\n",
    "files25 = [ 'MEAS-151105-1good_ele01_ele08.kwik',\n",
    "            'MEAS-151105-1good_ele09_ele16.kwik',\n",
    "            'MEAS-151105-1good_ele17_ele24.kwik',\n",
    "            'MEAS-151105-1good_ele25_ele32.kwik',\n",
    "            'MEAS-151105-1good_ele33_ele40.kwik',\n",
    "            'MEAS-151105-1good_ele41_ele48.kwik',\n",
    "            'MEAS-151105-1good_ele49_ele56.kwik',\n",
    "            'MEAS-151105-1good_ele57_ele64.kwik',\n",
    "            'MEAS-151105-2_ele01_ele08.kwik',\n",
    "            'MEAS-151105-2_ele09_ele16.kwik',\n",
    "            'MEAS-151105-2_ele17_ele24.kwik',\n",
    "            'MEAS-151105-2_ele25_ele32.kwik',\n",
    "            'MEAS-151105-2_ele33_ele40.kwik',\n",
    "            'MEAS-151105-2_ele41_ele48.kwik',\n",
    "            'MEAS-151105-2_ele49_ele56.kwik',\n",
    "            'MEAS-151105-2_ele57_ele64.kwik']\n",
    "\n",
    "files26 = [ 'MEAS-151110-1_ele01_ele08.kwik',\n",
    "            'MEAS-151110-1_ele09_ele16.kwik',\n",
    "            'MEAS-151110-1_ele17_ele24.kwik',\n",
    "            'MEAS-151110-1_ele25_ele32.kwik',\n",
    "            'MEAS-151110-1_ele33_ele40.kwik',\n",
    "            'MEAS-151110-1_ele41_ele48.kwik',\n",
    "            'MEAS-151110-1_ele49_ele56.kwik',\n",
    "            #'MEAS-151110-1_ele57_ele64.kwik', out of S2\n",
    "            'MEAS-151110-2_ele01_ele08.kwik',\n",
    "            'MEAS-151110-2_ele09_ele16.kwik',\n",
    "            'MEAS-151110-2_ele17_ele24.kwik',\n",
    "            'MEAS-151110-2_ele25_ele32.kwik']#,\n",
    "            #'MEAS-151110-2_ele33_ele40.kwik',  no units\n",
    "            #'MEAS-151110-2_ele41_ele48.kwik', out of S2\n",
    "            #'MEAS-151110-2_ele49_ele56.kwik', no units\n",
    "            #'MEAS-151110-2_ele57_ele64.kwik', no units\n",
    "            #'MEAS-151110-3_ele01_ele08.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele09_ele16.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele17_ele24.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele25_ele32.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele33_ele40.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele41_ele48.kwik',  out of S2\n",
    "            #'MEAS-151110-3_ele49_ele56.kwik',  no units\n",
    "            #'MEAS-151110-3_ele57_ele64.kwik']  no units\n",
    "\n",
    "files27  = ['MEAS-151112-1_ele01_ele08.kwik',\n",
    "            'MEAS-151112-1_ele09_ele16.kwik',\n",
    "            'MEAS-151112-1_ele17_ele24.kwik',\n",
    "            'MEAS-151112-1_ele25_ele32.kwik',\n",
    "            'MEAS-151112-1_ele33_ele40.kwik',\n",
    "            'MEAS-151112-1_ele41_ele48.kwik',\n",
    "            'MEAS-151112-1_ele49_ele56.kwik',\n",
    "            'MEAS-151112-1_ele57_ele64.kwik',\n",
    "            'MEAS-151112-2_ele01_ele08.kwik',\n",
    "            'MEAS-151112-2_ele09_ele16.kwik',\n",
    "            'MEAS-151112-2_ele17_ele24.kwik',\n",
    "            'MEAS-151112-2_ele25_ele32.kwik',\n",
    "            'MEAS-151112-2_ele33_ele40.kwik',\n",
    "            'MEAS-151112-2_ele41_ele48.kwik',\n",
    "            'MEAS-151112-2_ele49_ele56.kwik',\n",
    "            'MEAS-151112-2_ele57_ele64.kwik',\n",
    "            'MEAS-151112-3_ele01_ele08.kwik',\n",
    "            'MEAS-151112-3_ele09_ele16.kwik',\n",
    "            'MEAS-151112-3_ele17_ele24.kwik',\n",
    "            'MEAS-151112-3_ele25_ele32.kwik',\n",
    "            'MEAS-151112-3_ele33_ele40.kwik',\n",
    "            'MEAS-151112-3_ele41_ele48.kwik',\n",
    "            'MEAS-151112-3_ele49_ele56.kwik',\n",
    "            'MEAS-151112-3_ele57_ele64.kwik']\n",
    "\n",
    "files28 =  ['MEAS-151116-1_ele01_ele08.kwik',\n",
    "            'MEAS-151116-1_ele09_ele16.kwik',\n",
    "            'MEAS-151116-1_ele17_ele24.kwik',\n",
    "            'MEAS-151116-1_ele25_ele32.kwik',\n",
    "            'MEAS-151116-1_ele33_ele40.kwik',\n",
    "            'MEAS-151116-1_ele41_ele48.kwik',\n",
    "            'MEAS-151116-1_ele49_ele56.kwik',\n",
    "            #'MEAS-151116-1_ele57_ele64.kwik',\n",
    "            'MEAS-151116-2_ele01_ele08.kwik',\n",
    "            'MEAS-151116-2_ele09_ele16.kwik',\n",
    "            'MEAS-151116-2_ele17_ele24.kwik',\n",
    "            'MEAS-151116-2_ele25_ele32.kwik',\n",
    "            'MEAS-151116-2_ele33_ele40.kwik',\n",
    "            'MEAS-151116-2_ele41_ele48.kwik',\n",
    "            'MEAS-151116-2_ele49_ele56.kwik',\n",
    "            'MEAS-151116-2_ele57_ele64.kwik',\n",
    "            'MEAS-151116-3_ele01_ele08.kwik',\n",
    "            'MEAS-151116-3_ele09_ele16.kwik',\n",
    "            'MEAS-151116-3_ele17_ele24.kwik',\n",
    "            'MEAS-151116-3_ele25_ele32.kwik',\n",
    "            'MEAS-151116-3_ele33_ele40.kwik',\n",
    "            'MEAS-151116-3_ele41_ele48.kwik',\n",
    "            'MEAS-151116-3_ele49_ele56.kwik',\n",
    "            'MEAS-151116-3_ele57_ele64.kwik']\n",
    "\n",
    "files29  = ['MEAS-151118-1_ele01_ele08.kwik',\n",
    "            'MEAS-151118-1_ele09_ele16.kwik',\n",
    "            'MEAS-151118-1_ele17_ele24.kwik',\n",
    "            'MEAS-151118-1_ele25_ele32.kwik',\n",
    "            'MEAS-151118-1_ele33_ele40.kwik',\n",
    "            'MEAS-151118-1_ele41_ele48.kwik',\n",
    "            'MEAS-151118-1_ele49_ele56.kwik',\n",
    "            'MEAS-151118-1_ele57_ele64.kwik',\n",
    "            'MEAS-151118-2_ele01_ele08.kwik',\n",
    "            'MEAS-151118-2_ele09_ele16.kwik',\n",
    "            'MEAS-151118-2_ele17_ele24.kwik',\n",
    "            'MEAS-151118-2_ele25_ele32.kwik',\n",
    "            'MEAS-151118-2_ele33_ele40.kwik',\n",
    "            'MEAS-151118-2_ele41_ele48.kwik',\n",
    "            'MEAS-151118-2_ele49_ele56.kwik',\n",
    "            'MEAS-151118-2_ele57_ele64.kwik',\n",
    "            'MEAS-151118-3_ele01_ele08.kwik',\n",
    "            'MEAS-151118-3_ele09_ele16.kwik',\n",
    "            'MEAS-151118-3_ele17_ele24.kwik',\n",
    "            'MEAS-151118-3_ele25_ele32.kwik',\n",
    "            'MEAS-151118-3_ele33_ele40.kwik',\n",
    "            'MEAS-151118-3_ele41_ele48.kwik',\n",
    "            'MEAS-151118-3_ele49_ele56.kwik',\n",
    "            'MEAS-151118-3_ele57_ele64.kwik']\n",
    "\n",
    "\n",
    "files30  = ['MEAS-151208-2_ele01_ele08.kwik',\n",
    "            'MEAS-151208-2_ele09_ele16.kwik',\n",
    "            'MEAS-151208-2_ele17_ele24.kwik',\n",
    "            'MEAS-151208-2_ele25_ele32.kwik',\n",
    "            'MEAS-151208-2_ele33_ele40.kwik',\n",
    "            'MEAS-151208-2_ele41_ele48.kwik',\n",
    "            'MEAS-151208-2_ele49_ele56.kwik',\n",
    "            'MEAS-151208-2_ele57_ele64.kwik',\n",
    "            'MEAS-151208-3_ele01_ele08.kwik',\n",
    "            'MEAS-151208-3_ele09_ele16.kwik',\n",
    "            'MEAS-151208-3_ele17_ele24.kwik',\n",
    "            'MEAS-151208-3_ele25_ele32.kwik',\n",
    "            'MEAS-151208-3_ele33_ele40.kwik',\n",
    "            'MEAS-151208-3_ele41_ele48.kwik',\n",
    "            'MEAS-151208-3_ele49_ele56.kwik',\n",
    "            'MEAS-151208-3_ele57_ele64.kwik',\n",
    "            'MEAS-151208-4_ele01_ele08.kwik',\n",
    "            'MEAS-151208-4_ele09_ele16.kwik',\n",
    "            'MEAS-151208-4_ele17_ele24.kwik',\n",
    "            'MEAS-151208-4_ele25_ele32.kwik',\n",
    "            'MEAS-151208-4_ele33_ele40.kwik',\n",
    "            'MEAS-151208-4_ele41_ele48.kwik',\n",
    "            'MEAS-151208-4_ele49_ele56.kwik',\n",
    "            'MEAS-151208-4_ele57_ele64.kwik',\n",
    "            'MEAS-151208-5_ele01_ele08.kwik',\n",
    "            'MEAS-151208-5_ele09_ele16.kwik',\n",
    "            'MEAS-151208-5_ele17_ele24.kwik',\n",
    "            'MEAS-151208-5_ele25_ele32.kwik',\n",
    "            'MEAS-151208-5_ele33_ele40.kwik',\n",
    "            'MEAS-151208-5_ele41_ele48.kwik',\n",
    "            'MEAS-151208-5_ele49_ele56.kwik',\n",
    "            'MEAS-151208-5_ele57_ele64.kwik']\n",
    "\n",
    "\n",
    "files31 = [ #'MEAS-151210-1_ele01_ele08.kwik',  no units\n",
    "            #'MEAS-151210-1_ele09_ele16.kwik',  no units\n",
    "            #'MEAS-151210-1_ele17_ele24.kwik',  no units\n",
    "            #'MEAS-151210-1_ele25_ele32.kwik',  no units\n",
    "            #'MEAS-151210-1_ele33_ele40.kwik',  no units\n",
    "            'MEAS-151210-1_ele41_ele48.kwik',\n",
    "            'MEAS-151210-1_ele49_ele56.kwik',\n",
    "            'MEAS-151210-1_ele57_ele64.kwik',\n",
    "            #'MEAS-151210-2_ele01_ele08.kwik',   out of S2\n",
    "            #'MEAS-151210-2_ele09_ele16.kwik',   out of S2\n",
    "            #'MEAS-151210-2_ele17_ele24.kwik',   out of S2\n",
    "            #'MEAS-151210-2_ele25_ele32.kwik',   out of S2\n",
    "            'MEAS-151210-2_ele33_ele40.kwik',\n",
    "            'MEAS-151210-2_ele41_ele48.kwik',\n",
    "            'MEAS-151210-2_ele49_ele56.kwik',\n",
    "            'MEAS-151210-2_ele57_ele64.kwik',\n",
    "            #'MEAS-151210-3_ele01_ele08.kwik',   out of S2\n",
    "            #'MEAS-151210-3_ele09_ele16.kwik',   no units\n",
    "            #'MEAS-151210-3_ele17_ele24.kwik',   no units\n",
    "            #'MEAS-151210-3_ele25_ele32.kwik',   out of S2\n",
    "            'MEAS-151210-3_ele33_ele40.kwik',\n",
    "            'MEAS-151210-3_ele41_ele48.kwik',\n",
    "            'MEAS-151210-3_ele49_ele56.kwik',\n",
    "            'MEAS-151210-3_ele57_ele64.kwik']\n",
    "\n",
    "files32 = [ 'MEAS-151214-1_ele01_ele08.kwik',\n",
    "            'MEAS-151214-1_ele09_ele16.kwik',\n",
    "            'MEAS-151214-1_ele17_ele24.kwik',\n",
    "            'MEAS-151214-1_ele25_ele32.kwik',\n",
    "            'MEAS-151214-1_ele33_ele40.kwik',\n",
    "            'MEAS-151214-2_ele01_ele08.kwik',\n",
    "            'MEAS-151214-2_ele09_ele16.kwik',\n",
    "            'MEAS-151214-2_ele17_ele24.kwik',\n",
    "            'MEAS-151214-2_ele25_ele32.kwik',\n",
    "            'MEAS-151214-2_ele33_ele40.kwik']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------\n",
    "# Here I create my dictionary of experiments\n",
    "Expe={}\n",
    "Vtags={}\n",
    "Stim={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "    Vtags[num] = dict()\n",
    "#---------------------------------------\n",
    "i=0        \n",
    "for meas in np.append(m164[0:4],m364[0:2]):\n",
    "    Expe[20][meas] = files20[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0 \n",
    "for meas in np.append(m164[0:4],m364[0:4]):\n",
    "    Expe[22][meas] = files22[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0 \n",
    "for meas in np.append(m164[0:2],m264[0:5]):\n",
    "    Expe[23][meas] = files23[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0\n",
    "for meas in np.append(m164[4:8],m264[5:8]):    \n",
    "    Expe[24][meas] = files24[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0 \n",
    "for meas in np.append(m164,m264):    \n",
    "    Expe[25][meas] = files25[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0\n",
    "for meas in np.append(m164[0:7],m264[0:4]):\n",
    "    Expe[26][meas] = files26[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "i=0\n",
    "for meas in np.append(np.append(m164[0:7],m264),m364):    \n",
    "    Expe[28][meas] = files28[i]\n",
    "    i+=1\n",
    "#---------------------------------------    \n",
    "i=0\n",
    "for meas in np.append(np.append(m164,m264),m364):    \n",
    "    Expe[27][meas] = files27[i]\n",
    "    Expe[29][meas] = files29[i]\n",
    "    Expe[30][meas] = files30[i]\n",
    "    i+=1\n",
    "#---------------------------------------    \n",
    "for meas in m464:\n",
    "    Expe[30][meas] = files30[i]\n",
    "    i+=1\n",
    "i=0\n",
    "#---------------------------------------    \n",
    "i=0\n",
    "for meas in np.append(np.append(m164[5:8],m264[4:8]),m364[4:8]):    \n",
    "    Expe[31][meas] = files31[i]\n",
    "    i+=1\n",
    "i=0\n",
    "#---------------------------------------    \n",
    "for meas in np.append(m164[0:5],m264[0:5]):\n",
    "    Expe[32][meas] = files32[i]\n",
    "    i+=1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Vtag files \n",
    "Vtags[20] = ['MEAS-150707-1_Vtag1.dat','nada','MEAS-150707-23_Vtag1.dat']\n",
    "Vtags[22] = ['MEAS-150716-12_Vtag1.dat','nada','MEAS-150716-3_Vtag1.dat']\n",
    "Vtags[23] = ['MEAS-151027-1_Vtag1.dat','MEAS-151027-2_Vtag1.dat']\n",
    "Vtags[23] = ['MEAS-151027-1_Vtag1.dat','MEAS-151027-2_Vtag1.dat']\n",
    "Vtags[24] = ['MEAS-151103-1_Vtag1.dat','MEAS-151103-2_Vtag1.dat']\n",
    "Vtags[25] = ['MEAS-151105-1good_Vtag1.dat','MEAS-151105-2_Vtag1.dat']\n",
    "Vtags[26] = ['MEAS-151110-1_Vtag1.dat','MEAS-151110-2_Vtag1.dat','MEAS-151110-3_Vtag1.dat']\n",
    "Vtags[27] = ['MEAS-151112-1_Vtag1.dat','MEAS-151112-2_Vtag1.dat','MEAS-151112-3_Vtag1.dat']\n",
    "Vtags[28] = ['MEAS-151116-1_Vtag1.dat','MEAS-151116-2_Vtag1.dat','MEAS-151116-3_Vtag1.dat']\n",
    "Vtags[29] = ['MEAS-151118-1_Vtag1.dat','MEAS-151118-2_Vtag1.dat','MEAS-151118-3_Vtag1.dat']\n",
    "Vtags[30] = ['MEAS-151208-2_Vtag1.dat','MEAS-151208-3_Vtag1.dat','MEAS-151208-4_Vtag1.dat','MEAS-151208-5_Vtag1.dat']\n",
    "Vtags[31] = ['MEAS-151210-1_Vtag1.dat','MEAS-151210-2_Vtag1.dat','MEAS-151210-3_Vtag1.dat']\n",
    "Vtags[32] = ['MEAS-151214-1_Vtag1.dat','MEAS-151214-2_Vtag1.dat']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Stimulus type\n",
    "for i in range(23,33):\n",
    "    Stim[i] = 'big_STIM_FC_corrected'\n",
    "for i in range(15,23):\n",
    "    Stim[i] = 'big_STIM'\n",
    "for i in range(10,15):\n",
    "    Stim[i] = 'small_STIM'  \n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "#Root folder to work in, such all will be in subfolders \n",
    "#e.g.: \"/EXP_23/m1s1/\" for data or \"/STIM/\" for stims\n",
    "rootF = '/home/matias/WORKSPACE/'    \n",
    "stimFolder = rootF +'STIM/'\n",
    "\n",
    "#I have a separate folder for exp 22 and before\n",
    "rootF_kwiks = rootF    #uncomment this to work with the other root folder\n",
    "#rootF_kwiks = '/media/matias/DATA/WORKSPACE2/'\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Initialize wave features dictionary\n",
    "PSTHdata = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "group: 2\n",
      "m1s1\n",
      "   reading stim at: m1s1\n",
      "   trimming stim at: m1s1\n",
      "m1s2\n",
      "   building psths\n",
      "m1s3\n",
      "   building psths\n",
      "m1s4\n",
      "   building psths\n",
      "m3s1\n",
      "   reading stim at: m3s1\n",
      "   trimming stim at: m3s1\n",
      "   building psths\n",
      "m3s2\n",
      "   building psths\n",
      "m3s3\n",
      "   building psths\n",
      "m3s4\n",
      "   building psths\n",
      "   saving\n"
     ]
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [22]#[23,24,26,27,28,29,30,31,32]#[20,22,23,24,26,27,28,29,30,31,32] #Expe                                        #select experiment numbers!\n",
    "grupete = [2]   #select cluster groups! 2 for good clusters 1 for multiunits, 3 for unsorted\n",
    "\n",
    "#select measurement and/or shanks!\n",
    "#Measurements = m264[7:8]           #['m1s1']#['m3s1','m3s3']#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']   \n",
    "\n",
    "#select type of stimuli, for PSTH is only 'F' and this does not change anything\n",
    "choices = ['F','C','U']                      #select stimulus type (for STA and STC)\n",
    "\n",
    "# choice code not to ploteverything at the same time\n",
    "ploteo = [1,0,0,0]                                           #1 to make plots: psth,sta,ufc,stc\n",
    "\n",
    "dirs =[]\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "last_exp=0     #we use this to load stim only when we change experiment\n",
    "for expe in SelExp:\n",
    "    \n",
    "    PSTHdata = {}\n",
    "    PSTH_spikes_counts = {}\n",
    "    \n",
    "    Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    print(expe)\n",
    "\n",
    "    #This two lines are to account for diffrerent stims when looping diffrerent experiments\n",
    "    binname= stimFolder + Stim[expe] + '/Stimulus_UCC.bin'     \n",
    "    textname=stimFolder + Stim[expe] + '/Stimulus_UCC.txt'\n",
    "    \n",
    "    last_meas =0   #we use this to find when we change measurement to load Vtag and stim again\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits, multiunits, unsorted...\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits 3 for unsorted\n",
    "        #folder names\n",
    "        if group ==3:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFallRM/EXP_'+str(expe),rootF + 'OUTPUT/PDFallRM/STC/EXP_'+str(expe)]\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFall/EXP_'+str(expe),rootF + 'OUTPUT/PDFall/STC/EXP_'+str(expe)]\n",
    "        if group ==1:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFallM/EXP_'+str(expe),rootF + 'OUTPUT/PDFallM/STC/EXP_'+str(expe)]\n",
    "        print('group:', group)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        #Measurements = sorted((Expe[expe]))\n",
    "        \n",
    "        for meas in Measurements:           \n",
    "            print(meas)\n",
    "            current_meas = int(meas[1])   #measurement number\n",
    "            #---------------------------------------------------------------\n",
    "            #select datafile\n",
    "            sp_file = rootF_kwiks + 'EXP_' + str(expe) +'/Spike_Sorting/'+ meas +'/'+ Expe[expe][meas]\n",
    "            #load datafile\n",
    "            Spikes, sampling_freq = readkwikinfo(sp_file, group)  \n",
    "            #---------------------------------------------------------------\n",
    "            #load stimulus if looping new experiment, without trimming\n",
    "            if expe!=last_exp or (expe==20 and meas=='m3s1') or (expe==22 and meas=='m3s1'):\n",
    "                stimraw = []\n",
    "                stimtyperaw=[]\n",
    "                print(\"   reading stim at:\",  meas)\n",
    "                stimraw,stimtyperaw = read_stimulus(expe,meas)\n",
    "\n",
    "            #---------------------------------------------------------------\n",
    "            #load Vtag if looping new measurement\n",
    "            if (last_meas!=current_meas): #or (expe!=last_exp):   \n",
    "                # get Vtag name\n",
    "                measV=int(meas[1])-1\n",
    "                bin_file = rootF_kwiks + 'EXP_' + str(expe) +'/' + Vtags[expe][measV]\n",
    "                #-----------------------------------------------------------\n",
    "                Vtag1 =[]                \n",
    "                Vtag1 = np.fromfile(file=bin_file, dtype=np.int16)\n",
    "                # here we trim down stim and stimtype from Vtag1 information\n",
    "                print(\"   trimming stim at:\", meas)\n",
    "                stim = []\n",
    "                stimtype=[]\n",
    "                stim, stimtype,starts, stops = readVtag(Vtag1,stimraw,stimtyperaw)\n",
    "                                          \n",
    "            last_meas = current_meas     #update measurement variable\n",
    "            last_exp = expe              #update experiment variable\n",
    "            \n",
    "            if len(Spikes.keys())>0:                              #do only if there are clusters\n",
    "                #Build PSTHs\n",
    "                t_before = .100  \n",
    "                t_after = .100\n",
    "                \n",
    "                print('   building psths')\n",
    "                #PSTH_spikes_counts, hist_output = BuildPSTH(stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops,expe,meas)\n",
    "                PSTH_spikes_counts= BuildPSTH(stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops,expe,meas)\n",
    "           \n",
    "            PSTHdata.update(PSTH_spikes_counts)\n",
    "            #print(sorted(list(PSTHdata.keys())))\n",
    "\n",
    "            #PSTHdata.update(hist_output)\n",
    "    \n",
    "    print('   saving')\n",
    "    if group == 2:\n",
    "        filesave =rootF +'S2_git/data/'+'psthdata' + str(expe)\n",
    "    else:\n",
    "        filesave =rootF +'S2_git/data/'+ 'psthdataMultiR' + str(expe)\n",
    "        \n",
    "    save_obj(PSTHdata,filesave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['psth_counts', 'meas', 'psth_length', 'clusnum', 'psth_times', 'exp', 'shank'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filesave\n",
    "\n",
    "sorted(list(PSTHdata.keys()))\n",
    "PSTHdata['exp20_m1s1_c29'].keys()\n",
    "\n",
    "data = rootF +'S2_git/data/'+'psthdata' + str(22)\n",
    "\n",
    "a = load_obj(data)\n",
    "\n",
    "a['exp22_m3s4_c1138'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update spiketimes to wavedataAll\n",
    "SelExp = [20] #[22,24,26,27,28,29,30,31,32] #Expe                                        #select experiment numbers!\n",
    "\n",
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "\n",
    "for e in SelExp:\n",
    "\n",
    "    data = Folder +'/wavedata'+ str(e)\n",
    "    wavedata = load_obj(data)\n",
    "\n",
    "    idx = list(wavedata.keys())\n",
    "\n",
    "    datapsth = Folder +'/psthdata' + str(e)\n",
    "    psthdata = load_obj(datapsth)\n",
    "\n",
    "\n",
    "    for n in idx:\n",
    "        wavedata[n].update(psthdata[n])    \n",
    "            \n",
    "    data = Folder +'data/datamix' + str(e)\n",
    "\n",
    "    save_obj(wavedata, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = list(PSTHdata.keys())\n",
    "PSTHdata[idx[0]].keys()\n",
    "#PSTHdata[idx[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PSTHdata[idx[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
