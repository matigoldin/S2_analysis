{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io, linalg\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from phy.io import KwikModel\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os as os\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getexpinfo(kwik) :\n",
    "    if '150716' in kwik : \n",
    "        exp=22\n",
    "    if '151027' in kwik : \n",
    "        exp=23\n",
    "    if '151103' in kwik : \n",
    "        exp=24\n",
    "    if '151105' in kwik : \n",
    "        exp=25\n",
    "    if '151110' in kwik : \n",
    "        exp=26\n",
    "    if '151112' in kwik : \n",
    "        exp=27\n",
    "    if '151116' in kwik : \n",
    "        exp=28\n",
    "    if '151118' in kwik : \n",
    "        exp=29\n",
    "    if '151208' in kwik : \n",
    "        exp=30\n",
    "    if '151210' in kwik : \n",
    "        exp=31\n",
    "    if '151214' in kwik : \n",
    "        exp=32\n",
    "     \n",
    "    if 'ele01_ele08' in kwik : \n",
    "        shank=1\n",
    "    if 'ele09_ele16' in kwik : \n",
    "        shank=2\n",
    "    if 'ele17_ele24' in kwik : \n",
    "        shank=3\n",
    "    if 'ele25_ele32' in kwik : \n",
    "        shank=4\n",
    "    if 'ele33_ele40' in kwik : \n",
    "        shank=5\n",
    "    if 'ele41_ele48' in kwik : \n",
    "        shank=6\n",
    "    if 'ele49_ele56' in kwik : \n",
    "        shank=7\n",
    "    if 'ele57_ele64' in kwik : \n",
    "        shank=8\n",
    "        \n",
    "    if '1_ele' in kwik : \n",
    "        meas=1\n",
    "    if '2_ele' in kwik : \n",
    "        meas=2\n",
    "    if '3_ele' in kwik : \n",
    "        meas=3\n",
    "    \n",
    "    if exp==30 :\n",
    "        if '-2_ele' in kwik : \n",
    "            meas=1\n",
    "        if '-3_ele' in kwik : \n",
    "            meas=2\n",
    "        if '-4_ele' in kwik : \n",
    "            meas=3\n",
    "        if '-5_ele' in kwik : \n",
    "            meas=4\n",
    "    return exp, meas, shank\n",
    "\n",
    "def getwaveforms(kwik, UseAll=True) :\n",
    "    ## This function will extract the waveforms from a kwik file and its associated dat file.\n",
    "    ## If the UseAll option is True, all waveforms will be extracted including the ones that \n",
    "    ## are in clusters that were not included in the analysis\n",
    "    ## If the UseAll option is False, only the good clusters will be taken and the cluster which\n",
    "    ## was not marked as good and has the largest number of events will be considered the noise cluster\n",
    "    if UseAll==False :\n",
    "        model = KwikModel(kwik) # load kwik model from file\n",
    "        clusters = model.spike_clusters # extract the clusters\n",
    "        cluster_groups = model.cluster_groups # extract cluster group dictionary\n",
    "        noiseclust = {} #initialize noise cluster dictionary\n",
    "        for key, value in cluster_groups.items() : \n",
    "            if value != 2 : # look at all clusters that are not good\n",
    "                noiseclust[key] = len(np.where(clusters==key)[0]) # store the size of each in dictionary\n",
    "        v = list(noiseclust.values()) # list all the sizes of nongood clusters\n",
    "        k = list(noiseclust.keys()) # list all the identities of nongood clusters\n",
    "        noisecluster = k[v.index(max(v))] # finds identity of largest nongood cluster\n",
    "    \n",
    "        inds = [] # initialize the good waveforms to get\n",
    "        waveformdata = np.zeros(model.waveforms.shape) # initialize waveforms\n",
    "        for i in np.arange(waveformdata.shape[0]) :\n",
    "            waveformdata[i,:,:] = model.waveforms[i] # add all waveforms at first\n",
    "            if cluster_groups[clusters[i]]==2 :\n",
    "                inds.append(i) # store the indexes of good waveforms to use\n",
    "            if clusters[i]==noisecluster :\n",
    "                inds.append(i) # store the indexes of noise waveforms to use\n",
    "        waves = waveformdata[inds,:,:] # restrict waveforms returned to just good and noise clusters\n",
    "        clusters = clusters[inds] # restrict the cluster list returned to just good and noise clusters\n",
    "    \n",
    "    if UseAll==True :\n",
    "        model = KwikModel(kwik) # load kwik model from file\n",
    "        clusters = model.spike_clusters # extract the clusters\n",
    "        cluster_groups = model.cluster_groups # extract cluster gruop dictionary\n",
    "        waves = np.zeros(model.waveforms.shape) # initialize waveforms\n",
    "        for i in np.arange(waves.shape[0]) :\n",
    "            waves[i,:,:] = model.waveforms[i] # add all waveforms\n",
    "    return waves, clusters, cluster_groups\n",
    "\n",
    "def getfeatures(kwik, numpcs=3, UseAll=True) :\n",
    "    ## This function is to be used if rather than calculating new features, you take the features that KK used\n",
    "    ## when it did the clustering\n",
    "    if UseAll==False :\n",
    "        model = KwikModel(kwik) # load kwik model from file\n",
    "        clusters = model.spike_clusters # extract the clusters\n",
    "        cluster_groups = model.cluster_groups # extract cluster group dictionary\n",
    "        noiseclust = {} #initialize noise cluster dictionary\n",
    "        for key, value in cluster_groups.items() : \n",
    "            if value != 2 : # look at all clusters that are not good\n",
    "                noiseclust[key] = len(np.where(clusters==key)[0]) # store the size of each in dictionary\n",
    "        v = list(noiseclust.values()) # list all the sizes of nongood clusters\n",
    "        k = list(noiseclust.keys()) # list all the identities of nongood clusters\n",
    "        noisecluster = k[v.index(max(v))] # finds identity of largest nongood cluster\n",
    "    \n",
    "        inds = [] # initialize the good waveforms to get\n",
    "        features = model.features # extract features\n",
    "        numelectrodes = np.int((features.shape[1]/numpcs))\n",
    "        f = np.zeros([features.shape[0], numpcs, numelectrodes]) # initialize pcs data structure\n",
    "        for i in np.arange(features.shape[0]) :\n",
    "            f[i,:,:] = np.reshape(features[i], [numpcs, numelectrodes], order='F') # add all pcs at first\n",
    "            if cluster_groups[clusters[i]]==2 :\n",
    "                inds.append(i) # store the indexes of good waveforms to use\n",
    "            if clusters[i]==noisecluster :\n",
    "                inds.append(i) # store the indexes of noise waveforms to use\n",
    "        \n",
    "        pcs = f[inds,:,:] # restrict waveforms returned to just good and noise clusters\n",
    "        clusters = clusters[inds] # restrict the cluster list returned to just good and noise clusters\n",
    "    \n",
    "    if UseAll==True :\n",
    "        model = KwikModel(kwik) # load kwik model from file\n",
    "        clusters = model.spike_clusters # extract the clusters\n",
    "        cluster_groups = model.cluster_groups # extract cluster group dictionary\n",
    "        features = model.features # extract features \n",
    "        pcs = np.zeros([features.shape[0], numpcs, numelectrodes]) # initialize pcs data structure\n",
    "        for i in np.arange(features.shape[0]) :\n",
    "            pcs[i,:,:] = np.reshape(features[i], [numpcs, numelectrodes], order='F')\n",
    "    return pcs, clusters, cluster_groups, numelectrodes\n",
    "\n",
    "def EnergyNorm(waveformdata, enorm=True) :\n",
    "    waveformsnorm = np.zeros(waveformdata.shape) # initialize normalized waveforms\n",
    "    E = np.zeros([waveformdata.shape[0], 1, waveformdata.shape[2]]) # initialize Energy\n",
    "    for i in np.arange(waveformsnorm.shape[0]) :\n",
    "        for j in np.arange(waveformsnorm.shape[2]) : \n",
    "            E[i,:,j] = np.sqrt(np.sum(np.square(waveformdata[i,:,j])))/waveformdata.shape[1] #compute energy\n",
    "            waveformsnorm[i,:,j] = waveformdata[i,:,j]/E[i,:,j] #normalize\n",
    "    if enorm == False :\n",
    "        waveformsnorm = waveformdata\n",
    "    return waveformsnorm, E\n",
    "\n",
    "def PCA(waveformdata, numpcs=3) :\n",
    "    pcs = np.zeros([waveformdata.shape[0], numpcs, waveformdata.shape[2]]) #initialize pcs\n",
    "    for ch in np.arange(waveformdata.shape[2]) :\n",
    "        data = waveformdata[:,:,ch] - waveformdata[:,:,ch].mean(axis=0) #mean center\n",
    "        R = np.cov(data, rowvar=False) #covariance matrix\n",
    "        evals, evecs = linalg.eigh(R) #eigenvector decomposition\n",
    "        idx = np.argsort(evals)[::-1] #find the highest eigenvalues and return there index\n",
    "        evecs = evecs[:,idx] #sort eigenvectors\n",
    "        evals = evals[idx] #sort eigenvalues\n",
    "        evecs = evecs[:, :numpcs] #throw out eigenvectors outside the desired range\n",
    "        pcs[:,:,ch] = np.dot(evecs.T, data.T).T #project to compute PCS\n",
    "    return pcs\n",
    "\n",
    "def CalcMahalDist(waveformdata, E, pcs, clusters, cluster_groups, pcsinc=3, numelectrodes=8, enorm=True) :\n",
    "    \n",
    "    goodclusts = [] #initialize good cluster list\n",
    "    for key, value in cluster_groups.items() :\n",
    "        if value==2 :\n",
    "            goodclusts.append(key) #adds clusters marked good to list\n",
    "    goodclusts = np.sort(goodclusts)\n",
    "    if enorm == True :\n",
    "        numfeatures = (1+pcsinc)*numelectrodes #features are energy plus number of pcs included (pcsinc)\n",
    "    if enorm == False :\n",
    "        numfeatures = pcsinc*numelectrodes\n",
    "    featurevecs = np.zeros([waveformdata.shape[0], numfeatures])\n",
    "    for i in np.arange(waveformdata.shape[0]) :\n",
    "        for j in np.arange(waveformdata.shape[2]) :\n",
    "            if enorm == True :\n",
    "                featurevecs[i,j] = E[i,0,j]\n",
    "                if pcsinc==1 :\n",
    "                    featurevecs[i,j+numelectrodes] = pcs[i,0,j]\n",
    "                if pcsinc==2 :\n",
    "                    featurevecs[i,j+numelectrodes] = pcs[i,0,j]\n",
    "                    featurevecs[i,j+numelectrodes*2] = pcs[i,1,j]\n",
    "                if pcsinc==3 :\n",
    "                    featurevecs[i,j+numelectrodes] = pcs[i,0,j]\n",
    "                    featurevecs[i,j+numelectrodes*2] = pcs[i,1,j]\n",
    "                    featurevecs[i,j+numelectrodes*3] = pcs[i,2,j]\n",
    "            if enorm == False :\n",
    "                if pcsinc==1 :\n",
    "                    featurevecs[i,j] = pcs[i,0,j]\n",
    "                if pcsinc==2 :\n",
    "                    featurevecs[i,j] = pcs[i,0,j]\n",
    "                    featurevecs[i,j+numelectrodes] = pcs[i,1,j]\n",
    "                if pcsinc==3 :\n",
    "                    featurevecs[i,j] = pcs[i,0,j]\n",
    "                    featurevecs[i,j+numelectrodes] = pcs[i,1,j]\n",
    "                    featurevecs[i,j+numelectrodes*2] = pcs[i,2,j]\n",
    "                    \n",
    "    muC = {} #initialize cluster centres\n",
    "    covC = {} #initialize cluster covariances\n",
    "    for clust in goodclusts :\n",
    "        inds = np.where(clusters==clust)[0]\n",
    "        if enorm == True :\n",
    "            if pcsinc==1 :\n",
    "                muC[clust] = np.array(np.concatenate(([np.mean(E[inds,0,:], axis=0), np.mean(pcs[inds,0,:], axis=0)])))\n",
    "                # This is coded to use the Energy and the 1st PC as features across the 8 channels\n",
    "            if pcsinc==2 :\n",
    "                muC[clust] = np.array(np.concatenate(([np.mean(E[inds,0,:], axis=0), np.mean(pcs[inds,0,:], axis=0), np.mean(pcs[inds,1,:], axis=0)])))\n",
    "                # This is coded to use the Energy, 1st, and 2nd PC as features across the 8 channels\n",
    "            if pcsinc==3 :\n",
    "                muC[clust] = np.array(np.concatenate(([np.mean(E[inds,0,:], axis=0), np.mean(pcs[inds,0,:], axis=0), np.mean(pcs[inds,1,:], axis=0), np.mean(pcs[inds,2,:], axis=0)])))\n",
    "                # This is coded to use the Energy, 1st, 2nd, and 3rd PC as features across the 8 channels\n",
    "            covC[clust] = np.cov(featurevecs[inds,:]-np.mean(featurevecs[inds,:], axis=0), rowvar=False)\n",
    "        if enorm == False :\n",
    "            if pcsinc==1 :\n",
    "                muC[clust] = np.mean(pcs[inds,0,:], axis=0)\n",
    "                # This is coded to use the 1st PC as features across the 8 channels\n",
    "            if pcsinc==2 :\n",
    "                muC[clust] = np.array(np.concatenate(([np.mean(pcs[inds,0,:], axis=0), np.mean(pcs[inds,1,:], axis=0)])))\n",
    "                # This is coded to use the 1st and 2nd PC as features across the 8 channels\n",
    "            if pcsinc==3 :\n",
    "                muC[clust] = np.array(np.concatenate(([np.mean(pcs[inds,0,:], axis=0), np.mean(pcs[inds,1,:], axis=0), np.mean(pcs[inds,2,:], axis=0)])))\n",
    "                # This is coded to use the 1st, 2nd, and 3rd PC as features across the 8 channels\n",
    "            covC[clust] = np.cov(featurevecs[inds,:]-np.mean(featurevecs[inds,:], axis=0), rowvar=False)\n",
    "            \n",
    "    D = np.zeros([waveformdata.shape[0], len(goodclusts)]) #initialize Mahalanobis distance\n",
    "    j=0\n",
    "    for clust in goodclusts :\n",
    "        mu = muC[clust]\n",
    "        sigma = linalg.inv(covC[clust])\n",
    "        for i in np.arange(waveformdata.shape[0]) :\n",
    "            D[i,j] = np.dot(np.dot(((featurevecs[i,:]-mu).T), sigma), (featurevecs[i,:]-mu))\n",
    "        j+=1\n",
    "    return D, goodclusts, featurevecs, muC, covC\n",
    "\n",
    "def computeLratio(D, clusters, goodclusts, df=24) :\n",
    "    Lr = {}\n",
    "    j = 0\n",
    "    for c in goodclusts :\n",
    "        Dtemp = D[np.where(clusters!=c)[0],j]\n",
    "        Lratio = 0\n",
    "        for i in np.arange(Dtemp.shape[0]) :\n",
    "            Lratio += 1 - chi2.cdf(Dtemp[i], df, loc=0, scale=1)\n",
    "        Lr[c] = Lratio/len(np.where(clusters==c)[0])\n",
    "        j+=1\n",
    "    return Lr\n",
    "\n",
    "def computeIsolationDistance(D, clusters, goodclusts) :\n",
    "    Id = {}\n",
    "    j = 0\n",
    "    for c in goodclusts :\n",
    "        Dtemp = D[np.where(clusters!=c)[0],j] # look at one cluster, just the out of cluster spikes, column j\n",
    "        idx = np.argsort(Dtemp) # find the order or indexes to sort this array from smallest to largest\n",
    "        Dtemp = Dtemp[idx] # sort those spikes by Dvalue, smallest to largest\n",
    "        indx = len(np.where(clusters==c)[0]) # find the index corresponding to the number of spikes in the cluster\n",
    "        Id[c] = Dtemp[indx-1] # subtract one because the indexing starts at 0\n",
    "        j+=1\n",
    "    return Id\n",
    "\n",
    "def ClusterSummary(D, Lr, Id, goodclusts, pdf_files_directory, exp, meas, shank) :   \n",
    "    MIN, MAX = 0.1, 10.0\n",
    "    i=0\n",
    "    numclusts = len(goodclusts)\n",
    "    numbins = 500\n",
    "    nGOOD = np.zeros([numclusts,numbins-1])\n",
    "    nNOISE = np.zeros([numclusts,numbins-1])\n",
    "    for c in goodclusts :\n",
    "        GOOD = D[np.where(clusters==c)[0],i]\n",
    "        NOISE = D[np.where(clusters!=c)[0],i]\n",
    "        n1, bins, patches = hist(np.log10(GOOD), bins = 10 ** np.linspace(np.log10(MIN), np.log10(MAX), numbins))\n",
    "        nGOOD[i,:] = n1\n",
    "        close()\n",
    "        n2, bins, patches = hist(np.log10(NOISE), bins = 10 ** np.linspace(np.log10(MIN), np.log10(MAX), numbins))\n",
    "        nNOISE[i,:] = n2\n",
    "        close()\n",
    "        i+=1\n",
    "    \n",
    "    normnum = (1/np.sum(nGOOD+nNOISE))\n",
    "    height = np.max(nGOOD, axis=1)/(1/normnum)\n",
    "    clf()\n",
    "    \n",
    "    xmin = np.log10(0.99*np.min(D))\n",
    "    xmax = np.log10(1.1*np.max(D))\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    for c in goodclusts :\n",
    "        GOOD = D[np.where(clusters==c)[0],i]\n",
    "        NOISE = D[np.where(clusters!=c)[0],i]\n",
    "        ax1 = subplot(np.int(np.floor((len(goodclusts))/3))+1,3,i+1, frame_on=True)\n",
    "        hist(np.log10(GOOD), bins = 10 ** np.linspace(np.log10(MIN), np.log10(MAX), numbins), color='b', alpha=0.5, edgecolor='none', histtype='stepfilled', label='n = '+str(len(GOOD)), weights=np.repeat(normnum, len(GOOD)))\n",
    "        hist(np.log10(NOISE), bins = 10 ** np.linspace(np.log10(MIN), np.log10(MAX), numbins), color='g', alpha=0.5, edgecolor='none', histtype='stepfilled', label='n = '+str(len(NOISE)), weights=np.repeat(normnum, len(NOISE)))\n",
    "        ymax = 1.1*height[i]\n",
    "        ylim(0, ymax)\n",
    "        xlim(xmin, xmax)\n",
    "        ax1.tick_params(axis='y', which='both', left='on', right='off', labelsize=4, width=0.8)\n",
    "        ax1.set_yticks(np.around(np.linspace(0, ymax, 4), decimals=6), minor=False)\n",
    "        ax1.yaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "        gca().set_xscale(\"log\")\n",
    "        ax1.tick_params(axis='x', which='both', bottom='on', top='off', labelbottom='off', width=0.8)\n",
    "        if c==goodclusts[-1] :\n",
    "            ax1.tick_params(axis='x', which='both', bottom='on', top='off', labelbottom='on', labelsize=4, width=0.8)\n",
    "            ax1.xaxis.set_minor_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax1.set_xlabel(r'$\\log_{10}(D^2)$', fontsize = 6)\n",
    "            ax1.xaxis.set_label_coords(0.5, -0.05)\n",
    "        ax1.set_title('Nrn' + str(c),fontsize=8)\n",
    "        handles, labels = ax1.get_legend_handles_labels()\n",
    "        legend = ax1.legend(handles, labels, loc=[0.1,0.5], prop={'size':4})\n",
    "        legend.set_title(title='Lr = '+str(np.around(Lr[c],decimals=2))+'\\nId = '+str(np.int(np.around(Id[c])))+'\\n', prop={'size':6})\n",
    "        legend.get_frame().set_linewidth(0.8)\n",
    "        legend.get_frame().set_edgecolor('red')\n",
    "        ax1.spines['bottom'].set_linewidth(0.8)\n",
    "        ax1.spines['bottom'].set_color('black')\n",
    "        ax1.spines['left'].set_linewidth(0.8)\n",
    "        ax1.spines['left'].set_color('black')\n",
    "        ax1.spines['right'].set_linewidth(0)\n",
    "        ax1.spines['top'].set_linewidth(0)        \n",
    "        i+=1\n",
    "    \n",
    "    suptitle('Cluster Statistics for ' + 'Exp' + str(exp) + '_Meas' + str(meas) + '_Shank' + str(shank),fontsize=12)\n",
    "    savefig(pdf_files_directory + 'Exp' + str(exp) + '_Meas' + str(meas) + '_Shank' + str(shank) + '_ClusterMetrics.pdf', format='pdf')\n",
    "    clf()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    left, width = 0.1, 0.65\n",
    "    bottom, height = 0.1, 0.65\n",
    "    bottom_h = left_h = left + width + 0.02\n",
    "    \n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_boxx = [left, bottom_h, width, 0.2]\n",
    "    rect_boxy = [left_h, bottom, 0.2, height]\n",
    "    \n",
    "    axScatter = plt.axes(rect_scatter)\n",
    "    axBoxx = plt.axes(rect_boxx)\n",
    "    axBoxy = plt.axes(rect_boxy)\n",
    "    axScatter.spines['bottom'].set_linewidth(0.8)\n",
    "    axScatter.spines['bottom'].set_color('black')\n",
    "    axScatter.spines['left'].set_linewidth(0.8)\n",
    "    axScatter.spines['left'].set_color('black')\n",
    "    axScatter.spines['right'].set_linewidth(0)\n",
    "    axScatter.spines['top'].set_linewidth(0)\n",
    "    axScatter.tick_params(axis='x', which='both', bottom='on', top='off', labelbottom='on', labelsize=8, width=0.8)\n",
    "    axScatter.tick_params(axis='y', which='both', left='on', right='off', labelleft='on', labelsize=8, width=0.8)\n",
    "    axScatter.set_xlabel(r'$L_{ratio}$', fontsize = 12)\n",
    "    axScatter.set_ylabel(r'$I_{dist}$', fontsize = 12)\n",
    "    axBoxx.spines['bottom'].set_linewidth(0)\n",
    "    axBoxx.spines['left'].set_linewidth(0)\n",
    "    axBoxx.spines['right'].set_linewidth(0)\n",
    "    axBoxx.spines['top'].set_linewidth(0)\n",
    "    axBoxx.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    axBoxx.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "    axBoxy.spines['bottom'].set_linewidth(0)\n",
    "    axBoxy.spines['left'].set_linewidth(0)\n",
    "    axBoxy.spines['right'].set_linewidth(0)\n",
    "    axBoxy.spines['top'].set_linewidth(0)\n",
    "    axBoxy.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    axBoxy.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "    \n",
    "    Lratio = np.zeros(len(Lr))\n",
    "    Idist = np.zeros(len(Id))\n",
    "    names = []\n",
    "    j=0\n",
    "    for c in goodclusts :\n",
    "        Lratio[j]=Lr[c]\n",
    "        Idist[j]=Id[c]\n",
    "        names.append(c)\n",
    "        j+=1\n",
    "            \n",
    "    xlimit = np.max(np.fabs(Lratio))*1.1\n",
    "    ylimit = np.max(np.fabs(Idist))*1.1\n",
    "    axScatter.set_xlim((0, xlimit))\n",
    "    axScatter.set_ylim((0, ylimit))\n",
    "    axBoxx.set_xlim(axScatter.get_xlim())\n",
    "    axBoxy.set_ylim(axScatter.get_ylim())\n",
    "    \n",
    "    axScatter.scatter(Lratio, Idist)\n",
    "    \n",
    "    for i, txt in enumerate(names):\n",
    "        axScatter.annotate(txt, (Lratio[i],Idist[i]))\n",
    "    \n",
    "    axBoxx.boxplot(Lratio,0,'rs',0)\n",
    "    axBoxy.boxplot(Idist)\n",
    "    \n",
    "    suptitle('Summary Statistics for ' + 'Exp' + str(exp) + '_Meas' + str(meas) + '_Shank' + str(shank),fontsize=12)\n",
    "    savefig(pdf_files_directory + 'Exp' + str(exp) + '_Meas' + str(meas) + '_Shank' + str(shank) + '_MetricSummary.pdf', format='pdf')\n",
    "    clf()\n",
    "\n",
    "def getkwiks(startdir='.') :\n",
    "    kwikfiles = []\n",
    "    for dirpath, dirnames, filenames in os.walk(startdir) :\n",
    "        for filename in [f for f in filenames if f.endswith('.kwik')]:\n",
    "            kwikfiles.append(os.path.join(dirpath, filename))\n",
    "    return kwikfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwiks = getkwiks(startdir='.')\n",
    "numpcs=3\n",
    "\n",
    "for i in np.arange(len(kwiks)) :\n",
    "    kwik = kwiks[i]\n",
    "    method = 'kkfeatures'\n",
    "\n",
    "    if method=='kkfeatures' :\n",
    "        pcs, clusters, cluster_groups, numelectrodes = getfeatures(kwik, numpcs, False)\n",
    "        waveformdata = pcs\n",
    "        E = pcs[:,0,:]\n",
    "\n",
    "    if method=='waveforms' :\n",
    "        waveformdata, clusters, cluster_groups = getwaveforms(kwik, False)\n",
    "        waveformdata, E = EnergyNorm(waveformdata, enorm=False)\n",
    "        pcs = PCA(waveformdata, numpcs=3)\n",
    "\n",
    "    exp, meas, shank = getexpinfo(kwik)\n",
    "    D, goodclusts, featurevecs, muC, covC = CalcMahalDist(waveformdata, E, pcs, clusters, cluster_groups, pcsinc=3, enorm=False, numelectrodes=numelectrodes)\n",
    "    Lr = computeLratio(D, clusters, goodclusts, df=numelectrodes*numpcs)\n",
    "    Id = computeIsolationDistance(D, clusters, goodclusts)\n",
    "    ClusterSummary(D, Lr, Id, goodclusts, './', exp, meas, shank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
