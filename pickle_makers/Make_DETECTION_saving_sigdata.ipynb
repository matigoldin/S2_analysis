{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DETECTION and LATENCY using surpdata, sigdata.pckl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detet significant surprises for every neuron and save them\n",
    "\n",
    "It uses surprises from 5 to 55ms since after 55ms overlaps with next stimulus response\n",
    "It uses the Blanksurprise data for the thresholds\n",
    "\n",
    "It is made for:\n",
    "    - every neuron\n",
    "    - every whisker\n",
    "    - both directions\n",
    "        \n",
    "Three main cells used in order do:\n",
    "- Compute surprise\n",
    "- Detect significant whiskers\n",
    "- Compute Latencies\n",
    "\n",
    "Parameters are:\n",
    "    - sizesaboveth\n",
    "    - consecaboveth\n",
    "\n",
    "For latencies we remind:\n",
    "    - maxbin 20\n",
    "    - surpmax 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['arctanh', 'log', 'show_config', 'arccos', '__version__', 'log10', 'power', 'linalg', 'log2', 'test', 'arcsin', 'fft', 'sqrt', 'poisson']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#%autoreload 1\n",
    "#%aimport surp_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "import numpy as np\n",
    "from attrdict import AttrDict\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import sys\n",
    "sys.path.append('../functions') #this is where we put all the functions.py\n",
    "import exps_files_folders as EFF\n",
    "Expe, Vtags, Stim, rootF, stimFolder = EFF.eff()\n",
    "from save_load import *\n",
    "\n",
    "from surp_functions import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pval for blank threshold:  0.0001\n",
      "Thresholds for all binsizes :\n",
      "[[ 4.7]\n",
      " [ 4.3]\n",
      " [ 4.4]\n",
      " [ 4.4]\n",
      " [ 4.4]\n",
      " [ 4.5]\n",
      " [ 4.8]\n",
      " [ 5. ]\n",
      " [ 5.2]\n",
      " [ 5.4]\n",
      " [ 5.1]\n",
      " [ 5.2]\n",
      " [ 6.8]\n",
      " [ 6.8]\n",
      " [ 6.8]\n",
      " [ 6.8]\n",
      " [ 6.8]\n",
      " [ 6.8]\n",
      " [ 6.8]\n",
      " [ 6.8]]\n",
      "20\n",
      "Saving\n",
      "22\n",
      "Saving\n",
      "23\n",
      "Saving\n",
      "24\n",
      "Saving\n",
      "26\n",
      "Saving\n",
      "27\n",
      "Saving\n",
      "28\n",
      "Saving\n",
      "29\n",
      "Saving\n",
      "30\n",
      "Saving\n",
      "31\n",
      "Saving\n",
      "32\n",
      "Saving\n"
     ]
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [20,22,23,24,26,27,28,29,30,31,32] #Expe                           #select experiment numbers!\n",
    "\n",
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "\n",
    "thfile = Folder + '/Blanksurprise'\n",
    "Th = load_obj(thfile)\n",
    "\n",
    "# Threshold was computed for this 5 pvals: (0.01, 0.005, 0.001, 0.0005, 0.0001)\n",
    "# we select HERE the 0.005 at 4th position\n",
    "position = 5\n",
    "\n",
    "pvalue = Th.pval_list[position-1]\n",
    "print('Selected pval for blank threshold: ', pvalue)\n",
    "\n",
    "thresholds = Th.surp_thresh[:,position-1]\n",
    "print('Thresholds for all binsizes :')\n",
    "print( np.reshape(thresholds,[-1,1]))\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "for expe in SelExp:\n",
    "    print(expe)\n",
    "    \n",
    "    Detection = {}\n",
    "    #--------------------\n",
    "    # To load Surprise\n",
    "    surpdata = {}\n",
    "    surpfile = Folder +'/surpdata' + str(expe)\n",
    "    surpdata = load_obj(surpfile)\n",
    "    #--------------------\n",
    "       \n",
    "    idx = sorted(list(surpdata.keys()))\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # loop neurons\n",
    "    #--------------------------------------------------------------------------------\n",
    "    for n in idx[:]:\n",
    "        #print('   neuron: ' , n)\n",
    "        clus = surpdata[n].clusnum\n",
    "        meas = surpdata[n].meas\n",
    "        shank = surpdata[n].shank\n",
    "        surp = surpdata[n].surprise_data.Data\n",
    "       \n",
    "        #-------------------------------------------------------    \n",
    "        Detection[n] = AttrDict({})\n",
    "        Detection[n].update({'clusnum': clus, 'exp' : int(expe) , 'meas': meas , 'shank': shank})\n",
    "        #-------------------------------------------------------\n",
    "\n",
    "        # we give the whisker number blank stimulus\n",
    "        wblank = 20   \n",
    "        if expe <= 22:     #Only for EXP 22 or less: odd ELPHY piezo assignement\n",
    "            wblank = 11\n",
    "        #-------------------------------------------------------\n",
    "        #----------------------------------------------------\n",
    "        # we detect significant whiskers\n",
    "        surpmin = 5       #minimum latency in ms, so significance is computed from here\n",
    "        \n",
    "        nconsecaboveth = 1   # how many bins consecutive with surp above th to call it significant\n",
    "        nsizesaboveth = 2    #number of binnings where surprise to be significative for whisker to be significative\n",
    "\n",
    "        Detection[n].update({'detection_data': BuildSig(surp,thresholds,wblank,nconsecaboveth,surpmin,nsizesaboveth)})\n",
    "                               \n",
    "        #----------------------------------------------------\n",
    "        #-------------------------------------------------------\n",
    "        # we get the Latencies, only for the significant whiskers\n",
    "        surpmax= 55\n",
    "        maxbin = 20\n",
    "        Latencies = GetLatency(surp,Detection[n].detection_data, surpmax, maxbin, surpmin, thresholds)\n",
    "        Detection[n].update({'latency_data' : Latencies })\n",
    "       \n",
    "    print('Saving')\n",
    "    filesave =Folder +'/sigdata' + str(expe)\n",
    "    save_obj(Detection,filesave)                 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp20_m1s1_c29\n",
      "dict_keys(['Sig_strength', 'PWstrong', 'logic_tree_significants', 'PW', 'Sig_top', 'Sig_strength_norm', 'Sig_sizes', 'logic_tree_sig_sizes', 'Sig'])\n",
      "[[[ 0.  1.]\n",
      "  [ 0.  0.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 0.  0.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 0.  1.]\n",
      "  [ 0.  0.]\n",
      "  [ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 0.  0.]\n",
      "  [ 0.  1.]\n",
      "  [ 0.  0.]\n",
      "  [ 0.  1.]]\n",
      "\n",
      " [[ 1.  0.]\n",
      "  [ 1.  0.]\n",
      "  [ 0.  0.]\n",
      "  [ 1.  0.]\n",
      "  [ 1.  0.]]\n",
      "\n",
      " [[ 0.  0.]\n",
      "  [ 0.  1.]\n",
      "  [ 0.  1.]\n",
      "  [ 1.  0.]\n",
      "  [ 1.  1.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.03053435],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.13282443,  0.05343511],\n",
       "        [ 0.08396947,  0.00763359],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.78473282,  0.80916031],\n",
       "        [ 0.64885496,  0.50839695],\n",
       "        [ 0.        ,  0.03206107],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.01526718,  0.01526718]],\n",
       "\n",
       "       [[ 0.66870229,  0.38625954],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.03664122],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.01374046]],\n",
       "\n",
       "       [[ 0.04732824,  0.        ],\n",
       "        [ 0.0519084 ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.0778626 ,  0.        ],\n",
       "        [ 0.01068702,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.00916031],\n",
       "        [ 0.        ,  0.02900763],\n",
       "        [ 0.18931298,  0.        ],\n",
       "        [ 1.        ,  0.99083969]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "filesave =Folder +'/sigdata20' \n",
    "\n",
    "a = load_obj(filesave)\n",
    "\n",
    "idx = sorted(list(a.keys()))\n",
    "\n",
    "i=0\n",
    "\n",
    "n = idx[i]\n",
    "print(n)\n",
    "#print(a[n].keys())\n",
    "print(a[n].detection_data.keys())\n",
    "print(a[n].detection_data.Sig.reshape([5,5,2]))\n",
    "a[n].detection_data.Sig_strength_norm.reshape([5,5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['meas', 'clusnum', 'detection_data', 'exp', 'shank'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "\n",
    "\n",
    "filesave =Folder +'/sigdata20' \n",
    "\n",
    "a = load_obj(filesave)\n",
    "\n",
    "idx = list(a.keys())\n",
    "\n",
    "n = idx[0]\n",
    "\n",
    "\n",
    "a[n].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
