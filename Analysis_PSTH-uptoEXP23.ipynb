{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD PSTHs STAs AND STCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# READ STIMULUS\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Here we read the binary file with stimulus: 902 of 25 piezos x 1024 samples\n",
    "# Text file has the type of stimulus: F sparse, C correlated, U uncorrelated\n",
    "def read_stimulus(expe,meas,lenstim):\n",
    "    read_data = []\n",
    "    copy_data = []\n",
    "    txt_data = []\n",
    "    \n",
    "    global UFC\n",
    "    UFC = np.zeros(3)\n",
    "    \n",
    "    if expe>22: length = 923\n",
    "    else: length = 902   #stim files are different since exp 23\n",
    "    \n",
    "    #we load the stim file\n",
    "    bin_file = open(binname,'rb')\n",
    "    read_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "    read_data = read_data.reshape((length,25,10240))\n",
    "    txt_data = np.loadtxt(textname, dtype='S8')\n",
    "    txt_data = txt_data.view(np.chararray).decode('utf-8')\n",
    "    \n",
    "    #lenstim comes from the Vtag file for experiments that were ended before the last stim\n",
    "    if expe>22:\n",
    "        length1= lenstim\n",
    "        length2=0\n",
    "        \n",
    "        txt_data = np.append(txt_data[0:length1], txt_data[0:length2])\n",
    "\n",
    "        read_data = np.append(read_data[0:length1], read_data[0:length2],0)\n",
    "        read_data = read_data.reshape((length1+length2,25,10240))\n",
    "        close(binname)\n",
    "\n",
    "        bin_file = open(binname,'rb')\n",
    "        copy_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "        copy_data = copy_data.reshape((length,25,10240))\n",
    "\n",
    "        copy_data = np.append(copy_data[0:length1], copy_data[0:length2],0)\n",
    "        copy_data = copy_data.reshape((length1+length2,25,10240))\n",
    "        close(binname)\n",
    "        \n",
    "        UFC = np.zeros(3)\n",
    "        for i in range(lenstim):\n",
    "            if txt_data[i] == 'U': UFC[0]+=1\n",
    "            elif txt_data[i] == 'F': UFC[1]+=1\n",
    "            elif txt_data[i] == 'C': UFC[2]+=1\n",
    "        \n",
    "    else:\n",
    "        #-----------------------------------------------------------------------------------------------------------\n",
    "        #here we treat each experiment differently since we stopped before end, and recorded more than once in a site\n",
    "        if expe == 21 and meas ==2:\n",
    "            length2 =357\n",
    "            extra = 63\n",
    "            #there are 63 extra events in exp2 and 358 in exp3\n",
    "            ext = [0]*extra*25*10240\n",
    "            ext=np.array(ext)\n",
    "            ext = ext.reshape(extra,25,10240)\n",
    "            ext_text = ['B']*extra\n",
    "\n",
    "            txt_data = np.append(txt_data[0:length],ext_text)\n",
    "            txt_data = np.append(txt_data, txt_data[0:length2])\n",
    "            read_data = np.append(read_data[0:length],ext,0)\n",
    "            read_data = np.append(read_data,read_data[0:length2],0)   \n",
    "\n",
    "            close(binname)\n",
    "\n",
    "            bin_file = open(binname,'rb')\n",
    "            copy_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "            copy_data = copy_data.reshape((length,25,10240))\n",
    "            copy_data = np.append(copy_data[0:length],ext,0)\n",
    "            copy_data = np.append(copy_data,copy_data[0:length2],0)   \n",
    "\n",
    "            close(binname)\n",
    "        else:\n",
    "            if expe == 18 or (expe ==20 and meas==1) or (expe==21 and meas==1) or (expe==22 and meas==2):\n",
    "                    length1=902\n",
    "                    length2 =0\n",
    "            if expe == 20 and meas==2:\n",
    "                    length1 = 46 \n",
    "                    #there are 46 events in exp2 and 879 in exp3\n",
    "                    length2 =879\n",
    "            if expe == 22 and meas==1:\n",
    "                    length1=902\n",
    "                    length2 =93\n",
    "\n",
    "            txt_data = np.append(txt_data[0:length1], txt_data[0:length2])\n",
    "\n",
    "            read_data = np.append(read_data[0:length1], read_data[0:length2],0)\n",
    "            read_data = read_data.reshape((length1+length2,25,10240))\n",
    "            close(binname)\n",
    "\n",
    "            bin_file = open(binname,'rb')\n",
    "            copy_data = np.fromfile(file=bin_file, dtype=np.float32)\n",
    "            copy_data = copy_data.reshape((length,25,10240))\n",
    "\n",
    "            copy_data = np.append(copy_data[0:length1], copy_data[0:length2],0)\n",
    "            copy_data = copy_data.reshape((length1+length2,25,10240))\n",
    "            close(binname)\n",
    "\n",
    "        #this correction applies until exp 22, then whisker assignment is fine    \n",
    "        read_data[:, 11, :] = copy_data[:, 24, :]\n",
    "        read_data[:, 20, :] = copy_data[:, 11, :]\n",
    "        read_data[:, 21, :] = copy_data[:, 20, :]\n",
    "        read_data[:, 22, :] = copy_data[:, 21, :]\n",
    "        read_data[:, 23, :] = copy_data[:, 22, :]\n",
    "        read_data[:, 24, :] = copy_data[:, 23, :]\n",
    "        \n",
    "    \n",
    "        UFC = np.zeros(3)\n",
    "        for i in range(len(read_data)):\n",
    "            if txt_data[i] == 'U': UFC[0]+=1\n",
    "            elif txt_data[i] == 'F': UFC[1]+=1\n",
    "            elif txt_data[i] == 'C': UFC[2]+=1\n",
    "       #-----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return read_data, txt_data\n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "def readkwikinfo(kwik, grupete):\n",
    "    model = KwikModel(kwik)\n",
    "    spiketimes = model.spike_times\n",
    "    clusters = model.cluster_groups\n",
    "    sample_rate = model.sample_rate\n",
    "    \n",
    "    spikedata = dict()\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "                \n",
    "        if clustergroup==grupete:\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS PSTH\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildPSTH(Vtag1,stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops) :\n",
    "## The first task is to find the stimulus onset times for each whisker in each sweep in each direction\n",
    "    #stim, stimtype = read_stimulus()\n",
    "    stim = stim[np.where(stimtype=='F')[0], :, :]\n",
    "\n",
    "    stimtimes = {}\n",
    "    stimspersweep = 6  #as the maximum\n",
    "    FCsweeps = UFC[1]\n",
    "       \n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        timesUP = np.zeros((FCsweeps, stimspersweep))\n",
    "        timesDOWN = np.zeros((FCsweeps, stimspersweep))\n",
    "        for i in np.arange(len(stim), dtype='int') :\n",
    "            indsUP = np.where(stim[i, w, :]>0)[0]-1   #we correct for 0 at the start of stim\n",
    "            diffUP = indsUP[1:] - indsUP[:-1]\n",
    "            stimsup = len(indsUP)/28\n",
    "            timesUP[i,0:stimsup] = np.insert(indsUP[np.where(diffUP>1)[0]+1], 0, indsUP[0])\n",
    "            \n",
    "            indsDOWN = np.where(stim[i, w, :]<0)[0]-1 #we correct for 0 at the start of stim\n",
    "            diffDOWN = indsDOWN[1:] - indsDOWN[:-1]\n",
    "            stimsdown = len(indsDOWN)/28\n",
    "            timesDOWN[i,0:stimsdown] = np.insert(indsDOWN[np.where(diffDOWN>1)[0]+1], 0, indsDOWN[0])\n",
    "            \n",
    "        stimtimes[w] = timesUP, timesDOWN #stimtimes[whisker][0]=UP stimtimes[whisker][1]=DOWN\n",
    "    \n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    hist_inds = {}\n",
    "    PSTH_spike_counts = {}\n",
    "    \n",
    "    ## Now we will take the stim times and find all the relevant spikes\n",
    "    #start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "    #starts = (where(start_and_stops==1)[0]-2999)/float(sampling_freq) # time in seconds\n",
    "    #stops = (where(start_and_stops==-1)[0]+4110)/float(sampling_freq) # time in seconds\n",
    "    starts = starts[np.where(stimtype=='F')[0]]\n",
    "    stops = stops[np.where(stimtype=='F')[0]]\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in Spikes.keys(): \n",
    "        PSTH_spike_counts[neuron], hist_inds[neuron] = PSTH_spikes(stim, stimtype, stimtimes, Spikes[neuron].spike_times, sampling_freq, t_before, t_after, starts, stops)\n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "def PSTH_spikes(stimulation, stimtype, stimtimes, spikes, samp, t_before, t_after, starts, stops):\n",
    "    \"\"\"\n",
    "    stimulation   : a list of numpy arrays with a n*t stimulus inside\n",
    "    stimtimes     : a list of the times the stimulus occurred for each whisker \n",
    "    spikes        : an array that contains the spike times (s)\n",
    "    Vtag1         : synchronises stimulus with spike times\n",
    "    samp          : sampling rate of the stimulation (Hz)\n",
    "    t_before      : duration before the stim (positive, s)\n",
    "    t_after       : duration after the stim (positive, s)\n",
    "    starts        : the start of the F sweeps\n",
    "    stops         : the stops of the F sweeps\n",
    "    \"\"\"\n",
    "    \n",
    "    stim_samp = 1/.0009997575757 \n",
    "    PSTH_spike_counts = {}\n",
    "    \n",
    "    # Loop all whiskers for the spikes following the stimuli\n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(6, dtype='int') :           \n",
    "                if (stimtimes[w][0][i, x]>0) & (stimtimes[w][1][i, x]>0) :\n",
    "                    timesUP = starts[i] + stimtimes[w][0][i, x]/stim_samp\n",
    "                    timesDOWN = starts[i] + stimtimes[w][1][i, x]/stim_samp\n",
    "\n",
    "                    ## select spikes which fall near this stimulus\n",
    "                    spikecountsup += len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)])\n",
    "                    spikecountsdown += len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "        PSTH_spike_counts[w] = spikecountsup, spikecountsdown\n",
    "    \n",
    "    hist_inds = {}\n",
    "    \n",
    "    for w in np.arange(25, dtype='int') :\n",
    "        hist_inds[w] = np.zeros(PSTH_spike_counts[w][0]), np.zeros(PSTH_spike_counts[w][1])\n",
    "        spikecountsup = 0\n",
    "        spikecountsdown = 0\n",
    "        for i in np.arange(len(stimulation), dtype='int') : \n",
    "            for x in np.arange(6, dtype='int') :           \n",
    "                if (stimtimes[w][0][i, x]>0) & (stimtimes[w][1][i, x]>0) : #to rule out cases with less than 5 stims per sweep\n",
    "                    timesUP = starts[i] + stimtimes[w][0][i, x]/stim_samp\n",
    "                    timesDOWN = starts[i] + stimtimes[w][1][i, x]/stim_samp\n",
    "\n",
    "                    ## select spikes which fall near this stimulus\n",
    "                    spikecountup = len(spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)])\n",
    "                    spikecountdown = len(spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)])\n",
    "\n",
    "                    spikeidxup = spikes[(timesUP - t_before < spikes) * (spikes < timesUP + t_after)]\n",
    "                    spikeidxdown = spikes[(timesDOWN - t_before < spikes) * (spikes < timesDOWN + t_after)]\n",
    "                    spikeidxup = np.around((spikeidxup - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "                    spikeidxdown = np.around((spikeidxdown - starts[i])/float(stops[i] - starts[i])*len(stimulation[i,0]))\n",
    "\n",
    "                    hist_inds[w][0][spikecountsup:(spikecountsup+spikecountup)] = spikeidxup-stimtimes[w][0][i, x]\n",
    "                    hist_inds[w][1][spikecountsdown:(spikecountsdown+spikecountdown)] = spikeidxdown-stimtimes[w][1][i, x]\n",
    "\n",
    "                    spikecountsup += spikecountup\n",
    "                    spikecountsdown += spikecountdown\n",
    "    return PSTH_spike_counts, hist_inds\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "def GetWhiskers(histdata, t_before, t_after, thresh,activity,chancelevel) :\n",
    "    STC_on = {}\n",
    "    PW = {}\n",
    "    ActMod2={}\n",
    "    ActModout={}\n",
    "    \n",
    "    \n",
    "    stim_samp = 1/.0009997575757 \n",
    "    before_index = int(np.around(t_before*stim_samp)) \n",
    "    after_index = int(np.around(t_after*stim_samp)) \n",
    "    bins = before_index + after_index\n",
    "    \n",
    "    for neuron in histdata.keys() :\n",
    "        ActMod = np.zeros(25)\n",
    "        Countinout = np.zeros(25)\n",
    "        Count=np.zeros(25)\n",
    "        SHARP = np.zeros(25)\n",
    "        for i in np.arange(25, dtype='int') :\n",
    "            after = 0\n",
    "            before = 0\n",
    "            countin = 0\n",
    "            countout =0\n",
    "            \n",
    "            for j in np.arange(len(histdata[neuron][i][0]), dtype='int') :\n",
    "                if histdata[neuron][i][0][j]>9 and histdata[neuron][i][0][j]<45 : \n",
    "                    after+=1                              #conunt spikes in 30ms timewindow after stimulus\n",
    "                    countin += 1\n",
    "                elif histdata[neuron][i][0][j]<10 :                \n",
    "                    before+=1                             #conunt spikes in 20ms timewindow befor stimulus\n",
    "                    countout += 1\n",
    "            for j in np.arange(len(histdata[neuron][i][1]), dtype='int') :\n",
    "                if histdata[neuron][i][1][j]>9 and histdata[neuron][i][1][j]<45 :\n",
    "                    after+=1                              \n",
    "                    countin += 1\n",
    "                elif histdata[neuron][i][1][j]<10:\n",
    "                    before+=1\n",
    "                    countout += 1\n",
    "            if (after+before)==0 :\n",
    "                before=1\n",
    "            elif (after+before)>activity : \n",
    "                ActMod[i]= (  after*(before_index+10) - before*35  ) / (  after*(before_index+10) + before*35  )   #weight different time windows\n",
    "                Countinout[i] = countin/(countout+1)\n",
    "                condition1 = where((histdata[neuron][i][0]<20)*(histdata[neuron][i][0]>5))\n",
    "                condition2 = where((histdata[neuron][i][1]<20)*(histdata[neuron][i][1]>5))\n",
    "                SHARP[i] = sum( histdata[neuron][i][0][ condition1 ] ) + sum( histdata[neuron][i][1][condition2] )\n",
    "            else :\n",
    "                ActMod[i]=0               \n",
    "            Count[i]=countin+countout\n",
    "            \n",
    "        ActModout[neuron]=ActMod\n",
    "        ActMod2[neuron]=ActMod*Countinout*SHARP\n",
    "        STC_on[neuron] = (ActMod>thresh)*(Count/sum(Count)>chancelevel)\n",
    "        PW[neuron] = np.where(ActMod2[neuron]==max(ActMod2[neuron]))[0][0]\n",
    "        if size(np.where(STC_on[neuron]==True))==0:\n",
    "            PW[neuron]= 20\n",
    "        \n",
    "        \n",
    "    return STC_on,PW, ActModout,ActMod2\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS LATENCIES\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildLatencies(histdata,STC_on,t_before, t_after,zth,lookbins) :\n",
    "    \n",
    "    stim_samp = 1/.0009997575757 \n",
    "    before_index = int(np.around(t_before*stim_samp)) \n",
    "    after_index = int(np.around(t_after*stim_samp)) \n",
    "    nbins = before_index + after_index\n",
    "    bins=np.linspace(-before_index, after_index, nbins+1)   #here we use 50 bins, so linspace has the bin delimiters\n",
    "                                                            # first bin between -5 and -4, and last 44 and 45 for example  \n",
    "    Latencies = {}\n",
    "    LatMean ={}\n",
    "    ResponseRC = {}\n",
    "    Zsc={}\n",
    "    \n",
    "    for neuron in sorted(histdata.keys())[:] :\n",
    "        \n",
    "        resp = zeros(25)\n",
    "        lat = zeros([2,25])\n",
    "        latM = zeros([2,25])\n",
    "        Zsc[0]=zeros([25,nbins])\n",
    "        Zsc[1]=zeros([25,nbins])\n",
    "        \n",
    "        histo = np.append(np.histogram(hist_output[neuron][20][0],bins=bins)[0],np.histogram(hist_output[neuron][20][1],bins=bins)[0])\n",
    "        mu = np.mean(histo) \n",
    "        if mu<0.1: mu = 0.75\n",
    "        sigma = np.std(histo)\n",
    "               \n",
    "        if len(np.where(STC_on[neuron]==True)[0])>0:         #if list not empty\n",
    "            for i in np.where(STC_on[neuron]==True)[0] : \n",
    "                \n",
    "                #compute zscore for each bin of each whisker that is active\n",
    "                Zsc[0][i] = (np.histogram(histdata[neuron][i][0],bins=bins)[0]-mu)/sigma\n",
    "                Zsc[1][i] = (np.histogram(histdata[neuron][i][1],bins=bins)[0]-mu)/sigma\n",
    "                \n",
    "                #----------------------------------------------------------------------------------------\n",
    "                #Find latencies for positive stimulus\n",
    "                #compute Max and sums in area of interest                \n",
    "                Max = np.where(Zsc[0][i][before_index+5:-10]==max(Zsc[0][i][before_index+5:-10]))[0][0]  + before_index+5      \n",
    "                max0 = max(Zsc[0][i])\n",
    "                sum0 = sum(Zsc[0][i][before_index+10:before_index+45])\n",
    "                \n",
    "                #get rid of whiskers without enough response, looking around the max bin\n",
    "                if Zsc[0][i][Max]<5 and sum(Zsc[0][i][Max-4:Max+1])/5 < 1.5:\n",
    "                    lat[0][i] = float('nan')\n",
    "                else:\n",
    "                    zth2=zth\n",
    "                    lookb = lookbins\n",
    "                    #if max zscore is not high enough, increase zthreshold and decrease looking window size\n",
    "                    if max0<12: \n",
    "                        zth2 = zth2*1.5\n",
    "                        lookb=lookb-1\n",
    "                    \n",
    "                    #here we loop until finding the start bin of the response\n",
    "                    should_restart = True\n",
    "                    while should_restart:\n",
    "                        should_restart = False\n",
    "                        for j in arange(Max)[-lookb::-1]:  \n",
    "                            #look back from the max_bin in a lookb window averaging below zth or a until a big slope\n",
    "                            if (sum(Zsc[0][i][j:j+lookb])/lookb<zth2) or ( (Zsc[0][i][j+lookb]-sum(Zsc[0][i][j:j+lookb-1]))/(lookbins-1)>zth2*1.):  \n",
    "                                #this shifts accounts for the window size\n",
    "                                shift = np.where(Zsc[0][i][j:j+lookb+1]>zth2)[0][0]\n",
    "                                #bins are centered at +.5, from -before_index, so we add 0.5\n",
    "                                #and another 1 since we got here most probably when max is out of the searhc window\n",
    "                                lat[0][i] = j-before_index+ 1.5 +shift*0.75   \n",
    "                                latM[0][i] = (Max-before_index+lat[0][i])/2\n",
    "                                #loop restarts if latency is below 5msec with higher zthreshold\n",
    "                                if lat[0][i]<5:        \n",
    "                                    should_restart =True       \n",
    "                                    zth2 = zth2*1.2\n",
    "                                break                           \n",
    "                #----------------------------------------------------------------------------------------\n",
    "                #We repeat for the negative stimulus\n",
    "                #compute Max and sums in area of interest                \n",
    "                Max = np.where(Zsc[1][i][before_index+5:-10]==max(Zsc[1][i][before_index+5:-10]))[0][0]  + before_index+5      \n",
    "                max1 = max(Zsc[1][i])\n",
    "                sum1 = sum(Zsc[1][i][before_index+10:before_index+45])\n",
    "                \n",
    "                #get rid of whiskers without enough response, looking around the max bin\n",
    "                if Zsc[1][i][Max]<5 and sum(Zsc[1][i][Max-4:Max+1])/5 < 1.5:\n",
    "                    lat[1][i] = float('nan')\n",
    "                else:\n",
    "                    zth2=zth    \n",
    "                    lookb = lookbins\n",
    "                    #if max zscore is not high enough, increase zthreshold and decrease looking window size\n",
    "                    if max1<12: \n",
    "                        zth2 = zth2*1.5\n",
    "                        lookb=lookb-1\n",
    "\n",
    "                    #here we loop until finding the start bin of the response\n",
    "                    should_restart = True\n",
    "                    while should_restart:\n",
    "                        should_restart = False\n",
    "                        for j in arange(Max)[-lookb::-1]:\n",
    "                            #look back from the max_bin in a lookb window averaging below zth or a until a big slope\n",
    "                            if sum(Zsc[1][i][j:j+lookb])/lookb<zth2 or ( (Zsc[1][i][j+lookb]-sum(Zsc[1][i][j:j+lookb-1]))/(lookb-1)>zth2*1.):\n",
    "                                #this shifts accounts for the window size\n",
    "                                shift = np.where(Zsc[1][i][j:j+lookb+1]>zth2)[0][0]\n",
    "                                lat[1][i] = j-before_index+ 1.5 +shift*0.75\n",
    "                                latM[1][i] = (Max-before_index+lat[1][i])/2\n",
    "                                #loop restarts if latency is below 5msec with higher zthreshold\n",
    "                                if lat[1][i]<5: \n",
    "                                    should_restart =True\n",
    "                                    zth2 = zth2*1.2\n",
    "                                break\n",
    "                #----------------------------------------------------------------------------------------\n",
    "                #Compute the direction of the dominant response 1 positive -1 negative\n",
    "                if max0+sum0/35>max1+sum1/35: resp[i]=1\n",
    "                else : resp[i]=-1\n",
    "            #----------------------------------------------------------------------------------------                \n",
    "            #Output variables\n",
    "            Latencies[neuron] = lat\n",
    "            LatMean[neuron] = latM\n",
    "            ResponseRC[neuron]= resp\n",
    "       \n",
    "    return Latencies, LatMean , ResponseRC\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILD SPIKE TABLES\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Code to guide construction of the spike tables with rows representing variables (whisker and time) and each spike has a column        \n",
    "def BuildSpikeTables(Spikes, Vtag1,stim,stimtype, sampling_freq, t_before, t_after, choice,starts,stops):\n",
    "    \n",
    "    #start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "    #starts = (np.where(start_and_stops==1)[0]-2999)/float(sampling_freq)\n",
    "    #stops = (np.where(start_and_stops==-1)[0]+4110)/float(sampling_freq)\n",
    "    \n",
    "    #if len(starts)>len(stops): starts = [starts, stops[-1]+0.01]\n",
    "    \n",
    "    Spike_counts = {}\n",
    "    Spike_Tables = {}\n",
    "    \n",
    "    #stim, stimtype = read_stimulus()\n",
    "    \n",
    "    for neuron in Spikes.keys():\n",
    "        Spike_counts[neuron], Spike_Tables[neuron] = GenSpikeTables(stim, Spikes[neuron].spike_times, starts, stops, sampling_freq, t_before, t_after, stimtype, choice)\n",
    "    return Spike_counts, Spike_Tables\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# GEN SPIKE TALBLES\n",
    "#----------------------------------------------------------------------------------------\n",
    "# This generates the spike tables with rows representing variables (whisker and time) and each spike has a column\n",
    "def GenSpikeTables(stimulation, spikes, t_start, t_stop, samp, t_before, t_after, stimtype, choice) :\n",
    "    \"\"\"\n",
    "    stimulation : a numpy array with a n*t stimulus inside\n",
    "    spikes      : an array that contains the spike times (s)\n",
    "    t_start     : the stimulation start time (s)\n",
    "    samp        : sampling rate of the stimulation (Hz)\n",
    "    t_before    : duration before the stim (positive, s)\n",
    "    stimtype    : a vector of the type of stimulation, 'U' = uncorrelated, 'C' = correlated; 'F' = forward\n",
    "    choice      : what kind of stimulation to analyse\n",
    "    \"\"\"\n",
    "\n",
    "    stim_samp = 1/.0009997575757\n",
    "    \n",
    "    before_index = np.int(np.around(t_before*stim_samp))\n",
    "    after_index = np.int(np.around(t_after*stim_samp))\n",
    "    iterator = before_index + after_index\n",
    "\n",
    "    spike_count = 0\n",
    "\n",
    "    for i in np.arange(len(stimulation), dtype='int'):\n",
    "        if stimtype[i]==choice :\n",
    "            ## select spikes who fall in this particular sweep\n",
    "            spikeidx = spikes[( (t_start[i]+t_before) < spikes) * (spikes < (t_stop[i]-t_after))]\n",
    "            spike_count += len(spikeidx)\n",
    "    \n",
    "    spike_table = np.zeros((iterator*25, spike_count), dtype='int')\n",
    "    spikenumber = 0\n",
    "    for i in np.arange(len(stimulation), dtype='int'):\n",
    "        if stimtype[i]==choice :\n",
    "            ## select spikes who fall in this particular sweep\n",
    "            spikeidx = spikes[( (t_start[i]+t_before) < spikes) * (spikes < (t_stop[i]-t_after))]\n",
    "            ## calculate the index in the sweep that the spike occurred\n",
    "            spikeidx = np.around((spikeidx - t_start[i])/float(t_stop[i] - t_start[i])*len(stimulation[i,0]))    \n",
    "            for s in spikeidx:\n",
    "                spikewindow = stimulation[i, :, np.int(s)-before_index:np.int(s)+after_index]\n",
    "                spike_table[:, spikenumber] = np.reshape(spikewindow, [size(spikewindow)])\n",
    "                spikenumber = spikenumber + 1\n",
    "    return spike_count, spike_table\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILD STA\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Build STAs from spike tables, just averages across rows of the spike table\n",
    "def Build_STA(Spike_Tables) :\n",
    "    STA_Tables = {}\n",
    "\n",
    "    for neuron in Spike_Tables.keys():\n",
    "        STAraw = np.mean(Spike_Tables[neuron],axis=1)\n",
    "        STA_Tables[neuron] = np.reshape(STAraw,(25,len(STAraw)/25))\n",
    "    \n",
    "    return STA_Tables\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILD STC\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Build STCs from spike tables\n",
    "def Build_STC(Spike_Tables,stim,stimtype, whiskers, choice, numsamples, t_before, t_after, stimtreatment, cutoff) :\n",
    "    ## First we randomly select parts of the stimulus and compute the covariance matrix for the stimulus.\n",
    "    \n",
    "    stim_samp = 1/.0009997575757\n",
    "    \n",
    "    before_index = np.int(np.around(t_before*stim_samp))\n",
    "    after_index = np.int(np.around(t_after*stim_samp))\n",
    "    iterator = before_index+after_index\n",
    "\n",
    "    #stim, stimtype = read_stimulus()\n",
    "    inds = np.where(stimtype==choice)[0]\n",
    "    stimtrim = stim[inds,:,110:10145]         #we are only using the stimulus part of 'C' or 'U'\n",
    "    \n",
    "    Nstimcovmat = {}\n",
    "    W = {}\n",
    "    \n",
    "    if stimtreatment=='whiten' :\n",
    "        for neuron in Spike_Tables.keys() :\n",
    "            whiskinds = np.where(whiskers[neuron]==True)[0]\n",
    "            if np.where(whiskers[neuron]==True)[0].size==0 :\n",
    "                #whiskinds = np.arange(25, dtype='int')    #uncomment to analyse all whiskers when there is no significant one\n",
    "                whiskinds = np.array([20])                   #uncomment to speed up and not evaluate neurons without significant whiskers\n",
    "            spike_table = np.zeros((len(whiskinds)*iterator, numsamples))\n",
    "\n",
    "            for sample in np.arange(numsamples, dtype='int') :\n",
    "                stimsweep = randint(0, stimtrim.shape[0])\n",
    "                s = randint(before_index, stimtrim.shape[2]-after_index)\n",
    "                spikewindow = stimtrim[stimsweep, whiskinds, s-before_index:s+after_index]\n",
    "                spike_table[:,sample] = np.reshape(spikewindow, [size(spikewindow)])\n",
    "        \n",
    "            #spike_table = np.mean(np.reshape(spike_table, [2, -1, numsamples], 'F'), axis=0)\n",
    "            indsdown = np.zeros((len(whiskinds),np.int(((iterator/5)+1))), dtype='int')\n",
    "            k=1\n",
    "            for i in np.arange(((iterator/5)+1), dtype='int') :\n",
    "                if i>0 :\n",
    "                    k=0\n",
    "                for j in np.arange(len(whiskinds), dtype='int') :\n",
    "                    indsdown[j,i] = np.int(i*5+j*50+k-1)\n",
    "            indsdown[0, 0] = 0\n",
    "            indsdown = np.reshape(indsdown, [size(indsdown)])\n",
    "\n",
    "            spike_table = spike_table[indsdown, :]\n",
    "        \n",
    "            spike_table = spike_table - np.mean(spike_table, axis=1)[:, np.newaxis] # mean centering\n",
    "            Nstimcovmat[neuron] = np.cov(spike_table)\n",
    "            eigval1, eigvec1 = np.linalg.eigh(Nstimcovmat[neuron])\n",
    "    \n",
    "            inds = np.argsort(eigval1)[::-1]\n",
    "            eigval = eigval1[inds]\n",
    "            eigvec = eigvec1[:, inds]\n",
    "    \n",
    "            scalede = np.sqrt(np.real(eigval))\n",
    "            inveigval = np.diag(1/scalede)\n",
    "    \n",
    "            n_eigvecs = np.int(np.around(len(eigvec)*cutoff))\n",
    "            inveigval[n_eigvecs:] = 0\n",
    "\n",
    "            W[neuron] = np.dot(eigvec, np.dot(inveigval, eigvec.T))\n",
    "    \n",
    "    #Second we must whiten the spike triggered ensemble, and do an eigenvalue decomposition of the covariance matrix\n",
    "    #for each neuron \n",
    "    STC_covmats = {}\n",
    "    STC_eigs = {}\n",
    "    \n",
    "    for neuron in Spike_Tables.keys() :\n",
    "        #For STC we usually will not take the full 100ms before and after the stimulus\n",
    "        #These lines trim the stimulus down \n",
    "        whiskinds = np.where(whiskers[neuron]==True)[0]\n",
    "        if np.where(whiskers[neuron]==True)[0].size==0 :\n",
    "            #whiskinds = np.arange(25, dtype='int')    #uncomment to analyse all whiskers when there is no significant one\n",
    "            whiskinds = np.array([20])                   #uncomment to speed up and not evaluate neurons without significant whiskers\n",
    "\n",
    "        spike_table = Spike_Tables[neuron]\n",
    "        spike_table = np.reshape(spike_table, [spike_table.shape[0]/25, 25, spike_table.shape[1]], 'F')\n",
    "\n",
    "        \n",
    "        spike_table = spike_table[:, whiskinds, :]\n",
    "        spike_table = np.reshape(spike_table, [spike_table.shape[0]*spike_table.shape[1], spike_table.shape[2]], 'F')\n",
    "        \n",
    "        \n",
    "        indsdown = np.zeros((len(whiskinds),np.int(((iterator/5)+1))), dtype='int')\n",
    "        k=1\n",
    "        for i in np.arange(((iterator/5)+1), dtype='int') :\n",
    "            if i>0 :\n",
    "                k=0\n",
    "            for j in np.arange(len(whiskinds), dtype='int') :\n",
    "                indsdown[j,i] = np.int(i*5+j*50+k-1)\n",
    "        indsdown[0, 0] = 0\n",
    "        indsdown = np.reshape(indsdown, [size(indsdown)])\n",
    "        spike_table = spike_table[indsdown, :]\n",
    "\n",
    "        #spike_table = np.mean(np.reshape(spike_table, [2, -1, spike_table.shape[1]], 'F'), axis=0)\n",
    "        spike_table = spike_table - np.mean(spike_table,axis=1)[:, np.newaxis] # mean centering\n",
    "        \n",
    "        \n",
    "        if stimtreatment == 'remcorr' :\n",
    "            STC_covmats[neuron] = np.cov(np.dot(eigvec1.T, spike_table)) #with spatial correlation removed\n",
    "        elif stimtreatment == 'whiten' :\n",
    "            STC_covmats[neuron] = np.cov(np.dot(W[neuron], spike_table)) #with whitening\n",
    "        elif stimtreatment == 'none':\n",
    "            STC_covmats[neuron] = np.cov(spike_table) #raw spike triggered ensemble\n",
    "            \n",
    "        STCeig = AttrDict({'eigvals': np.zeros(STC_covmats[neuron].shape[0]), 'eigvecs': np.zeros((STC_covmats[neuron].shape[0], STC_covmats[neuron].shape[0]))})\n",
    "        STCeig.eigvals, STCeig.eigvecs = np.linalg.eigh(STC_covmats[neuron])\n",
    "        STC_eigs[neuron] = STCeig\n",
    "    \n",
    "    return STC_eigs, STC_covmats, W, Nstimcovmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAYING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY PSTH \n",
    "#----------------------------------------------------------------------------------------\n",
    "# Plot a single neuron PSTH, 25 piezos\n",
    "def display_PSTH(histdata, counts, t_before, t_after,fig,inner_grid,neuron,numspikesP,numspikesN,STC_on,PW) :\n",
    "    stim_samp = 1/.0009997575757 \n",
    "    before_index = int(np.around(t_before*stim_samp)) # indexes\n",
    "    after_index = int(np.around(t_after*stim_samp)) # indexes\n",
    "    histlength = before_index + after_index + 1\n",
    "    \n",
    "    nup = np.zeros((25,histlength-1))\n",
    "    ndown = np.zeros((25,histlength-1))\n",
    "    \n",
    "    \n",
    "    fig2 = figure()\n",
    "    ax = fig2.add_subplot(1,1,1)\n",
    "    for i in range(25) :\n",
    "        if histdata[i][0].size :\n",
    "            n1, bins, patches = ax.hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength))\n",
    "            nup[i,:] = n1\n",
    "            close()\n",
    "        if histdata[i][1].size :\n",
    "            n2=2\n",
    "            n2, bins, patches = ax.hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength))\n",
    "            ndown[i,:] = n2\n",
    "            close()\n",
    "    normnum = (1/np.sum(nup+ndown))\n",
    "    height = np.max(np.array([np.max(nup), np.max(ndown)]))/(1/normnum)\n",
    "     \n",
    "   \n",
    "        \n",
    "    clf()\n",
    "    \n",
    "    for i in range(25) :\n",
    "        if i == 0 :\n",
    "            #ax1 = subplot(5,5,1, frame_on=False)\n",
    "            ax1 = Subplot(fig, inner_grid[i])     \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        elif i==20:\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.spines['right'].set_linewidth(0.3)\n",
    "            ax1.spines['top'].set_linewidth(0.3)\n",
    "            ax1.spines['left'].set_linewidth(0.3)\n",
    "            ax1.spines['bottom'].set_linewidth(0.3)\n",
    "            \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        else :\n",
    "            #subplot(5,5,i+1,sharex=ax1,sharey=ax1,frame_on=False)\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        \n",
    "        if PW==i:\n",
    "            ax1.set_axis_bgcolor('#dddddd')    \n",
    "        elif i!=20:\n",
    "            ax1.spines['right'].set_visible(False)\n",
    "            ax1.spines['top'].set_visible(False)\n",
    "            ax1.spines['left'].set_visible(False)\n",
    "            ax1.spines['bottom'].set_visible(False)\n",
    "        if STC_on[i]== True:\n",
    "            ax1.set_axis_bgcolor('#dddddd')    \n",
    "                        \n",
    "        \n",
    "        if histdata[i][1].size :\n",
    "            ax1.hist(histdata[i][1], bins = np.linspace(-before_index, after_index, histlength), color='g', alpha=1.0, edgecolor='none', histtype='stepfilled', label='Pos', weights=np.repeat(normnum, len(histdata[i][1])))\n",
    "        if histdata[i][0].size :\n",
    "            ax1.hist(histdata[i][0], bins = np.linspace(-before_index, after_index, histlength), color='b', alpha=0.7, edgecolor='none', histtype='stepfilled', label='Neg', weights=np.repeat(normnum, len(histdata[i][0]))) \n",
    "        #if (histdata[i][0].size) or (histdata[i][1].size) :\n",
    "        xlim(-before_index, after_index)\n",
    "        ax1.axvline(0, color = 'r', linewidth=1)\n",
    "        ax1.axhline(0, color = 'r', linewidth=2)\n",
    "        ymax = 1.02 * height\n",
    "        ylim(0, ymax)\n",
    "        xvals = np.array([0,10,20,30])\n",
    "        yvals = np.array([0,ymax*0.9,ymax*0.9,0])\n",
    "        ax1.plot(xvals, yvals, linewidth=0.2,color = (0.75,0.75,0.75))\n",
    "        if i==4: ax1.set_title('ymax =' + str( np.around(height,decimals = 3) ),fontsize=8)\n",
    "        if i ==1: ax1.set_title('Nrn' + str(neuron) + '_Pos' + str(int(numspikesP))+ '_Neg' + str(int(numspikesN)),fontsize=9)\n",
    "\n",
    "        \n",
    "        fig.add_subplot(ax1)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "def display_all_PSTHs_of_recording(histdata, counts, pdf_files_directory, t_before, t_after,grupete,STC_on,PW,titles) :\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(histdata.keys())\n",
    "    if nrns <16: \n",
    "        layout = [5,3]\n",
    "    else: layout = [nrns//3+(nrns%3!=0),3]\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.1, hspace=0.2)\n",
    "    \n",
    "    ii=0\n",
    "    \n",
    "    orderneurons = np.sort(list(histdata.keys()))\n",
    "    for neuron in  orderneurons:\n",
    "        clf()\n",
    "        totalup = 0\n",
    "        totaldown = 0\n",
    "        for i in np.arange(25, dtype='int') :\n",
    "            totalup+=counts[neuron][i][0]\n",
    "            totaldown+=counts[neuron][i][1]\n",
    "            \n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(5,5,subplot_spec=outer_grid[ii], wspace=0.1, hspace=0.1)\n",
    "               \n",
    "        numspikesP= totalup                  \n",
    "        numspikesN= totaldown\n",
    "        display_PSTH(histdata[neuron], counts[neuron], t_before, t_after,fig,inner_grid,neuron,numspikesP,numspikesN,STC_on[neuron],PW[neuron])                               \n",
    "        \n",
    "        if grupete ==1:\n",
    "            fig.suptitle(titles + '_multiunits',fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(titles ,fontsize=16)\n",
    "        \n",
    "        ii+=1\n",
    "    if grupete ==1:                  \n",
    "        fig.savefig(pdf_files_directory + titles + '_hist_multi.pdf', format='pdf')\n",
    "    else:\n",
    "        fig.savefig(pdf_files_directory + titles + '_hist.pdf', format='pdf')\n",
    "        \n",
    "    clf()\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------          \n",
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY LATENCIES\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Plot a single neuron PSTH, 25 piezos\n",
    "def display_Latencies(PW, STC_on, ResRC, Latencies,titles,grupete,pdf_files_directory) :\n",
    "    \n",
    "    AdGraph = {}\n",
    "\n",
    "    AdGraph[0] = array([1,5,6])\n",
    "    AdGraph[1] = array([0,2,5,6,7])\n",
    "    AdGraph[2] = array([1,3,6,7,8])\n",
    "    AdGraph[3] = array([2,4,7,8,9])\n",
    "    AdGraph[4] = array([3,8,9])\n",
    "\n",
    "    AdGraph[5] = array([0,1,6,10,11])\n",
    "    AdGraph[6] = array([0,1,2,5,7,10,11,12])\n",
    "    AdGraph[7] = array([1,2,3,6,8,11,12,13])\n",
    "    AdGraph[8] = array([2,3,4,7,9,12,13,14])\n",
    "    AdGraph[9] = array([3,4,8,13,14])\n",
    "\n",
    "    AdGraph[10] = array([5,6,11,15,16])\n",
    "    AdGraph[11] = array([5,6,7,10,12,15,16,17])\n",
    "    AdGraph[12] = array([6,7,8,11,13,16,17,18])\n",
    "    AdGraph[13] = array([7,8,9,12,14,17,18,19])\n",
    "    AdGraph[14] = array([8,9,13,18,19])\n",
    "\n",
    "    AdGraph[15] = array([10,11,16,21])\n",
    "    AdGraph[16] = array([10,11,12,15,17,21,22])\n",
    "    AdGraph[17] = array([11,12,13,16,18,21,22,23])\n",
    "    AdGraph[18] = array([12,13,14,17,19,22,23,24])\n",
    "    AdGraph[19] = array([13,14,18,23,24])\n",
    "\n",
    "    AdGraph[21] = array([15,16,17,22])\n",
    "    AdGraph[22] = array([16,17,18,21,23])\n",
    "    AdGraph[23] = array([17,18,19,22,24])\n",
    "    AdGraph[24] = array([18,19,23])\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    #Plotting stuff\n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    ax1 = fig.add_subplot(321)    #Latencies between PW AW and RW\n",
    "    ax2 = fig.add_subplot(323)    #Latencies in PW ordered by respones\n",
    "    ax3 = fig.add_subplot(324)    #Latencies in PW ordered from min to max\n",
    "    ax4 = fig.add_subplot(325)    #Latencies in PW ordered from min to max\n",
    "\n",
    "        \n",
    "    # Hide the right and top spines\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax1.yaxis.set_ticks_position('left')\n",
    "    ax1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    # Hide the right and top spines\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "         \n",
    "    # Hide the right and top spines\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax3.yaxis.set_ticks_position('left')\n",
    "    ax3.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    # Hide the right and top spines\n",
    "    ax4.spines['right'].set_visible(False)\n",
    "    ax4.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax4.yaxis.set_ticks_position('left')\n",
    "    ax4.xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "    colors = ['blue','green','red','yellow','orange','cyan','magenta','greenyellow','black','gray', \n",
    "              'purple','salmon','brown', 'beige','chocolate','dimgray','ivory','seagreen','lavender','palegreen']\n",
    "    \n",
    "    lt=['-','--']\n",
    "    lts=['-o','-s']\n",
    "    #-------------------------------------------------------------\n",
    "    #-------------------------------------------------------------\n",
    "      \n",
    "    data_pw = []\n",
    "    data_aw = []\n",
    "    datos_PWm = []\n",
    "    datos_PWM = []\n",
    "    datos_PWmax = []\n",
    "    Pref = zeros(8)\n",
    "    neucol=-1      #initialize colors  \n",
    "    \n",
    "    for neuron in sorted(PW.keys())[:]:        #loop ordered units\n",
    "        neucol+=1\n",
    "        if len(np.where(STC_on[neuron]==True)[0])>0:  #if list not empty\n",
    "            #compute latencies\n",
    "            PW0=Latencies[neuron][0][PW[neuron]]\n",
    "            PW1=Latencies[neuron][1][PW[neuron]]\n",
    "            PWmin = min(PW0,PW1)\n",
    "            PWmax = max(PW0,PW1)\n",
    "            #------------------------------------------------------\n",
    "            #plotting options. If positive wins, then it's square, if not circle\n",
    "            if PW0<PW1:\n",
    "                dotts = [0,1]\n",
    "            else:\n",
    "                dotts = [1,0]\n",
    "            #------------------------------------------------------\n",
    "            #Plot PW dominant and PW oposite\n",
    "            if isnan(PWmin):     #in case one direction does not respond\n",
    "                PWmin = np.nanmin([PW0,PW1])\n",
    "                PWmax = float('nan')\n",
    "                datos_PWm =np.append(datos_PWm,PWmin)\n",
    "                ax2.plot([0],PWmin, lts[dotts[1]] ,color= colors[neucol])\n",
    "            else:\n",
    "                if ResRC[neuron][PW[neuron]]==1:          #ask for positive dominant PW\n",
    "                    datos_PWm =np.append(datos_PWm,PW0)\n",
    "                    datos_PWM =np.append(datos_PWM,PW1)\n",
    "                    ax2.plot([0,1],[PW0,PW1],lt[0],color= colors[neucol],ms=4)\n",
    "                    ax2.plot([0],PW0, lts[dotts[1]] ,color= colors[neucol])\n",
    "                    ax2.plot([1],PW1, lts[dotts[0]] ,color= colors[neucol])\n",
    "                else:\n",
    "                    datos_PWm =np.append(datos_PWm,PW1)\n",
    "                    datos_PWM =np.append(datos_PWM,PW0)\n",
    "                    ax2.plot([0,1],[PW1,PW0],lt[0],color= colors[neucol],ms=4)\n",
    "                    ax2.plot([0],PW1, lts[dotts[1]] ,color= colors[neucol])\n",
    "                    ax2.plot([1],PW0, lts[dotts[0]] ,color= colors[neucol])\n",
    "            #------------------------------------------------------\n",
    "            #save data for boxplots   \n",
    "            data_pw = np.append(data_pw,PWmin)\n",
    "            datos_PWmax = np.append(datos_PWmax,PWmax)\n",
    "            \n",
    "            if ResRC[neuron][PW[neuron]]==1: Pref[0] +=1 \n",
    "            else: Pref[1] +=1 \n",
    "            \n",
    "            #------------------------------------------------------\n",
    "            #here I plot the PW in first and third graphs\n",
    "            if PW[neuron]!=20:\n",
    "                #if pos direction is PW dominant, I plot it with a square and I label it \n",
    "                #if neg direction is PW dominant, I plot it with a circle and I label it \n",
    "                ax1.plot([0],PWmin,lts[dotts[1]],color= colors[neucol],label ='Nrn_'+str(neuron))\n",
    "                                \n",
    "                ax3.plot([0,1],[PWmin,PWmax],lt[0],color= colors[neucol],ms=4)\n",
    "                ax3.plot([0],PWmin, lts[dotts[1]] ,color= colors[neucol])\n",
    "                ax3.plot([1],PWmax, lts[dotts[0]] ,color= colors[neucol])\n",
    "            \n",
    "            #------------------------------------------------------\n",
    "            #Loop and plot adjacent whiskers that are active\n",
    "            for aw in AdGraph[PW[neuron]]:\n",
    "                if STC_on[neuron][aw]==True:\n",
    "                \n",
    "                    aw0=Latencies[neuron][0][aw]\n",
    "                    aw1=Latencies[neuron][1][aw]\n",
    "                    data_aw = np.append(data_aw,[aw0,aw1])\n",
    "                    \n",
    "                    if ResRC[neuron][aw]==1: \n",
    "                        Pref[2] +=1 \n",
    "                        if ResRC[neuron][PW[neuron]]==1:\n",
    "                            Pref[6]+=1\n",
    "                        else:\n",
    "                            Pref[7]+=1\n",
    "                    else: \n",
    "                        Pref[3] +=1 \n",
    "                        if ResRC[neuron][PW[neuron]]==-1:\n",
    "                            Pref[6]+=1\n",
    "                        else:\n",
    "                            Pref[7]+=1\n",
    "                 \n",
    "                    #plot the first aw with their corresponding marks \n",
    "                    ax1.plot([1],aw0,lts[1*(ResponseRC[neuron][aw]==1)],color= colors[neucol])\n",
    "                    ax1.plot([1],aw1,lts[1*(ResponseRC[neuron][aw]==-1)],color= colors[neucol])\n",
    "                    #then I join points\n",
    "                    ax1.plot([0,1],[PWmin,aw0],lt[dotts[0]],color= colors[neucol],ms=4)\n",
    "                    ax1.plot([0,1],[PWmin,aw1],lt[dotts[1]],color= colors[neucol],ms=4)\n",
    "            #------------------------------------------------------\n",
    "            #Loop and plot r whiskers that are active\n",
    "            for rw in arange(25):\n",
    "                if rw not in AdGraph[PW[neuron]] and rw!=PW[neuron] and STC_on[neuron][rw]==True:\n",
    "                    rw0 = Latencies[neuron][0][rw] \n",
    "                    rw1 = Latencies[neuron][1][rw] \n",
    "                    \n",
    "                    ax1.plot([2],rw0,lts[1*(ResponseRC[neuron][rw]==1)],color= colors[neucol])\n",
    "                    ax1.plot([2],rw1,lts[1*(ResponseRC[neuron][rw]==-1)],color= colors[neucol])\n",
    "                    ax1.plot([0,2],[PWmin,rw0],lt[dotts[0]],color= colors[neucol],ms=4)\n",
    "                    ax1.plot([0,2],[PWmin,rw1],lt[dotts[1]],color= colors[neucol],ms=4)\n",
    "\n",
    "    \n",
    "    #---------------------------\n",
    "    #titles\n",
    "    if grupete ==1:\n",
    "        fig.suptitle( titles + '_Latencies_multiunits',fontsize=16)\n",
    "    else:\n",
    "        fig.suptitle( titles + '_Latencies' ,fontsize=16)\n",
    "             \n",
    "        fig.add_subplot(ax1)\n",
    "        fig.add_subplot(ax2)\n",
    "    #---------------------------\n",
    "    #boxplots\n",
    "    ax1.boxplot([data_pw,data_aw],positions = [-0.25,1.25])\n",
    "    ax2.boxplot(datos_PWm,positions = [-0.25])\n",
    "    ax2.boxplot(datos_PWM,positions = [1.25])\n",
    "    ax3.boxplot(data_pw,positions = [-0.25])\n",
    "    ax3.boxplot(datos_PWmax,positions = [1.25])\n",
    "    \n",
    "    \n",
    "    Pref[4] = Pref[0]+Pref[2]\n",
    "    Pref[5] = Pref[1]+Pref[3]\n",
    "    #---------------------------\n",
    "    #ylims and labels\n",
    "    y_lims = ax1.get_ylim()\n",
    "    ax1.set_ylim([6,36])\n",
    "    #ax1.set_ylim(y_lims)\n",
    "    y_lims = ax2.get_ylim()\n",
    "    ax2.set_ylim([8,35])\n",
    "    #ax2.set_ylim(y_lims)\n",
    "    ax3.set_ylim([8,35])\n",
    "    \n",
    "    ax1.set_ylabel('Latencies (ms)')\n",
    "    ax2.set_ylabel('Latencies (ms)')\n",
    "    ax3.set_ylabel('Latencies (ms)')\n",
    "    ax4.set_ylabel('Number of whiskers')\n",
    "\n",
    "    #---------------------------\n",
    "    #xlims and labels\n",
    "    ax1.set_xlim([-0.5, 2.2])\n",
    "    ax2.set_xlim([-0.5, 2.2])\n",
    "    ax3.set_xlim([-0.5, 2.2])\n",
    "    ax4.set_xlim([-0.5, 2.2])\n",
    "\n",
    "    ind = arange(3)\n",
    "    ax1.set_xticks(ind)   \n",
    "    ax1.set_xticklabels( ['PW', 'AW', 'RW'] )\n",
    "    \n",
    "    ind = arange(2)\n",
    "    ax2.set_xticks(ind)   \n",
    "    ax2.set_xticklabels( ['PWmaxResp', 'PWsecond'] )\n",
    "    \n",
    "    ax3.set_xticks(ind)   \n",
    "    ax3.set_xticklabels( ['PWmin', 'PWmax'] )\n",
    "    \n",
    "    ind = arange(-0.4,2.1,0.35)\n",
    "    ax4.set_xticks(ind)   \n",
    "    ax4.set_xticklabels( ['','PWup-down','','AWup-down','','TOTup-down','','PW =/op AW'] )\n",
    "    for i in arange(4): ind[2*i+1] = ind[2*i+1]-0.1\n",
    "    ax4.bar(ind,Pref,width=0.2)\n",
    "    #---------------------------\n",
    "    #legend and texts\n",
    "    ax1.legend(bbox_to_anchor=(1.45, 1.2), loc=1, borderaxespad=0.)\n",
    "    \n",
    "    ax1.text(-0.3, 37,\"mean    = %.1f\"% nanmean(data_pw))\n",
    "    ax1.text(-0.3, 36,\"median = %.1f\"% nanmedian(data_pw))\n",
    "    ax1.text(-0.3, 35,\"stdev    =   %.1f\"% nanstd(data_pw))\n",
    "    ax1.text(0.9, 37,\"mean    = %.1f\"% nanmean(data_aw))\n",
    "    ax1.text(0.9, 36,\"median = %.1f\"% nanmedian(data_aw))\n",
    "    ax1.text(0.9, 35,\"stdev    =   %.1f\"% nanstd(data_aw))\n",
    "    \n",
    "    ax2.text(-0.3, 36,\"mean    = %.1f\"% nanmean(datos_PWm))\n",
    "    ax2.text(-0.3, 35,\"median = %.1f\"% nanmedian(datos_PWm))\n",
    "    ax2.text(-0.3, 34,\"stdev    =   %.1f\"% nanstd(datos_PWm))\n",
    "    ax2.text(0.9, 36,\"mean    = %.1f\"% nanmean(datos_PWM))\n",
    "    ax2.text(0.9, 35,\"median = %.1f\"% nanmedian(datos_PWM))\n",
    "    ax2.text(0.9, 34,\"stdev    =   %.1f\"% nanstd(datos_PWM))\n",
    "    \n",
    "    ax3.text(-0.3, 36,\"mean    = %.1f\"% nanmean(data_pw))\n",
    "    ax3.text(-0.3, 35,\"median = %.1f\"% nanmedian(data_pw))\n",
    "    ax3.text(-0.3, 34,\"stdev    =   %.1f\"% std(data_pw))\n",
    "    ax3.text(0.9, 36,\"mean    = %.1f\"% nanmean(datos_PWmax))\n",
    "    ax3.text(0.9, 35,\"median = %.1f\"% nanmedian(datos_PWmax))\n",
    "    ax3.text(0.9, 34,\"stdev    =   %.1f\"% nanstd(datos_PWmax))\n",
    "    \n",
    "    ax4.legend(bbox_to_anchor=(1.45, 1.), loc=1, borderaxespad=0.)\n",
    "    #---------------------------\n",
    "    #save figure\n",
    "    if grupete ==1:                  \n",
    "        fig.savefig(pdf_files_directory + titles + '_Latencies_multi.pdf', format='pdf')    \n",
    "    else:\n",
    "        fig.savefig(pdf_files_directory + titles + '_Latencies.pdf', format='pdf')    \n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------          \n",
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY STA\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Plot a single STA\n",
    "def display_STA(STAneuron, origin,fig,inner_grid,neuron,numspikes,STC_on,PW) :\n",
    "    \n",
    "    height =np.max(abs(STAneuron))\n",
    "    ymax = 1.02 * height\n",
    "    \n",
    "    for i in range(25) :\n",
    "        if i == 0 :\n",
    "            ax1 = Subplot(fig, inner_grid[i])     \n",
    "            ax1.set_xticks([])\n",
    "            ax1.set_yticks([])\n",
    "        \n",
    "        elif i==20:\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            ax1.spines['right'].set_linewidth(0.3)\n",
    "            ax1.spines['top'].set_linewidth(0.3)\n",
    "            ax1.spines['left'].set_linewidth(0.3)\n",
    "            ax1.spines['bottom'].set_linewidth(0.3)\n",
    "        else :\n",
    "            ax1 = Subplot(fig,inner_grid[i],sharex=ax1,sharey=ax1)\n",
    "            xticks([],[])  #gets rid of the x ticks and numbers\n",
    "            yticks([],[])  #gets rid of the y ticks and numbers\n",
    "       \n",
    "    \n",
    "        if PW==i:\n",
    "            ax1.set_axis_bgcolor('#dddddd')    \n",
    "        elif i!=20:\n",
    "            ax1.spines['right'].set_visible(False)\n",
    "            ax1.spines['top'].set_visible(False)\n",
    "            ax1.spines['left'].set_visible(False)\n",
    "            ax1.spines['bottom'].set_visible(False)\n",
    "        if STC_on[i]== True:\n",
    "            ax1.set_axis_bgcolor('#dddddd')    \n",
    "    \n",
    "        ax1.set_xlim([0, int(STAneuron.shape[1])]) \n",
    "        ax1.axvline(origin, color = 'r', linewidth=0.5)\n",
    "        ax1.axhline(0, color = 'r', linewidth=0.5)\n",
    "        ax1.plot(STAneuron[i,:])\n",
    "        \n",
    "        ax1.set_ylim([-ymax, ymax])\n",
    "        \n",
    "        if i==4: ax1.set_title('ymax =' + str( np.around(ymax,decimals = 3) ),fontsize=8)\n",
    "        if i ==1: ax1.set_title('STA_Nrn' + str(neuron) + '_Stim' + choice+ '_'+ str(int(numspikes)),fontsize=9)\n",
    "\n",
    "        fig.add_subplot(ax1)\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# SAVE ALL STA OF RECORDING\n",
    "#----------------------------------------------------------------------------------------\n",
    "# Plot and save all STAs pdfs\n",
    "def save_all_STAs_of_recording(STA_Table, spike_counts, choice, pdf_files_directory, origin,STC_on,PW,titles,grupete) :\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(STA_Table.keys())\n",
    "    if nrns <16: \n",
    "        layout = [5,3]\n",
    "    else: layout = [nrns//3+(nrns%3!=0),3]\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.1, hspace=0.2)\n",
    "    \n",
    "    ii=0\n",
    "    \n",
    "    orderneurons = np.sort(list(STA_Table.keys()))\n",
    "    \n",
    "    for neuron in  orderneurons:\n",
    "      \n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(5,5,subplot_spec=outer_grid[ii], wspace=0.1, hspace=0.1)\n",
    "        \n",
    "        numspikes=spike_counts[neuron]\n",
    "        display_STA(STA_Table[neuron], origin,fig,inner_grid,neuron,numspikes,STC_on[neuron],PW[neuron])\n",
    "      \n",
    "        if grupete ==1:\n",
    "            fig.suptitle(titles + '_STA_Stim' + choice +'_multiunits',fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(titles + '_STA_Stim' + choice ,fontsize=16)\n",
    "        ii+=1\n",
    "        \n",
    "    if grupete ==1:                  \n",
    "        fig.savefig(pdf_files_directory + titles + '_STA_Stim' + choice + '_multi.pdf', format='pdf')\n",
    "    else:\n",
    "        fig.savefig(pdf_files_directory + titles + '_STA_Stim' + choice + '.pdf', format='pdf')\n",
    "\n",
    "        \n",
    "#----------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "# SAVE ALL F C U\n",
    "#----------------------------------------------------------------------------------------\n",
    "def save_all_FCU_of_recording(spike_counts,pdf_files_directory,titles,grupete):\n",
    "    \n",
    "    fig3 = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(list(spike_counts['F'].keys()))\n",
    "    if nrns <16: \n",
    "        layout = [5,3]\n",
    "    else: layout = [nrns//3+(nrns%3!=0),3]\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.3, hspace=0.2)\n",
    "    \n",
    "    orderneurons = np.sort(list(spike_counts['F'].keys()))\n",
    "    \n",
    "    global UFC\n",
    "    \n",
    "    ind=np.arange(3)\n",
    "    width= 0.5\n",
    "       \n",
    "    fig1 = plt.figure(figsize=(12,16.5),frameon=False)\n",
    "           \n",
    "    ax1 = fig1.add_subplot(321)    \n",
    "    ax2 = fig1.add_subplot(323)\n",
    "    \n",
    "    ax1.set_xlim([-0.2, 2.2])\n",
    "    ax1.set_xticks(ind)   \n",
    "    ax1.set_xticklabels( ['U', 'F', 'C'] )\n",
    "    \n",
    "    ax2.set_xlim([-0.2, 2.2])\n",
    "    ax2.set_xticks(ind)   \n",
    "    ax2.set_xticklabels( ['U', 'F', 'C'] )\n",
    "    \n",
    "    \n",
    "    ax1.set_ylim([0, 5000])        \n",
    "    ax2.set_ylim([0, 1.5])     \n",
    "    \n",
    "    # Hide the right and top spines\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax1.yaxis.set_ticks_position('left')\n",
    "    ax1.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    # Hide the right and top spines\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    ii=0\n",
    "    for neuron in orderneurons :     \n",
    "        \n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(1,1,subplot_spec=outer_grid[ii], wspace=0.1, hspace=0.1)\n",
    "\n",
    "        i=0\n",
    "        ax3 = Subplot(fig3, inner_grid[i])     \n",
    "        ax3.set_xticks([])\n",
    "        #ax3.set_yticks([])\n",
    "                \n",
    "        numspikes= [spike_counts['U'][neuron]/UFC[0]*360, spike_counts['F'][neuron]/UFC[1]*360,spike_counts['C'][neuron]/UFC[2]*360]\n",
    "                        \n",
    "        ax3.set_xlim([-0.25, 2.8])\n",
    "        ax3.set_xticks(ind+width/2)   \n",
    "        ax3.set_xticklabels( ['U', 'F', 'C'] )\n",
    "        \n",
    "        ax3.bar(ind,numspikes,width)\n",
    "        \n",
    "        # Hide the right and top spines\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        # Only show ticks on the left and bottom spines\n",
    "        ax3.yaxis.set_ticks_position('left')\n",
    "        ax3.xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "        if (numspikes[0]>numspikes[1] and numspikes[0]>numspikes[2]):\n",
    "            lt = '--s'\n",
    "        elif numspikes[1]>numspikes[2]:\n",
    "            lt = '-o'\n",
    "        else:\n",
    "            lt = ':d'\n",
    "         \n",
    "        if (x>300 and x< 10000 for x in numspikes):\n",
    "            ax1.plot([0,1,2],numspikes,lt,label ='Nrn_'+str(neuron))\n",
    "            ax2.plot([0,1,2],[x/numspikes[1] for x in numspikes ],lt,label ='Nrn_'+str(neuron))\n",
    "        \n",
    "        if grupete ==1:\n",
    "            fig3.suptitle( titles + '_UFC_multiunits',fontsize=16)\n",
    "        else:\n",
    "            fig3.suptitle( titles + '_UFC' ,fontsize=16)\n",
    "        ii+=1\n",
    "        \n",
    "        ax3.set_title('Nrn_' + str(neuron) + '_Tot' +str(int(sum(numspikes))),fontsize=9)\n",
    "        \n",
    "        fig3.add_subplot(ax3)\n",
    "\n",
    "    if grupete ==1:\n",
    "            fig1.suptitle(titles + '_UFC_multiunits',fontsize=16)\n",
    "    else:\n",
    "            fig1.suptitle(titles + '_UFC' ,fontsize=16)\n",
    "    ax1.set_title('UFC relation',fontsize=12)\n",
    "    ax2.set_title('UFC relation normalized',fontsize=12)\n",
    "    \n",
    "    ax1.set_ylabel('Spike counts')\n",
    "    ax1.legend(bbox_to_anchor=(1.55, 1), loc=1, borderaxespad=0.)\n",
    "    \n",
    "    #fig1.add_subplot(ax1)    \n",
    "    #fig1.add_subplot(ax2)\n",
    "          \n",
    "    if grupete ==1:                  \n",
    "        fig1.savefig(pdf_files_directory + titles + 'UFC_all_multi.pdf', format='pdf')    \n",
    "        fig3.savefig(pdf_files_directory + titles + '_UFC_multi.pdf', format='pdf')\n",
    "    else:\n",
    "        fig1.savefig(pdf_files_directory + titles + 'UFC_all.pdf', format='pdf')    \n",
    "        fig3.savefig(pdf_files_directory + titles + '_UFC.pdf', format='pdf')        \n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY STC\n",
    "#----------------------------------------------------------------------------------------\n",
    "#Plot eigenvalues\n",
    "def display_STC_eigs(STC_eigs, Spike_counts, whiskers, origin, choice, pdf_files_directory,titles,grupete) :\n",
    "    close(\"all\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,16.5))\n",
    "    nrns = len(STC_eigs.keys())\n",
    "    if nrns <16: \n",
    "        layout = [5,3]\n",
    "    else: layout = [nrns//3+(nrns%3!=0),3]\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.2, hspace=0.4)\n",
    " \n",
    "    orderneurons = np.sort(list(STC_eigs.keys()))\n",
    "    \n",
    "    ii=0\n",
    "    clf()\n",
    "    for neuron in orderneurons:\n",
    "        noprint=0\n",
    "    \n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(1,1,subplot_spec=outer_grid[ii], wspace=0.1, hspace=0.1)\n",
    "        ax1 = Subplot(fig, inner_grid[0])     \n",
    "          \n",
    "        whiskerinds = np.where(whiskers[neuron]==True)[0]\n",
    "        numwhiskers = len(whiskerinds)\n",
    "        if np.where(whiskers[neuron]==True)[0].size==0 :\n",
    "            #whiskerinds = np.arange(25, dtype='int')\n",
    "            whiskinds = np.array([20])                   #uncomment to speed up and not evaluate neurons without significant whiskers\n",
    "            numwhiskers = 1                               #idem\n",
    "            noprint = 1\n",
    "\n",
    "        numspikes = Spike_counts[neuron]\n",
    "        \n",
    "        eigvals = STC_eigs[neuron].eigvals\n",
    "        \n",
    "        inds = np.argsort(eigvals)[::-1]\n",
    "        ploteigvals = eigvals[inds]\n",
    "\n",
    "        eigvals = eigvals[inds]\n",
    "        \n",
    "        #figure()\n",
    "        ax1.plot(ploteigvals, 'bo',markersize=5,)\n",
    "        fig.add_subplot(ax1)\n",
    "        \n",
    "        ax1.set_xlim(left = 0)\n",
    "        ax1.set_title('Nrn_' + str(neuron) ,fontsize=9)\n",
    "        ax1.set_xlabel('#Eigenvalue')\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=7)\n",
    "        ax1.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0e'))\n",
    "        \n",
    "        if grupete ==1:\n",
    "            fig.suptitle(titles + '_STC_Eigs_Stim' + choice +'_multiunits',fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(titles + '_STC_Eigs_Stim' + choice ,fontsize=16)\n",
    "        \n",
    "        close(\"all\")\n",
    "        ii+=1   \n",
    "        if noprint==0:    \n",
    "            if grupete ==1:                  \n",
    "                fig.savefig(pdf_files_directory + titles + '_STC_Eigs_Stim' + choice + '_multi.pdf', format='pdf')\n",
    "            else:\n",
    "                fig.savefig(pdf_files_directory + titles + '_STC_Eigs_Stim' + choice + '.pdf', format='pdf')\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# DISPLAY STC\n",
    "#----------------------------------------------------------------------------------------        \n",
    "# Plot all STC and save them\n",
    "def display_STC(STC_eigs, Spike_counts, whiskers, numfilters, origin, choices, pdf_files_directory,PW,titles,grupete) :\n",
    "    \n",
    "    \n",
    "    nrns = len(STC_eigs.keys())\n",
    "    if numfilters<5:\n",
    "        layout = [5,3]\n",
    "    else:\n",
    "        layout = [numfilters,3]\n",
    "\n",
    "    outer_grid = gridspec.GridSpec(layout[0], layout[1], wspace=0.2, hspace=0.2)\n",
    " \n",
    "    orderneurons = np.sort(list(STC_eigs['F'].keys()))    \n",
    "    \n",
    "    for neuron in orderneurons:\n",
    "        clf()\n",
    "        fig = plt.figure(figsize=(12,16.5))\n",
    "    \n",
    "        whiskerinds = np.where(whiskers[neuron]==True)[0]\n",
    "        numwhiskers = len(whiskerinds)\n",
    "        if np.where(whiskers[neuron]==True)[0].size==0 :\n",
    "            #whiskerinds = np.arange(25, dtype='int')\n",
    "            whiskinds = np.array([20])                   #uncomment to speed up and not evaluate neurons without significant whiskers\n",
    "            numwhiskers = 1                               #idem\n",
    "            continue\n",
    "        \n",
    "        j=0\n",
    "        for choice in choices:\n",
    "            j+=1                     #column U C or F\n",
    "        \n",
    "            numspikes = Spike_counts[choice][neuron]\n",
    "        \n",
    "            eigvecs = STC_eigs[choice][neuron].eigvecs\n",
    "            eigvals = STC_eigs[choice][neuron].eigvals\n",
    "\n",
    "            inds = np.argsort(eigvals)[::-1]\n",
    "            indsplot = np.argsort(eigvals)[::-1]\n",
    "            ploteigvals = eigvals[inds]\n",
    "\n",
    "            inds = inds[0:numfilters]\n",
    "            eigvals = eigvals[inds]\n",
    "            eigvecs = eigvecs[:, inds]\n",
    "            eigvecs = np.reshape(eigvecs, [eigvecs.shape[0]/numwhiskers, numwhiskers, numfilters], 'F')\n",
    "\n",
    "            for fil in np.arange(numfilters, dtype='int') :\n",
    "                iii=(j-1)+fil*3              #subplot number\n",
    "               \n",
    "                inner_grid = gridspec.GridSpecFromSubplotSpec(5,5,subplot_spec=outer_grid[iii], wspace=0.1, hspace=0.1)\n",
    "                for i in np.arange(25, dtype='int') :\n",
    "\n",
    "                    if i == 0:\n",
    "                        ax2 = Subplot(fig, inner_grid[i])     \n",
    "                        ax2.set_xticks([])\n",
    "                        ax2.set_yticks([])      \n",
    "                        ax2.spines['right'].set_visible(False)\n",
    "                        ax2.spines['top'].set_visible(False)\n",
    "                        ax2.spines['left'].set_visible(False)\n",
    "                        ax2.spines['bottom'].set_visible(False)\n",
    "                    elif i == PW[neuron]:\n",
    "                        ax2 = Subplot(fig, inner_grid[i],sharex=ax2,sharey=ax2)     \n",
    "                        ax2.set_xticks([])\n",
    "                        ax2.set_yticks([])        \n",
    "                    else :\n",
    "                        ax2 = Subplot(fig,inner_grid[i],sharex=ax2,sharey=ax2)\n",
    "                        ax2.spines['right'].set_visible(False)\n",
    "                        ax2.spines['top'].set_visible(False)\n",
    "                        ax2.spines['left'].set_visible(False)\n",
    "                        ax2.spines['bottom'].set_visible(False)\n",
    "\n",
    "                        ax2.set_xticks([])\n",
    "                        ax2.set_yticks([])        \n",
    "\n",
    "                    if any(i==whiskerinds) :\n",
    "                        tempind = np.where(whiskerinds==i)[0]\n",
    "                        ax2.plot(eigvecs[:,tempind,fil])\n",
    "                        ymax = 1.02 * np.max(abs(eigvecs))\n",
    "                        ylim(-ymax, ymax)\n",
    "\n",
    "                    ax2.axvline(origin, color = 'r', linewidth=0.5)\n",
    "                    ax2.axhline(0, color = 'r', linewidth=0.5)\n",
    "\n",
    "                    if i==2 and iii<3:\n",
    "                        ax2.set_title('Eigval' + str(fil) + '_' + 'stim_'+ choice + '_'+ str(numspikes),fontsize=12)\n",
    "                    elif i==2:\n",
    "                        ax2.set_title('Eigval' + str(fil),fontsize=12)\n",
    "                    fig.add_subplot(ax2)\n",
    "        if grupete ==1:\n",
    "            fig.suptitle(titles + '_STC_Nrn' + str(neuron) +'_multiunits',fontsize=16)\n",
    "        else:\n",
    "            fig.suptitle(titles + '_STC_Nrn' + str(neuron) ,fontsize=16)\n",
    "        fig.savefig(pdf_files_directory + 'STC/' +  titles + '_STC_Nrn' + str(neuron) +  '.pdf', format='pdf')\n",
    "        close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-390b70cd8363>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmeas\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm164\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm264\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mExpe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeas\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles23\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Experiment numbers\n",
    "ExpeNum = [18,20,21,22,23]\n",
    "\n",
    "#Folders for measurements and experiments\n",
    "m12 = ['m1s1','m1s2','m1s3','m1s4','m2s1','m2s2','m2s3','m2s4']\n",
    "m13 = ['m1s1','m1s2','m1s3','m1s4','m3s1','m3s2','m3s3','m3s4']\n",
    "\n",
    "m164 = ['m1s1','m1s2','m1s3','m1s4','m1s5','m1s6','m1s7','m1s8']\n",
    "m264 = ['m2s1','m2s2','m2s3','m2s4','m2s5','m2s6','m2s7','m2s8']\n",
    "\n",
    "\n",
    "Expe={}\n",
    "Vtags={}\n",
    "Stim={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "    Vtags[num] = dict()\n",
    "    \n",
    "#Kwik files    \n",
    "files18 = ['MEAS-150630-1_ele01_ele08.kwik',\n",
    "                    'MEAS-150630-1_ele09_ele16.kwik',\n",
    "                    'MEAS-150630-1_ele17_ele24.kwik',\n",
    "                    'MEAS-150630-1_ele25_ele32.kwik',\n",
    "                    'MEAS-150630-2_ele01_ele08.kwik',\n",
    "                    'MEAS-150630-2_ele09_ele16.kwik',\n",
    "                    'MEAS-150630-2_ele17_ele24.kwik',\n",
    "                    'MEAS-150630-2_ele25_ele32.kwik']\n",
    "\n",
    "files20 = ['MEAS-150707-1_ele01_ele08.kwik',\n",
    "                    'MEAS-150707-1_ele09_ele16.kwik',\n",
    "                    'MEAS-150707-1_ele17_ele24.kwik',\n",
    "                    'MEAS-150707-1_ele25_ele32.kwik',\n",
    "                    'MEAS-150707-23_ele01_ele08.kwik',\n",
    "                    'MEAS-150707-23_ele16_ele09.kwik',\n",
    "                    'MEAS-150707-23_ele17_ele24.kwik',\n",
    "                    'MEAS-150707-23_ele25_ele32.kwik']\n",
    "    \n",
    "files21 = ['MEAS-150709-1-ordered_ele01_ele08.kwik',\n",
    "                    'MEAS-150709-1-ordered_ele09_ele16.kwik',\n",
    "                    'MEAS-150709-1-ordered_ele17_ele24.kwik',\n",
    "                    'MEAS-150709-1-ordered6_ele25_ele30.kwik',\n",
    "                    'MEAS-150709-23-ordered_ele01_ele08.kwik',\n",
    "                    'MEAS-150709-23-ordered_ele09_ele16.kwik',\n",
    "                    'MEAS-150709-23-ordered_ele17_ele24.kwik',\n",
    "                    'MEAS-150709-23-ordered6_ele25_ele30.kwik']\n",
    "                   \n",
    "            \n",
    "files22 = ['MEAS-150716-12_ele01_ele08.kwik',\n",
    "                    'MEAS-150716-12_ele09_ele16.kwik',\n",
    "                    'MEAS-150716-12_ele17_ele24.kwik',\n",
    "                    'MEAS-150716-12_ele25_ele32.kwik',\n",
    "                    'MEAS-150716-3_ele01_ele08.kwik',\n",
    "                    'MEAS-150716-3_ele09_ele16.kwik',\n",
    "                    'MEAS-150716-3_ele17_ele24.kwik',\n",
    "                    'MEAS-150716-3_ele25_ele32.kwik']\n",
    "\n",
    "files23 = ['MEAS-151027-1_ele01_ele08.kwik',\n",
    "                    'MEAS-151027-1_ele09_ele16.kwik',\n",
    "                    'MEAS-151027-1_ele17_ele24.kwik',\n",
    "                    'MEAS-151027-1_ele25_ele32.kwik',\n",
    "                    'MEAS-151027-1_ele33_ele40.kwik',\n",
    "                    'MEAS-151027-1_ele41_ele48.kwik',\n",
    "                    'MEAS-151027-1_ele49_ele56.kwik',\n",
    "                    'MEAS-151027-1_ele57_ele64.kwik',\n",
    "                    'MEAS-151027-2_ele01_ele08.kwik',\n",
    "                    'MEAS-151027-2_ele09_ele16.kwik',\n",
    "                    'MEAS-151027-2_ele17_ele24.kwik',\n",
    "                    'MEAS-151027-2_ele25_ele32.kwik',\n",
    "                    'MEAS-151027-2_ele33_ele40.kwik',\n",
    "                    'MEAS-151027-2_ele41_ele48.kwik',\n",
    "                    'MEAS-151027-2_ele49_ele56.kwik',\n",
    "                    'MEAS-151027-2_ele57_ele64.kwik']\n",
    "\n",
    "#Vtag files \n",
    "Vtags[18] = ['MEAS-150630-1_Vtag1.dat','MEAS-150630-2_Vtag1.dat']\n",
    "Vtags[20] = ['MEAS-150707-1_Vtag1.dat','MEAS-150707-23_Vtag1.dat']\n",
    "Vtags[21] = ['MEAS-150709-1_Vtag1.dat','MEAS-150709-23_Vtag1.dat']\n",
    "Vtags[22] = ['MEAS-150716-12_Vtag1.dat','MEAS-150716-3_Vtag1.dat']\n",
    "Vtags[23] = ['MEAS-151027-1_Vtag1.dat','MEAS-151027-2_Vtag1.dat']\n",
    "\n",
    "#Build Experiment dictionary\n",
    "i=0\n",
    "for meas in m12:\n",
    "    Expe[18][meas] = files18[i]\n",
    "    Expe[21][meas] = files21[i]\n",
    "    i+=1\n",
    "i=0\n",
    "for meas in m13:\n",
    "    Expe[20][meas] = files20[i]\n",
    "    Expe[22][meas] = files22[i]\n",
    "    i+=1\n",
    "\n",
    "i=0    \n",
    "for meas in np.append(m164,m264):\n",
    "    Expe[23][meas] = files23[i]\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "#Stimulus type\n",
    "for expe in ExpeNum:\n",
    "    Stim[expe] = 'big_STIM'\n",
    "\n",
    "Stim[23] = 'big_STIM_FC_corrected'\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders\n",
    "rootF = '/home/matias/WORKSPACE/'    \n",
    "stimFolder = rootF +'STIM/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "m1s1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/miniconda/lib/python3.4/site-packages/ipykernel/__main__.py:131: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/matias/miniconda/lib/python3.4/site-packages/ipykernel/__main__.py:132: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3) into shape (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-03e4b39bdb70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcomputePSTH\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                     \u001b[0mPSTH_spikes_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBuildPSTH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVtag1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstimtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpikes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_after\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstarts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m                 \u001b[0mSTC_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPW\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mActMod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mActMod2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGetWhiskers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_before\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_after\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchancelevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;31m#--------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-332dd3a8a48e>\u001b[0m in \u001b[0;36mBuildPSTH\u001b[1;34m(Vtag1, stim, stimtype, Spikes, sampling_freq, t_before, t_after, starts, stops)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mindsUP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m   \u001b[1;31m#we correct for 0 at the start of stim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mdiffUP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindsUP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindsUP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mtimesUP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindsUP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiffUP\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindsUP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mindsDOWN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#we correct for 0 at the start of stim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3) into shape (4)"
     ]
    }
   ],
   "source": [
    "global binname, textname, UFC\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [23]   #Expe                                        #select experiment numbers!\n",
    "grupete = [2]                                                #select cluster groups! 2 for good clusters 1 for multiunits\n",
    "Measurements = [m164[0]]#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']        #select measurement and/or shanks!\n",
    "loadVtag = 1                                                 #number of shank in which to load Vtag\n",
    "choices = ['F','C','U']                                      #select stimulus type\n",
    "dirs =[]\n",
    "ploteo = [1,0,0,0,0,0]                                         #1 to make plots:  psth,latencies, sta, ufc, stc, stcnrns\n",
    "computePSTH = 1                                              #1 to do PSTH\n",
    "computeLat = 0                                              #1 to do PSTH\n",
    "computeSTA= 0                                                #1 to do STA\n",
    "computeSTC = 0                                               #1 to do STC\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#loop experiments\n",
    "for expe in SelExp:\n",
    "    \n",
    "    #Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    \n",
    "    print(expe)\n",
    "\n",
    "    binname= stimFolder + Stim[expe] + '/Stimulus_UCC.bin'\n",
    "    textname=stimFolder + Stim[expe] + '/Stimulus_UCC.txt'\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits and multiunits\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits\n",
    "        \n",
    "        #folder names\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFall',rootF + 'OUTPUT/PDFall/STC']\n",
    "        if group ==1:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFallM',rootF + 'OUTPUT/PDFallM/STC']\n",
    "        if group ==3:\n",
    "            dirs  = [rootF + 'OUTPUT/PDFallU',rootF + 'OUTPUT/PDFallU/STC']\n",
    "     \n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        measurements = Expe[expe]                            \n",
    "                \n",
    "        for meas in Measurements:           \n",
    "            \n",
    "            print(meas)\n",
    "    \n",
    "            #select datafile\n",
    "            sp_file = rootF + 'EXP_' + str(expe) +'/'+ meas +'/'+ measurements[meas]\n",
    "            #select Vtag\n",
    "            if int(meas[1])<2: measV = 0    #select Vtag\n",
    "            else: measV=1\n",
    "            bin_file = rootF + 'EXP_' + str(expe) +'/' + Vtags[expe][measV]\n",
    "            #--------------------------------------------------------------------------------\n",
    "            #load data\n",
    "            Spikes, sampling_freq = readkwikinfo(sp_file, group)\n",
    "            #load Vtag and stimulus\n",
    "            if int(meas[1])==1 and int(meas[3])==loadVtag:               #load the stimulus once every 4 shanks\n",
    "                stim = []\n",
    "                stimtype=[]\n",
    "                stim,stimtype = read_stimulus(expe,1)\n",
    "                \n",
    "                Vtag1 =[]\n",
    "                Vtag1 = np.fromfile(file=bin_file, dtype=np.int16)\n",
    "                start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "                starts = (where(start_and_stops==1)[0]-2999)/float(sampling_freq) # time in seconds\n",
    "                stops = (where(start_and_stops==-1)[0]+4110)/float(sampling_freq) # time in seconds\n",
    "            \n",
    "            if (int(meas[1])==2 or int(meas[1])==3) and int(meas[3])==loadVtag:\n",
    "                stim = []\n",
    "                stimtype=[]\n",
    "                stim,stimtype = read_stimulus(expe,2)\n",
    "\n",
    "                Vtag1 =[]\n",
    "                Vtag1 = np.fromfile(file=bin_file, dtype=np.int16)\n",
    "                start_and_stops = Vtag1[1:] - Vtag1[:-1]\n",
    "                starts = (where(start_and_stops==1)[0]-2999)/float(sampling_freq) # time in seconds\n",
    "                stops = (where(start_and_stops==-1)[0]+4110)/float(sampling_freq) # time in seconds\n",
    "                        \n",
    "            if len(Spikes.keys())>0:                              #do only if there are clusters\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #create output folders\n",
    "                \n",
    "                for dir in dirs:\n",
    "                    if not os.path.exists(dir):\n",
    "                        os.makedirs(dir) \n",
    "\n",
    "                dire = dirs[0] +'/'\n",
    "                titles = 'Exp'+ str(expe) + '_Meas_' + meas[1] + '_Shank_' + meas[3]\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Build PSTHs\n",
    "                \n",
    "                t_before = .005  \n",
    "                t_after = .045\n",
    "                thresh = 0.37     #Act mod activity between 10,45ms and -10,10 ms (from -1 to 1)\n",
    "                activity = 40    #minimun amount of activity to get an active whisker from 10 to 45ms\n",
    "                chancelevel = 1/25*1.4   #how much activity above chance in response area (10-45ms)\n",
    "                \n",
    "                if computePSTH ==1:\n",
    "                    PSTH_spikes_counts, hist_output = BuildPSTH(Vtag1,stim,stimtype, Spikes, sampling_freq, t_before, t_after,starts,stops)\n",
    "                STC_on, PW ,ActMod,ActMod2= GetWhiskers(hist_output, t_before,t_after,thresh,activity,chancelevel)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot PSTH\n",
    "                if ploteo[0]==1: display_all_PSTHs_of_recording(hist_output, PSTH_spikes_counts, dire, t_before, t_after,group,STC_on,PW,titles)\n",
    "                #-----------------------------\n",
    "                #Get Latencies\n",
    "                \n",
    "                zscore = 3         #stdev of first two consecutive bins that determine the latency\n",
    "                zscore_th = 1.8\n",
    "                bin_window = 5\n",
    "                \n",
    "                if computeLat:    \n",
    "                    Latencies, LatMean, ResponseRC = BuildLatencies(hist_output,STC_on,t_before,t_after,zscore_th,bin_window)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot Latencies\n",
    "                    if ploteo[1]==1: display_Latencies(PW,STC_on,ResponseRC,Latencies,titles,grupete,dire)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Build STAs\n",
    "                \n",
    "                if computeSTA==1:\n",
    "                    STA_Tables = {}\n",
    "                    Counts_Tables = {}\n",
    "                    Spike_Tables = {}\n",
    "\n",
    "                    t_before = .045\n",
    "                    t_after = .005\n",
    "\n",
    "                    #Loop all stimulus types\n",
    "                    for choice in choices:\n",
    "                        Counts_Tables[choice], Spike_Tables[choice] = BuildSpikeTables(Spikes, Vtag1,stim,stimtype, sampling_freq, t_before, t_after, choice,starts,stops)\n",
    "                        STA_Tables[choice] = Build_STA(Spike_Tables[choice])\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot STAs\n",
    "                if ploteo[2]==1:\n",
    "                    for choice in choices:\n",
    "                        save_all_STAs_of_recording(STA_Tables[choice], Counts_Tables[choice], choice, dire, t_before*1000,STC_on,PW,titles,group)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot UFC\n",
    "                if ploteo[3]==1:save_all_FCU_of_recording(Counts_Tables,dire,titles,group)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Build STCs\n",
    "                \n",
    "                if computeSTC==1:\n",
    "                    numsamples = 10000\n",
    "                    cutoff = 0.25\n",
    "\n",
    "                    STC_eigs = {}\n",
    "                    STC_covmats = {}\n",
    "                    W = {}\n",
    "                    Nstimcovmat = {}\n",
    "\n",
    "                    for choice in choices :\n",
    "                        if choice=='C' :\n",
    "                            stimtreatment='whiten'\n",
    "                        elif choice=='F' :\n",
    "                            stimtreatment='whiten'\n",
    "                        elif choice=='U' :\n",
    "                            stimtreatment='whiten'\n",
    "\n",
    "                        stimtreatment = 'none'\n",
    "\n",
    "                        STC_eigs[choice], STC_covmats[choice], W[choice], Nstimcovmat[choice] = Build_STC(Spike_Tables[choice],stim,stimtype, STC_on, choice, numsamples, t_before, t_after, stimtreatment, cutoff)\n",
    "                #--------------------------------------------------------------------------------\n",
    "                #Plot STCs\n",
    "                #Eigenvalues\n",
    "                if ploteo[4]==1:\n",
    "                    for choice in choices :\n",
    "                        display_STC_eigs(STC_eigs[choice], Counts_Tables[choice], STC_on, t_before*200, choice, dire,titles,group)\n",
    "                #Eigenvectors\n",
    "                filters = 8    \n",
    "                if ploteo[5]==1:\n",
    "                    display_STC(STC_eigs, Counts_Tables, STC_on, filters, t_before*200, choices, dire,PW,titles,group)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  0.,  0.],\n",
       "       [-1.,  1., -1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STC_on[255]\n",
    "#PW[55]\n",
    "np.reshape(ResponseRC[777],[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "#Spikes file from klusterkwik\n",
    "sp_file = 'MEAS-150716-3_ele17_ele24.kwik'\n",
    "#Spikes, sampling_freq = readkwikinfo(sp_file)\n",
    "model = KwikModel(sp_file)\n",
    "\n",
    "model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_before = .005\n",
    "t_after = .045\n",
    "PSTH_spike_counts_up, PSTH_spike_counts_down, hist_inds_up, hist_inds_down, trials = BuildPSTHdual(16, Spikes[78].spike_times, Vtag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_conditional_PSTHs(78, 16, hist_inds_up, hist_inds_down, PSTH_spike_counts_up, PSTH_spike_counts_down, trials, './PDFS/PDFpsth/', t_before, t_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_before = .005\n",
    "t_after = .045\n",
    "PSTH_spike_counts_up, PSTH_spike_counts_down, hist_inds_up, hist_inds_down, trials = BuildPSTHdual(12, Spikes[78].spike_times, Vtag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_conditional_PSTHs(78, 12, hist_inds_up, hist_inds_down, PSTH_spike_counts_up, PSTH_spike_counts_down, trials, './PDFS/PDFpsth/', t_before, t_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
